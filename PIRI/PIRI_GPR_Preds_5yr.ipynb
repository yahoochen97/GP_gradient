{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration of GPR for PIRI data with unit trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gpytorch\n",
    "print(gpytorch.__version__)\n",
    "from typing import Optional, Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "from gpytorch.means import LinearMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement constant mean module and mask mean module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantVectorMean(gpytorch.means.mean.Mean):\n",
    "    def __init__(self, d=1, prior=None, batch_shape=torch.Size(), **kwargs):\n",
    "        super().__init__()\n",
    "        self.batch_shape = batch_shape\n",
    "        self.register_parameter(name=\"constantvector\",\\\n",
    "                 parameter=torch.nn.Parameter(torch.zeros(*batch_shape, d)))\n",
    "        if prior is not None:\n",
    "            self.register_prior(\"mean_prior\", prior, \"constantvector\")\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.constantvector[input.int().reshape((-1,)).tolist()]\n",
    "    \n",
    "class MaskMean(gpytorch.means.mean.Mean):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_mean: gpytorch.means.mean.Mean,\n",
    "        active_dims: Optional[Tuple[int, ...]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if active_dims is not None and not torch.is_tensor(active_dims):\n",
    "            active_dims = torch.tensor(active_dims, dtype=torch.long)\n",
    "        self.active_dims = active_dims\n",
    "        self.base_mean = base_mean\n",
    "    \n",
    "    def forward(self, x, **params):\n",
    "        return self.base_mean.forward(x.index_select(-1, self.active_dims), **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data with last 5 years splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PIRI_data():\n",
    "    # read data\n",
    "    data = pd.read_csv(\"hb_data_complete.csv\", index_col=[0])\n",
    "\n",
    "    # all zero PIRI for new zealand and netherland\n",
    "    data = data.loc[~data['country'].isin(['N-ZEAL','NETHERL'])]\n",
    "\n",
    "    countries = sorted(data.country.unique())\n",
    "    years = data.year.unique()\n",
    "    n = len(countries)\n",
    "    m = len(years)\n",
    "\n",
    "    # build data\n",
    "    country_dict = dict(zip(countries, range(n)))\n",
    "    year_dict = dict(zip(years, range(m)))\n",
    "\n",
    "    # x is:\n",
    "    # 1: year number\n",
    "    # 2: country id\n",
    "    # 3: AIShame (treatment indicator)\n",
    "    # 4: cat_rat\n",
    "    # 5: ccpr_rat\n",
    "    # 6: democratic\n",
    "    # 7: log(gdppc)\n",
    "    # 8: log(pop)\n",
    "    # 9: Civilwar2\n",
    "    # 10: War\n",
    "    x = torch.zeros(data.shape[0], 10)\n",
    "    x[:,0] = torch.as_tensor(list(map(year_dict.get, data.year)))\n",
    "    x[:,1] = torch.as_tensor(list(map(country_dict.get, data.country)))\n",
    "    x[:,2] = torch.as_tensor(data.AIShame.to_numpy())\n",
    "    x[:,3] = torch.as_tensor(data.cat_rat.to_numpy())\n",
    "    x[:,4] = torch.as_tensor(data.ccpr_rat.to_numpy())\n",
    "    x[:,5] = torch.as_tensor(data.democratic.to_numpy())\n",
    "    x[:,6] = torch.as_tensor(data.log_gdppc.to_numpy())\n",
    "    x[:,7] = torch.as_tensor(data.log_pop.to_numpy())\n",
    "    x[:,8] = torch.as_tensor(data.Civilwar2.to_numpy())\n",
    "    x[:,9] = torch.as_tensor(data.War.to_numpy())\n",
    "    y = torch.as_tensor(data.PIRI.to_numpy()).double()\n",
    "\n",
    "    # split data into training and testing by last 5 years\n",
    "    train_mask = x[:,0] < (m-5)\n",
    "    train_x = x[train_mask]\n",
    "    test_x = x[~train_mask]\n",
    "    train_y = y[train_mask]\n",
    "    test_y = y[~train_mask]\n",
    "\n",
    "    unit_means = torch.zeros(n,)\n",
    "    for i in range(n):\n",
    "        unit_means[i] = train_y[train_x[:,1]==i].mean()\n",
    "\n",
    "    return train_x.double(), train_y.double(), test_x.double(), test_y.double(), unit_means.double(), data, countries, years\n",
    "\n",
    "train_x, train_y, test_x, test_y, unit_means, data, countries, years = load_PIRI_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build GPR model with unit trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specification: PIRI gp model with unit trends\n",
    "# PIRI ~ AIShame + u_i(t) + cat_rat + ccpr_rat \n",
    "#            + democratic + log(gdppc) + log(pop) \n",
    "#            + Civilwar2 + War\n",
    "# u_i(t) ~ GP(b_i, K_t)\n",
    "\n",
    "class GPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, ard_num_dim=None):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = MaskMean(active_dims=1, \\\n",
    "                base_mean=ConstantVectorMean(d=train_x[:,1].unique().size()[0]))\n",
    "        # year kernel * country kernel\n",
    "        self.unit_covar_module = ScaleKernel(RBFKernel(active_dims=0)*RBFKernel(active_dims=1))\n",
    "        self.x_covar_module = torch.nn.ModuleList([ScaleKernel(RBFKernel(\\\n",
    "            active_dims=(i))) for i in [6,7]])\n",
    "        self.binary_covar_module = torch.nn.ModuleList([ScaleKernel(RBFKernel(\\\n",
    "            active_dims=(i))) for i in [3,4,5,8,9]])\n",
    "        self.effect_covar_module = ScaleKernel(RBFKernel(active_dims=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        unit_covar_x = self.unit_covar_module(x)\n",
    "        effect_covar_x = self.effect_covar_module(x)\n",
    "        covar_x = unit_covar_x + effect_covar_x\n",
    "        for i, _ in enumerate(self.x_covar_module):\n",
    "            covar_x += self.x_covar_module[i](x)\n",
    "        for i, _ in enumerate(self.binary_covar_module):\n",
    "            covar_x += self.binary_covar_module[i](x)\n",
    "        \n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPModel(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): MaskMean(\n",
       "    (base_mean): ConstantVectorMean()\n",
       "  )\n",
       "  (unit_covar_module): ScaleKernel(\n",
       "    (base_kernel): ProductKernel(\n",
       "      (kernels): ModuleList(\n",
       "        (0): RBFKernel(\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "        )\n",
       "        (1): RBFKernel(\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (raw_outputscale_constraint): Positive()\n",
       "  )\n",
       "  (x_covar_module): ModuleList(\n",
       "    (0): ScaleKernel(\n",
       "      (base_kernel): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (1): ScaleKernel(\n",
       "      (base_kernel): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (binary_covar_module): ModuleList(\n",
       "    (0): ScaleKernel(\n",
       "      (base_kernel): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (1): ScaleKernel(\n",
       "      (base_kernel): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (2): ScaleKernel(\n",
       "      (base_kernel): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (3): ScaleKernel(\n",
       "      (base_kernel): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (4): ScaleKernel(\n",
       "      (base_kernel): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (effect_covar_module): ScaleKernel(\n",
       "    (base_kernel): RBFKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "    (raw_outputscale_constraint): Positive()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood = GaussianLikelihood()\n",
    "model = GPModel(train_x, train_y, likelihood).double()\n",
    "\n",
    "# initialize model parameters\n",
    "hypers = {\n",
    "    'mean_module.base_mean.constantvector': unit_means,\n",
    "    'likelihood.noise_covar.noise': torch.tensor(0.25),\n",
    "    'unit_covar_module.base_kernel.kernels.0.lengthscale': torch.tensor(4),\n",
    "    'unit_covar_module.base_kernel.kernels.1.lengthscale': torch.tensor(0.01),\n",
    "    'unit_covar_module.outputscale': torch.tensor(0.25),\n",
    "    'x_covar_module.0.outputscale': torch.tensor(0.25),\n",
    "    'x_covar_module.1.outputscale': torch.tensor(0.25),\n",
    "    'binary_covar_module.0.base_kernel.lengthscale': torch.tensor(0.01),\n",
    "    'binary_covar_module.1.base_kernel.lengthscale': torch.tensor(0.01),\n",
    "    'binary_covar_module.2.base_kernel.lengthscale': torch.tensor(0.01),\n",
    "    'binary_covar_module.3.base_kernel.lengthscale': torch.tensor(0.01),\n",
    "    'binary_covar_module.4.base_kernel.lengthscale': torch.tensor(0.01),\n",
    "    'effect_covar_module.base_kernel.lengthscale': torch.tensor(0.01),\n",
    "    'effect_covar_module.outputscale': torch.tensor(0.25)\n",
    "}    \n",
    "\n",
    "model.initialize(**hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model by optimizing hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 2.358 \n",
      "Iter 2/50 - Loss: 2.252 \n",
      "Iter 3/50 - Loss: 2.132 \n",
      "Iter 4/50 - Loss: 2.029 \n",
      "Iter 5/50 - Loss: 1.956 \n",
      "Iter 6/50 - Loss: 1.887 \n",
      "Iter 7/50 - Loss: 1.835 \n",
      "Iter 8/50 - Loss: 1.787 \n",
      "Iter 9/50 - Loss: 1.752 \n",
      "Iter 10/50 - Loss: 1.717 \n",
      "Iter 11/50 - Loss: 1.691 \n",
      "Iter 12/50 - Loss: 1.665 \n",
      "Iter 13/50 - Loss: 1.645 \n",
      "Iter 14/50 - Loss: 1.639 \n",
      "Iter 15/50 - Loss: 1.619 \n",
      "Iter 16/50 - Loss: 1.607 \n",
      "Iter 17/50 - Loss: 1.605 \n",
      "Iter 18/50 - Loss: 1.605 \n",
      "Iter 19/50 - Loss: 1.601 \n",
      "Iter 20/50 - Loss: 1.586 \n",
      "Iter 21/50 - Loss: 1.589 \n",
      "Iter 22/50 - Loss: 1.593 \n",
      "Iter 23/50 - Loss: 1.588 \n",
      "Iter 24/50 - Loss: 1.586 \n",
      "Iter 25/50 - Loss: 1.588 \n",
      "Iter 26/50 - Loss: 1.592 \n",
      "Iter 27/50 - Loss: 1.588 \n",
      "Iter 28/50 - Loss: 1.590 \n",
      "Iter 29/50 - Loss: 1.591 \n",
      "Iter 30/50 - Loss: 1.593 \n",
      "Iter 31/50 - Loss: 1.592 \n",
      "Iter 32/50 - Loss: 1.592 \n",
      "Iter 33/50 - Loss: 1.593 \n",
      "Iter 34/50 - Loss: 1.594 \n",
      "Iter 35/50 - Loss: 1.591 \n",
      "Iter 36/50 - Loss: 1.589 \n",
      "Iter 37/50 - Loss: 1.583 \n",
      "Iter 38/50 - Loss: 1.591 \n",
      "Iter 39/50 - Loss: 1.586 \n",
      "Iter 40/50 - Loss: 1.587 \n",
      "Iter 41/50 - Loss: 1.591 \n",
      "Iter 42/50 - Loss: 1.589 \n",
      "Iter 43/50 - Loss: 1.593 \n",
      "Iter 44/50 - Loss: 1.589 \n",
      "Iter 45/50 - Loss: 1.589 \n",
      "Iter 46/50 - Loss: 1.589 \n",
      "Iter 47/50 - Loss: 1.592 \n",
      "Iter 48/50 - Loss: 1.587 \n",
      "Iter 49/50 - Loss: 1.583 \n",
      "Iter 50/50 - Loss: 1.585 \n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "# freeze length scale in the country component in unit covar\n",
    "# freeze constant unit means\n",
    "all_params = set(model.parameters())\n",
    "final_params = list(all_params - \\\n",
    "            {model.unit_covar_module.base_kernel.kernels[1].raw_lengthscale, \\\n",
    "            model.mean_module.base_mean.constantvector, \\\n",
    "        #   model.x_covar_module[0].raw_outputscale,\n",
    "        #   model.x_covar_module[1].raw_outputscale,\n",
    "            model.binary_covar_module[0].base_kernel.raw_lengthscale,\n",
    "            model.binary_covar_module[1].base_kernel.raw_lengthscale,\n",
    "            model.binary_covar_module[2].base_kernel.raw_lengthscale,\n",
    "            model.binary_covar_module[3].base_kernel.raw_lengthscale,\n",
    "            model.binary_covar_module[4].base_kernel.raw_lengthscale,\n",
    "            model.effect_covar_module.base_kernel.raw_lengthscale})\n",
    "        #   model.effect_covar_module.raw_outputscale})\n",
    "optimizer = torch.optim.Adam(final_params, lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 50\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f '  % (\n",
    "        i + 1, training_iter, loss.item()\n",
    "    ))\n",
    "    optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(), \"PIRI_GPR_model_5yr.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate posterior of PIRI effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effect: 0.333 +- 0.164\n",
      "\n",
      "model evidence: -2339.637 \n",
      "\n",
      "BIC: 4774.135 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('PIRI_GPR_model_5yr.pth'))\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    out = likelihood(model(train_x))\n",
    "    mu_f = out.mean\n",
    "    V = out.covariance_matrix\n",
    "    L = torch.linalg.cholesky(V, upper=False)\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    model.unit_covar_module.outputscale = 0\n",
    "    for i,_ in enumerate(model.x_covar_module):\n",
    "        model.x_covar_module[i].outputscale = 0\n",
    "    for i,_ in enumerate(model.binary_covar_module):\n",
    "        model.binary_covar_module[i].outputscale = 0\n",
    "    effect_covar = model(train_x).covariance_matrix\n",
    "\n",
    "# get posterior effect mean\n",
    "alpha = torch.linalg.solve(L.t(),torch.linalg.solve(L,train_y-mu_f))\n",
    "tmp = torch.linalg.solve(L, effect_covar)\n",
    "post_effect_mean = effect_covar @ alpha\n",
    "# get posterior effect covariance\n",
    "post_effect_covar = effect_covar - tmp.t() @ tmp\n",
    "\n",
    "effect = post_effect_mean[train_x[:,2]==1].mean() - post_effect_mean[train_x[:,2]==0].mean()\n",
    "effect_std = post_effect_covar.diag().mean().sqrt()\n",
    "BIC = (2+4+6+1)*torch.log(torch.tensor(train_x.size()[0])) + 2*loss*train_x.size()[0]\n",
    "print(\"effect: {:0.3f} +- {:0.3f}\\n\".format(effect, effect_std))\n",
    "print(\"model evidence: {:0.3f} \\n\".format(-loss*train_x.size()[0]))\n",
    "print(\"BIC: {:0.3f} \\n\".format(BIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Durbin Watson tests for autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 out of 138 residuals are positively correlated.\n",
      "\n",
      "0 out of 138 residuals are negatively correlated.\n",
      "\n",
      "133 out of 138 residuals are not correlated.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yahoo/anaconda3/lib/python3.7/site-packages/statsmodels/stats/stattools.py:50: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dw = np.sum(diff_resids**2, axis=axis) / np.sum(resids**2, axis=axis)\n"
     ]
    }
   ],
   "source": [
    "# get unit trend wo AIShame\n",
    "model.load_state_dict(torch.load('PIRI_GPR_model_5yr.pth'))\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    model.effect_covar_module.outputscale = 0\n",
    "    unit_covar = likelihood(model(train_x)).covariance_matrix\n",
    "\n",
    "# get posterior unit trend mean\n",
    "alpha = torch.linalg.solve(L.t(),torch.linalg.solve(L,train_y-mu_f))\n",
    "tmp = torch.linalg.solve(L, unit_covar)\n",
    "post_unit_mean = mu_f + unit_covar @ alpha + post_effect_mean\n",
    "\n",
    "# DW-test for sample size = 13 and 8 regressors.\n",
    "dL = 0.147\n",
    "dU = 3.266\n",
    "n = len(countries)\n",
    "DW_results = np.zeros((n,))\n",
    "for i in range(n):\n",
    "    mask = (train_x[:,1]==i).numpy()\n",
    "    res = train_y[mask] - post_unit_mean[mask]\n",
    "    DW_results[i] = durbin_watson(res.detach().numpy())\n",
    "\n",
    "print(\"{} out of {} residuals are positively correlated.\\n\".format(np.sum(DW_results<=dL),n))\n",
    "print(\"{} out of {} residuals are negatively correlated.\\n\".format(np.sum(DW_results>=dU),n))\n",
    "print(\"{} out of {} residuals are not correlated.\\n\".format(np.sum((DW_results>dL) & (DW_results<dU)),n))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('PIRI_GPR_model_5yr.pth'))\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    y_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_np = y_pred.mean.numpy() #convert to Numpy array\n",
    "\n",
    "df = pd.DataFrame(y_pred_np) #convert to a dataframe\n",
    "df['true_y'] = test_y\n",
    "df.to_csv(\"predicted_5_year.csv\",index=False) #save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd2c9b04da0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_y.numpy(),y_pred_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7977184770878506"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(test_y.numpy(),y_pred_np)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
