{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration of dynamic Gaussian Process Item Response Theory\n",
    "with spactial-temporal relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PACKAGES\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import matplotlib.pyplot as plt\n",
    "from binomial_likelihood import BinomialLikelihood\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "import torch\n",
    "import gpytorch\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "background characteristics: x_i ~ N(0,1), i=1,2,3,4\n",
    "\n",
    "normalized geospatial locations: g_1 ~ Unif(0,1), g_2 ~ Unif(0,1)\n",
    "\n",
    "geospatial correlated noise: g_effect ~ N(0, K), K_{ij} = exp(-(g_i-g_j)^2/2)\n",
    "\n",
    "temporal correlated noise: t_effect ~ N(0,K), K_t = exp(-(t-t')^2/2) \n",
    "\n",
    "temporal normalized latent policy positions: sigma_i = x_1^2 + x_2 + x_1*x_2 + cos(x3) - x_4^3 + t_effect * g_effect(i)\n",
    "\n",
    "response model: y ~ binom(sigma_i,m), y=1,...,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000; # num of respondents\n",
    "T = 10; # num of time periods\n",
    "m = 10; # num of items in the battery\n",
    "np.random.seed(12345)\n",
    "x = np.zeros((n*T,4+2+1))\n",
    "y = np.zeros((n*T,))\n",
    "\n",
    "# background characteristics: x_i \n",
    "for i in range(4):\n",
    "    x[:,i] = np.repeat(np.random.normal(loc=0.0, scale=1.0, size=(n,)),T)\n",
    "\n",
    "# normalized geospatial locations: g_1 ~ Unif(0,1), g_2 ~ Unif(0,1)\n",
    "g = np.random.uniform(low=0.0, high=1.0, size=(n,2))\n",
    "x[:,4] = np.repeat(g[:,0],T)\n",
    "x[:,5] = np.repeat(g[:,1],T)\n",
    "\n",
    "# geospatial correlated noise: sigma(t) ~ N(0, K), K_{ij} = exp(-(g_i-g_j)^2/2), K_t = exp(-(t-t')^2/2) \n",
    "kernel = RBF(length_scale = 1.0)\n",
    "# K = np.kron(kernel(g*2),kernel(np.arange(T).reshape(-1,1)/T*3))\n",
    "K = kernel(g*2)\n",
    "x[:,6] = np.tile(np.arange(T),n)\n",
    "g_effects = np.random.multivariate_normal(np.zeros((n,)), K)\n",
    "\n",
    "K = kernel(np.arange(T).reshape(-1,1)/T*3)\n",
    "t_effects = np.random.multivariate_normal(np.zeros((T,)), K)\n",
    "\n",
    "# normalized latent policy positions: \n",
    "f = x[:,0]**2 + x[:,1] + x[:,0]*x[:,1] + np.cos(x[:,2]) - x[:,3]**3\n",
    "for t in range(T):\n",
    "    f[x[:,6]==t] = t_effects[t]*g_effects\n",
    "f_min = np.min(f)\n",
    "f_max = np.max(f)\n",
    "f = (f-f_min) / (f_max - f_min)\n",
    "\n",
    "# response model: y ~ binom(sigma_i,m), y=1,...,m\n",
    "for i in range(n*T):\n",
    "    y[i] = np.random.binomial(m,f[i])\n",
    "\n",
    "train_x = torch.from_numpy(x).double()\n",
    "train_y = torch.from_numpy(y).double()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customize binomial likelihood model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.distributions import base_distributions\n",
    "from gpytorch.functions import log_normal_cdf\n",
    "from gpytorch.likelihoods.likelihood import _OneDimensionalLikelihood\n",
    "\n",
    "class BinomialLikelihood(_OneDimensionalLikelihood):\n",
    "    r\"\"\"\n",
    "    Implements the Binomial likelihood for count data y between 1 and m. \n",
    "    The Binomial distribution is parameterized by :math:`m > 0`. \n",
    "    We can write the likelihood as:\n",
    "\n",
    "    .. math::\n",
    "        \\begin{equation*}\n",
    "            p(Y=y|f,m)=\\phi(f)^y(1-\\phi(f))^{(m-y)}\n",
    "        \\end{equation*}\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,m):\n",
    "        super().__init__()\n",
    "        if m<0 or int(m)!=m:\n",
    "            self.m = 10\n",
    "            print(\"m must be a positive integer!\")\n",
    "        else:\n",
    "            self.m = m\n",
    "\n",
    "    def forward(self, function_samples, **kwargs):\n",
    "        output_probs = base_distributions.Normal(0, 1).cdf(function_samples)\n",
    "        return base_distributions.Binomial(total_count=self.m, probs=output_probs)\n",
    "\n",
    "    def log_marginal(self, observations, function_dist, *args, **kwargs):\n",
    "        marginal = self.marginal(function_dist, *args, **kwargs)\n",
    "        return marginal.log_prob(observations)\n",
    "\n",
    "    def marginal(self, function_dist, **kwargs):\n",
    "        mean = function_dist.mean\n",
    "        var = function_dist.variance\n",
    "        link = mean.div(torch.sqrt(1 + var))\n",
    "        output_probs = base_distributions.Normal(0, 1).cdf(link)\n",
    "        return base_distributions.Binomial(total_count=self.m, probs=output_probs)\n",
    "\n",
    "    def expected_log_prob(self, observations, function_dist, *params, **kwargs):\n",
    "        if torch.any(torch.logical_or(observations.le(-1), observations.ge(self.m+1))):\n",
    "            # Remove after 1.0\n",
    "            warnings.warn(\n",
    "                \"BinomialLikelihood.expected_log_prob expects observations with labels in [0, m]. \"\n",
    "                \"Observations <0 or >m are not allowed.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "        else:\n",
    "            observations = torch.clamp(observations,0,self.m)\n",
    "        # Custom function here so we can use log_normal_cdf rather than Normal.cdf\n",
    "        # This is going to be less prone to overflow errors\n",
    "        log_prob_lambda = lambda function_samples: self.m*log_normal_cdf(-function_samples) + \\\n",
    "                observations.mul(log_normal_cdf(function_samples)-log_normal_cdf(-function_samples))\n",
    "        log_prob = self.quadrature(log_prob_lambda, function_dist)\n",
    "        return log_prob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customize gp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinomialGPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super(BinomialGPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.LinearMean(input_size=inducing_points.size(1))\n",
    "        # separate kernels for covariate, geospatial and time confounding\n",
    "        self.x_covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(active_dims=[0,1,2,3], ard_num_dims=4))\n",
    "        # use a product kernel for geospatial and time confounding\n",
    "        # but in general can be replaced by a joint g and t kernel\n",
    "        self.gt_covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(active_dims=[4,5], ard_num_dims=2)*\\\n",
    "                gpytorch.kernels.RBFKernel(active_dims=[6]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        # sum over all covariances\n",
    "        covar_x = self.x_covar_module(x)\n",
    "        covar_gt = self.gt_covar_module(x)\n",
    "        covar = covar_x + covar_gt\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimize model parameters (variational locations and hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yahoo/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2189.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 47.629\n",
      "Iter 2/200 - Loss: 34.529\n",
      "Iter 3/200 - Loss: 19.723\n",
      "Iter 4/200 - Loss: 12.863\n",
      "Iter 5/200 - Loss: 11.015\n",
      "Iter 6/200 - Loss: 11.518\n",
      "Iter 7/200 - Loss: 11.726\n",
      "Iter 8/200 - Loss: 10.915\n",
      "Iter 9/200 - Loss: 9.669\n",
      "Iter 10/200 - Loss: 8.573\n",
      "Iter 11/200 - Loss: 7.903\n",
      "Iter 12/200 - Loss: 7.595\n",
      "Iter 13/200 - Loss: 7.436\n",
      "Iter 14/200 - Loss: 7.321\n",
      "Iter 15/200 - Loss: 7.219\n",
      "Iter 16/200 - Loss: 7.132\n",
      "Iter 17/200 - Loss: 7.070\n",
      "Iter 18/200 - Loss: 7.017\n",
      "Iter 19/200 - Loss: 6.973\n",
      "Iter 20/200 - Loss: 6.935\n",
      "Iter 21/200 - Loss: 6.901\n",
      "Iter 22/200 - Loss: 6.868\n",
      "Iter 23/200 - Loss: 6.844\n",
      "Iter 24/200 - Loss: 6.822\n",
      "Iter 25/200 - Loss: 6.804\n",
      "Iter 26/200 - Loss: 6.786\n",
      "Iter 27/200 - Loss: 6.770\n",
      "Iter 28/200 - Loss: 6.757\n",
      "Iter 29/200 - Loss: 6.746\n",
      "Iter 30/200 - Loss: 6.736\n",
      "Iter 31/200 - Loss: 6.727\n",
      "Iter 32/200 - Loss: 6.719\n",
      "Iter 33/200 - Loss: 6.711\n",
      "Iter 34/200 - Loss: 6.704\n",
      "Iter 35/200 - Loss: 6.698\n",
      "Iter 36/200 - Loss: 6.692\n",
      "Iter 37/200 - Loss: 6.687\n",
      "Iter 38/200 - Loss: 6.682\n",
      "Iter 39/200 - Loss: 6.678\n",
      "Iter 40/200 - Loss: 6.674\n",
      "Iter 41/200 - Loss: 6.670\n",
      "Iter 42/200 - Loss: 6.667\n",
      "Iter 43/200 - Loss: 6.664\n",
      "Iter 44/200 - Loss: 6.660\n",
      "Iter 45/200 - Loss: 6.658\n",
      "Iter 46/200 - Loss: 6.655\n",
      "Iter 47/200 - Loss: 6.652\n",
      "Iter 48/200 - Loss: 6.650\n",
      "Iter 49/200 - Loss: 6.648\n",
      "Iter 50/200 - Loss: 6.645\n",
      "Iter 51/200 - Loss: 6.643\n",
      "Iter 52/200 - Loss: 6.641\n",
      "Iter 53/200 - Loss: 6.639\n",
      "Iter 54/200 - Loss: 6.638\n",
      "Iter 55/200 - Loss: 6.636\n",
      "Iter 56/200 - Loss: 6.634\n",
      "Iter 57/200 - Loss: 6.633\n",
      "Iter 58/200 - Loss: 6.631\n",
      "Iter 59/200 - Loss: 6.630\n",
      "Iter 60/200 - Loss: 6.628\n",
      "Iter 61/200 - Loss: 6.627\n",
      "Iter 62/200 - Loss: 6.626\n",
      "Iter 63/200 - Loss: 6.624\n",
      "Iter 64/200 - Loss: 6.623\n",
      "Iter 65/200 - Loss: 6.622\n",
      "Iter 66/200 - Loss: 6.621\n",
      "Iter 67/200 - Loss: 6.620\n",
      "Iter 68/200 - Loss: 6.619\n",
      "Iter 69/200 - Loss: 6.618\n",
      "Iter 70/200 - Loss: 6.617\n",
      "Iter 71/200 - Loss: 6.616\n",
      "Iter 72/200 - Loss: 6.615\n",
      "Iter 73/200 - Loss: 6.614\n",
      "Iter 74/200 - Loss: 6.613\n",
      "Iter 75/200 - Loss: 6.612\n",
      "Iter 76/200 - Loss: 6.612\n",
      "Iter 77/200 - Loss: 6.611\n",
      "Iter 78/200 - Loss: 6.610\n",
      "Iter 79/200 - Loss: 6.609\n",
      "Iter 80/200 - Loss: 6.609\n",
      "Iter 81/200 - Loss: 6.608\n",
      "Iter 82/200 - Loss: 6.607\n",
      "Iter 83/200 - Loss: 6.607\n",
      "Iter 84/200 - Loss: 6.606\n",
      "Iter 85/200 - Loss: 6.605\n",
      "Iter 86/200 - Loss: 6.605\n",
      "Iter 87/200 - Loss: 6.604\n",
      "Iter 88/200 - Loss: 6.604\n",
      "Iter 89/200 - Loss: 6.603\n",
      "Iter 90/200 - Loss: 6.602\n",
      "Iter 91/200 - Loss: 6.602\n",
      "Iter 92/200 - Loss: 6.601\n",
      "Iter 93/200 - Loss: 6.601\n",
      "Iter 94/200 - Loss: 6.600\n",
      "Iter 95/200 - Loss: 6.600\n",
      "Iter 96/200 - Loss: 6.599\n",
      "Iter 97/200 - Loss: 6.599\n",
      "Iter 98/200 - Loss: 6.598\n",
      "Iter 99/200 - Loss: 6.598\n",
      "Iter 100/200 - Loss: 6.598\n",
      "Iter 101/200 - Loss: 6.597\n",
      "Iter 102/200 - Loss: 6.597\n",
      "Iter 103/200 - Loss: 6.596\n",
      "Iter 104/200 - Loss: 6.596\n",
      "Iter 105/200 - Loss: 6.595\n",
      "Iter 106/200 - Loss: 6.595\n",
      "Iter 107/200 - Loss: 6.595\n",
      "Iter 108/200 - Loss: 6.594\n",
      "Iter 109/200 - Loss: 6.594\n",
      "Iter 110/200 - Loss: 6.594\n",
      "Iter 111/200 - Loss: 6.593\n",
      "Iter 112/200 - Loss: 6.593\n",
      "Iter 113/200 - Loss: 6.592\n",
      "Iter 114/200 - Loss: 6.592\n",
      "Iter 115/200 - Loss: 6.592\n",
      "Iter 116/200 - Loss: 6.591\n",
      "Iter 117/200 - Loss: 6.591\n",
      "Iter 118/200 - Loss: 6.591\n",
      "Iter 119/200 - Loss: 6.590\n",
      "Iter 120/200 - Loss: 6.590\n",
      "Iter 121/200 - Loss: 6.590\n",
      "Iter 122/200 - Loss: 6.589\n",
      "Iter 123/200 - Loss: 6.589\n",
      "Iter 124/200 - Loss: 6.589\n",
      "Iter 125/200 - Loss: 6.589\n",
      "Iter 126/200 - Loss: 6.588\n",
      "Iter 127/200 - Loss: 6.588\n",
      "Iter 128/200 - Loss: 6.588\n",
      "Iter 129/200 - Loss: 6.587\n",
      "Iter 130/200 - Loss: 6.587\n",
      "Iter 131/200 - Loss: 6.587\n",
      "Iter 132/200 - Loss: 6.587\n",
      "Iter 133/200 - Loss: 6.586\n",
      "Iter 134/200 - Loss: 6.586\n",
      "Iter 135/200 - Loss: 6.586\n",
      "Iter 136/200 - Loss: 6.586\n",
      "Iter 137/200 - Loss: 6.585\n",
      "Iter 138/200 - Loss: 6.585\n",
      "Iter 139/200 - Loss: 6.585\n",
      "Iter 140/200 - Loss: 6.585\n",
      "Iter 141/200 - Loss: 6.584\n",
      "Iter 142/200 - Loss: 6.584\n",
      "Iter 143/200 - Loss: 6.584\n",
      "Iter 144/200 - Loss: 6.584\n",
      "Iter 145/200 - Loss: 6.583\n",
      "Iter 146/200 - Loss: 6.583\n",
      "Iter 147/200 - Loss: 6.583\n",
      "Iter 148/200 - Loss: 6.583\n",
      "Iter 149/200 - Loss: 6.582\n",
      "Iter 150/200 - Loss: 6.582\n",
      "Iter 151/200 - Loss: 6.582\n",
      "Iter 152/200 - Loss: 6.582\n",
      "Iter 153/200 - Loss: 6.582\n",
      "Iter 154/200 - Loss: 6.581\n",
      "Iter 155/200 - Loss: 6.581\n",
      "Iter 156/200 - Loss: 6.581\n",
      "Iter 157/200 - Loss: 6.581\n",
      "Iter 158/200 - Loss: 6.580\n",
      "Iter 159/200 - Loss: 6.580\n",
      "Iter 160/200 - Loss: 6.580\n",
      "Iter 161/200 - Loss: 6.581\n",
      "Iter 162/200 - Loss: 6.583\n",
      "Iter 163/200 - Loss: 6.589\n",
      "Iter 164/200 - Loss: 6.600\n",
      "Iter 165/200 - Loss: 6.592\n",
      "Iter 166/200 - Loss: 6.586\n",
      "Iter 167/200 - Loss: 6.587\n",
      "Iter 168/200 - Loss: 6.583\n",
      "Iter 169/200 - Loss: 6.585\n",
      "Iter 170/200 - Loss: 6.582\n",
      "Iter 171/200 - Loss: 6.582\n",
      "Iter 172/200 - Loss: 6.582\n",
      "Iter 173/200 - Loss: 6.581\n",
      "Iter 174/200 - Loss: 6.581\n",
      "Iter 175/200 - Loss: 6.580\n",
      "Iter 176/200 - Loss: 6.580\n",
      "Iter 177/200 - Loss: 6.580\n",
      "Iter 178/200 - Loss: 6.579\n",
      "Iter 179/200 - Loss: 6.579\n",
      "Iter 180/200 - Loss: 6.578\n",
      "Iter 181/200 - Loss: 6.578\n",
      "Iter 182/200 - Loss: 6.578\n",
      "Iter 183/200 - Loss: 6.577\n",
      "Iter 184/200 - Loss: 6.577\n",
      "Iter 185/200 - Loss: 6.577\n",
      "Iter 186/200 - Loss: 6.577\n",
      "Iter 187/200 - Loss: 6.576\n",
      "Iter 188/200 - Loss: 6.576\n",
      "Iter 189/200 - Loss: 6.576\n",
      "Iter 190/200 - Loss: 6.576\n",
      "Iter 191/200 - Loss: 6.575\n",
      "Iter 192/200 - Loss: 6.575\n",
      "Iter 193/200 - Loss: 6.575\n",
      "Iter 194/200 - Loss: 6.575\n",
      "Iter 195/200 - Loss: 6.575\n",
      "Iter 196/200 - Loss: 6.574\n",
      "Iter 197/200 - Loss: 6.574\n",
      "Iter 198/200 - Loss: 6.574\n",
      "Iter 199/200 - Loss: 6.574\n",
      "Iter 200/200 - Loss: 6.574\n",
      "986.6167330741882\n"
     ]
    }
   ],
   "source": [
    "# initialize likelihood and model\n",
    "likelihood = BinomialLikelihood(m=m)\n",
    "inducing_index = torch.randperm(train_x.shape[0])[:500]\n",
    "model = BinomialGPModel(inducing_points=train_x[inducing_index]).double()\n",
    "\n",
    "training_iterations = 200\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, train_y.numel())\n",
    "\n",
    "start = time.time()\n",
    "for i in range(training_iterations):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "    optimizer.step()\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0 min 26.616733074188232 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"{} min {} sec\".format((end-start)//60, (end-start)%60))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize estimated expected response for the first respondent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # plot the estimated latent f for first respondent\n",
    "    test_x = train_x[0:T,:]\n",
    "    # Get classification predictions\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Initialize fig and axes for plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    ax.plot(test_x[:,6].numpy(), train_y[0:T].numpy(), 'k*')\n",
    "    # Get the predicted labels\n",
    "    pred_labels = observed_pred.mean.float()\n",
    "    ax.plot(test_x[0:T,6].numpy(), pred_labels.numpy(), 'b')\n",
    "    ax.legend(['Observed Data', 'Expected Responses'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize estimated expected response for a virtual respondent with x_1=x_2=x_3=x_4=0 with the same geo locations as the first respondent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # plot the estimated latent f for first respondent\n",
    "    test_x = train_x[0:T,:]\n",
    "    test_x[:,0:4] = 0\n",
    "    # Get classification predictions\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Initialize fig and axes for plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    true_f = t_effects * g_effects[0]\n",
    "    true_f = (true_f - f_min) / (f_max - f_min)\n",
    "    true_f = torch.clamp(torch.tensor(true_f), 0, 1)\n",
    "    ax.plot(test_x[:,6].numpy(), true_f.numpy()*m, 'k*')\n",
    "    # Get the predicted labels\n",
    "    pred_labels = observed_pred.mean.float()\n",
    "    ax.plot(test_x[0:T,6].numpy(), pred_labels.numpy(), 'b')\n",
    "    ax.legend(['True Expected Responses', 'Estimated Expected Responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
