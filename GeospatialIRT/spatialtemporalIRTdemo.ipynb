{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration of dynamic Gaussian Process Item Response Theory\n",
    "with spactial-temporal relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PACKAGES\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import matplotlib.pyplot as plt\n",
    "from binomial_likelihood import BinomialLikelihood\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "import torch\n",
    "import gpytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "background characteristics: x_i ~ N(0,1), i=1,2,3,4\n",
    "\n",
    "normalized geospatial locations: g_1 ~ Unif(0,1), g_2 ~ Unif(0,1)\n",
    "\n",
    "geospatial correlated noise: g_effect ~ N(0, K), K_{ij} = exp(-(g_i-g_j)^2/2)\n",
    "\n",
    "temporal correlated noise: t_effect ~ N(0,K), K_t = exp(-(t-t')^2/2) \n",
    "\n",
    "temporal normalized latent policy positions: sigma_i = x_1^2 + x_2 + x_1*x_2 + cos(x3) - x_4^3 + t_effect * g_effect(i)\n",
    "\n",
    "response model: y ~ binom(sigma_i,m), y=1,...,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500; # num of respondents\n",
    "T = 20; # num of time periods\n",
    "m = 10; # num of items in the battery\n",
    "np.random.seed(12345)\n",
    "x = np.zeros((n*T,4+2+1))\n",
    "y = np.zeros((n*T,))\n",
    "\n",
    "# background characteristics: x_i \n",
    "for i in range(4):\n",
    "    x[:,i] = np.repeat(np.random.normal(loc=0.0, scale=1.0, size=(n,)),T)\n",
    "\n",
    "# normalized geospatial locations: g_1 ~ Unif(0,1), g_2 ~ Unif(0,1)\n",
    "g = np.random.uniform(low=0.0, high=1.0, size=(n,2))\n",
    "x[:,4] = np.repeat(g[:,0],T)\n",
    "x[:,5] = np.repeat(g[:,1],T)\n",
    "\n",
    "# geospatial correlated noise: sigma(t) ~ N(0, K), K_{ij} = exp(-(g_i-g_j)^2/2), K_t = exp(-(t-t')^2/2) \n",
    "kernel = RBF(length_scale = 1.0)\n",
    "# K = np.kron(kernel(g*2),kernel(np.arange(T).reshape(-1,1)/T*3))\n",
    "K = kernel(g*2)\n",
    "x[:,6] = np.tile(np.arange(T),n)\n",
    "g_effects = np.random.multivariate_normal(np.zeros((n,)), K)\n",
    "\n",
    "K = kernel(np.arange(T).reshape(-1,1)/T*3)\n",
    "t_effects = np.random.multivariate_normal(np.zeros((T,)), K)\n",
    "\n",
    "# normalized latent policy positions: \n",
    "f = x[:,0]**2 + x[:,1] + x[:,0]*x[:,1] + np.cos(x[:,2]) - x[:,3]**3\n",
    "for t in range(T):\n",
    "    f[x[:,6]==t] = t_effects[t]*g_effects\n",
    "f_min = np.min(f)\n",
    "f_max = np.max(f)\n",
    "f = (f-f_min) / (f_max - f_min)\n",
    "\n",
    "# response model: y ~ binom(sigma_i,m), y=1,...,m\n",
    "for i in range(n*T):\n",
    "    y[i] = np.random.binomial(m,f[i])\n",
    "\n",
    "train_x = torch.from_numpy(x).double()\n",
    "train_y = torch.from_numpy(y).double()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customize binomial likelihood model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.distributions import base_distributions\n",
    "from gpytorch.functions import log_normal_cdf\n",
    "from gpytorch.likelihoods.likelihood import _OneDimensionalLikelihood\n",
    "\n",
    "class BinomialLikelihood(_OneDimensionalLikelihood):\n",
    "    r\"\"\"\n",
    "    Implements the Binomial likelihood for count data y between 1 and m. \n",
    "    The Binomial distribution is parameterized by :math:`m > 0`. \n",
    "    We can write the likelihood as:\n",
    "\n",
    "    .. math::\n",
    "        \\begin{equation*}\n",
    "            p(Y=y|f,m)=\\phi(f)^y(1-\\phi(f))^{(m-y)}\n",
    "        \\end{equation*}\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,m):\n",
    "        super().__init__()\n",
    "        if m<0 or int(m)!=m:\n",
    "            self.m = 10\n",
    "            print(\"m must be a positive integer!\")\n",
    "        else:\n",
    "            self.m = m\n",
    "\n",
    "    def forward(self, function_samples, **kwargs):\n",
    "        output_probs = base_distributions.Normal(0, 1).cdf(function_samples)\n",
    "        return base_distributions.Binomial(total_count=self.m, probs=output_probs)\n",
    "\n",
    "    def log_marginal(self, observations, function_dist, *args, **kwargs):\n",
    "        marginal = self.marginal(function_dist, *args, **kwargs)\n",
    "        return marginal.log_prob(observations)\n",
    "\n",
    "    def marginal(self, function_dist, **kwargs):\n",
    "        mean = function_dist.mean\n",
    "        var = function_dist.variance\n",
    "        link = mean.div(torch.sqrt(1 + var))\n",
    "        output_probs = base_distributions.Normal(0, 1).cdf(link)\n",
    "        return base_distributions.Binomial(total_count=self.m, probs=output_probs)\n",
    "\n",
    "    def expected_log_prob(self, observations, function_dist, *params, **kwargs):\n",
    "        if torch.any(torch.logical_or(observations.le(-1), observations.ge(self.m+1))):\n",
    "            # Remove after 1.0\n",
    "            warnings.warn(\n",
    "                \"BinomialLikelihood.expected_log_prob expects observations with labels in [0, m]. \"\n",
    "                \"Observations <0 or >m are not allowed.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "        else:\n",
    "            observations = torch.clamp(observations,0,self.m)\n",
    "        # Custom function here so we can use log_normal_cdf rather than Normal.cdf\n",
    "        # This is going to be less prone to overflow errors\n",
    "        log_prob_lambda = lambda function_samples: self.m*log_normal_cdf(-function_samples) + \\\n",
    "                observations.mul(log_normal_cdf(function_samples)-log_normal_cdf(-function_samples))\n",
    "        log_prob = self.quadrature(log_prob_lambda, function_dist)\n",
    "        return log_prob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customize gp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinomialGPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super(BinomialGPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.LinearMean(input_size=inducing_points.size(1))\n",
    "        # separate kernels for covariate, geospatial and time confounding\n",
    "        self.x_covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(active_dims=[0,1,2,3], ard_num_dims=4))\n",
    "        # use a product kernel for geospatial and time confounding\n",
    "        # but in general can be replaced by a joint g and t kernel\n",
    "        self.gt_covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(active_dims=[4,5], ard_num_dims=2)*\\\n",
    "                gpytorch.kernels.RBFKernel(active_dims=[6]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        # sum over all covariances\n",
    "        covar_x = self.x_covar_module(x)\n",
    "        covar_gt = self.gt_covar_module(x)\n",
    "        covar = covar_x + covar_gt\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimize model parameters (variational locations and hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 35.921\n",
      "Iter 2/200 - Loss: 25.180\n",
      "Iter 3/200 - Loss: 17.965\n",
      "Iter 4/200 - Loss: 17.979\n",
      "Iter 5/200 - Loss: 15.753\n",
      "Iter 6/200 - Loss: 11.948\n",
      "Iter 7/200 - Loss: 9.423\n",
      "Iter 8/200 - Loss: 8.874\n",
      "Iter 9/200 - Loss: 8.902\n",
      "Iter 10/200 - Loss: 8.504\n",
      "Iter 11/200 - Loss: 7.949\n",
      "Iter 12/200 - Loss: 7.598\n",
      "Iter 13/200 - Loss: 7.475\n",
      "Iter 14/200 - Loss: 7.391\n",
      "Iter 15/200 - Loss: 7.261\n",
      "Iter 16/200 - Loss: 7.120\n",
      "Iter 17/200 - Loss: 7.012\n",
      "Iter 18/200 - Loss: 6.938\n",
      "Iter 19/200 - Loss: 6.870\n",
      "Iter 20/200 - Loss: 6.805\n",
      "Iter 21/200 - Loss: 6.753\n",
      "Iter 22/200 - Loss: 6.707\n",
      "Iter 23/200 - Loss: 6.664\n",
      "Iter 24/200 - Loss: 6.624\n",
      "Iter 25/200 - Loss: 6.589\n",
      "Iter 26/200 - Loss: 6.557\n",
      "Iter 27/200 - Loss: 6.526\n",
      "Iter 28/200 - Loss: 6.501\n",
      "Iter 29/200 - Loss: 6.482\n",
      "Iter 30/200 - Loss: 6.463\n",
      "Iter 31/200 - Loss: 6.445\n",
      "Iter 32/200 - Loss: 6.428\n",
      "Iter 33/200 - Loss: 6.414\n",
      "Iter 34/200 - Loss: 6.402\n",
      "Iter 35/200 - Loss: 6.390\n",
      "Iter 36/200 - Loss: 6.379\n",
      "Iter 37/200 - Loss: 6.370\n",
      "Iter 38/200 - Loss: 6.362\n",
      "Iter 39/200 - Loss: 6.353\n",
      "Iter 40/200 - Loss: 6.346\n",
      "Iter 41/200 - Loss: 6.339\n",
      "Iter 42/200 - Loss: 6.332\n",
      "Iter 43/200 - Loss: 6.326\n",
      "Iter 44/200 - Loss: 6.321\n",
      "Iter 45/200 - Loss: 6.317\n",
      "Iter 46/200 - Loss: 6.312\n",
      "Iter 47/200 - Loss: 6.308\n",
      "Iter 48/200 - Loss: 6.304\n",
      "Iter 49/200 - Loss: 6.301\n",
      "Iter 50/200 - Loss: 6.297\n",
      "Iter 51/200 - Loss: 6.294\n",
      "Iter 52/200 - Loss: 6.291\n",
      "Iter 53/200 - Loss: 6.289\n",
      "Iter 54/200 - Loss: 6.286\n",
      "Iter 55/200 - Loss: 6.284\n",
      "Iter 56/200 - Loss: 6.282\n",
      "Iter 57/200 - Loss: 6.280\n",
      "Iter 58/200 - Loss: 6.278\n",
      "Iter 59/200 - Loss: 6.276\n",
      "Iter 60/200 - Loss: 6.275\n",
      "Iter 61/200 - Loss: 6.273\n",
      "Iter 62/200 - Loss: 6.272\n",
      "Iter 63/200 - Loss: 6.271\n",
      "Iter 64/200 - Loss: 6.270\n",
      "Iter 65/200 - Loss: 6.269\n",
      "Iter 66/200 - Loss: 6.268\n",
      "Iter 67/200 - Loss: 6.267\n",
      "Iter 68/200 - Loss: 6.266\n",
      "Iter 69/200 - Loss: 6.265\n",
      "Iter 70/200 - Loss: 6.264\n",
      "Iter 71/200 - Loss: 6.263\n",
      "Iter 72/200 - Loss: 6.262\n",
      "Iter 73/200 - Loss: 6.262\n",
      "Iter 74/200 - Loss: 6.261\n",
      "Iter 75/200 - Loss: 6.260\n",
      "Iter 76/200 - Loss: 6.260\n",
      "Iter 77/200 - Loss: 6.259\n",
      "Iter 78/200 - Loss: 6.259\n",
      "Iter 79/200 - Loss: 6.258\n",
      "Iter 80/200 - Loss: 6.258\n",
      "Iter 81/200 - Loss: 6.257\n",
      "Iter 82/200 - Loss: 6.257\n",
      "Iter 83/200 - Loss: 6.256\n",
      "Iter 84/200 - Loss: 6.256\n",
      "Iter 85/200 - Loss: 6.256\n",
      "Iter 86/200 - Loss: 6.255\n",
      "Iter 87/200 - Loss: 6.255\n",
      "Iter 88/200 - Loss: 6.255\n",
      "Iter 89/200 - Loss: 6.254\n",
      "Iter 90/200 - Loss: 6.254\n",
      "Iter 91/200 - Loss: 6.254\n",
      "Iter 92/200 - Loss: 6.253\n",
      "Iter 93/200 - Loss: 6.253\n",
      "Iter 94/200 - Loss: 6.253\n",
      "Iter 95/200 - Loss: 6.252\n",
      "Iter 96/200 - Loss: 6.252\n",
      "Iter 97/200 - Loss: 6.252\n",
      "Iter 98/200 - Loss: 6.252\n",
      "Iter 99/200 - Loss: 6.251\n",
      "Iter 100/200 - Loss: 6.251\n",
      "Iter 101/200 - Loss: 6.251\n",
      "Iter 102/200 - Loss: 6.251\n",
      "Iter 103/200 - Loss: 6.250\n",
      "Iter 104/200 - Loss: 6.250\n",
      "Iter 105/200 - Loss: 6.250\n",
      "Iter 106/200 - Loss: 6.250\n",
      "Iter 107/200 - Loss: 6.249\n",
      "Iter 108/200 - Loss: 6.249\n",
      "Iter 109/200 - Loss: 6.249\n",
      "Iter 110/200 - Loss: 6.249\n",
      "Iter 111/200 - Loss: 6.249\n",
      "Iter 112/200 - Loss: 6.248\n",
      "Iter 113/200 - Loss: 6.248\n",
      "Iter 114/200 - Loss: 6.248\n",
      "Iter 115/200 - Loss: 6.248\n",
      "Iter 116/200 - Loss: 6.248\n",
      "Iter 117/200 - Loss: 6.248\n",
      "Iter 118/200 - Loss: 6.247\n",
      "Iter 119/200 - Loss: 6.247\n",
      "Iter 120/200 - Loss: 6.247\n",
      "Iter 121/200 - Loss: 6.247\n",
      "Iter 122/200 - Loss: 6.247\n",
      "Iter 123/200 - Loss: 6.246\n",
      "Iter 124/200 - Loss: 6.246\n",
      "Iter 125/200 - Loss: 6.246\n",
      "Iter 126/200 - Loss: 6.246\n",
      "Iter 127/200 - Loss: 6.246\n",
      "Iter 128/200 - Loss: 6.246\n",
      "Iter 129/200 - Loss: 6.246\n",
      "Iter 130/200 - Loss: 6.245\n",
      "Iter 131/200 - Loss: 6.245\n",
      "Iter 132/200 - Loss: 6.245\n",
      "Iter 133/200 - Loss: 6.245\n",
      "Iter 134/200 - Loss: 6.245\n",
      "Iter 135/200 - Loss: 6.245\n",
      "Iter 136/200 - Loss: 6.244\n",
      "Iter 137/200 - Loss: 6.244\n",
      "Iter 138/200 - Loss: 6.244\n",
      "Iter 139/200 - Loss: 6.244\n",
      "Iter 140/200 - Loss: 6.244\n",
      "Iter 141/200 - Loss: 6.244\n",
      "Iter 142/200 - Loss: 6.244\n",
      "Iter 143/200 - Loss: 6.243\n",
      "Iter 144/200 - Loss: 6.243\n",
      "Iter 145/200 - Loss: 6.243\n",
      "Iter 146/200 - Loss: 6.243\n",
      "Iter 147/200 - Loss: 6.243\n",
      "Iter 148/200 - Loss: 6.243\n",
      "Iter 149/200 - Loss: 6.243\n",
      "Iter 150/200 - Loss: 6.242\n",
      "Iter 151/200 - Loss: 6.242\n",
      "Iter 152/200 - Loss: 6.242\n",
      "Iter 153/200 - Loss: 6.242\n",
      "Iter 154/200 - Loss: 6.242\n",
      "Iter 155/200 - Loss: 6.242\n",
      "Iter 156/200 - Loss: 6.242\n",
      "Iter 157/200 - Loss: 6.242\n",
      "Iter 158/200 - Loss: 6.241\n",
      "Iter 159/200 - Loss: 6.241\n",
      "Iter 160/200 - Loss: 6.241\n",
      "Iter 161/200 - Loss: 6.241\n",
      "Iter 162/200 - Loss: 6.241\n",
      "Iter 163/200 - Loss: 6.241\n",
      "Iter 164/200 - Loss: 6.241\n",
      "Iter 165/200 - Loss: 6.241\n",
      "Iter 166/200 - Loss: 6.240\n",
      "Iter 167/200 - Loss: 6.240\n",
      "Iter 168/200 - Loss: 6.240\n",
      "Iter 169/200 - Loss: 6.240\n",
      "Iter 170/200 - Loss: 6.240\n",
      "Iter 171/200 - Loss: 6.240\n",
      "Iter 172/200 - Loss: 6.240\n",
      "Iter 173/200 - Loss: 6.240\n",
      "Iter 174/200 - Loss: 6.239\n",
      "Iter 175/200 - Loss: 6.239\n",
      "Iter 176/200 - Loss: 6.239\n",
      "Iter 177/200 - Loss: 6.239\n",
      "Iter 178/200 - Loss: 6.239\n",
      "Iter 179/200 - Loss: 6.239\n",
      "Iter 180/200 - Loss: 6.239\n",
      "Iter 181/200 - Loss: 6.239\n",
      "Iter 182/200 - Loss: 6.239\n",
      "Iter 183/200 - Loss: 6.238\n",
      "Iter 184/200 - Loss: 6.238\n",
      "Iter 185/200 - Loss: 6.238\n",
      "Iter 186/200 - Loss: 6.238\n",
      "Iter 187/200 - Loss: 6.238\n",
      "Iter 188/200 - Loss: 6.238\n",
      "Iter 189/200 - Loss: 6.238\n",
      "Iter 190/200 - Loss: 6.238\n",
      "Iter 191/200 - Loss: 6.238\n",
      "Iter 192/200 - Loss: 6.237\n",
      "Iter 193/200 - Loss: 6.237\n",
      "Iter 194/200 - Loss: 6.237\n",
      "Iter 195/200 - Loss: 6.237\n",
      "Iter 196/200 - Loss: 6.238\n",
      "Iter 197/200 - Loss: 6.239\n",
      "Iter 198/200 - Loss: 6.246\n",
      "Iter 199/200 - Loss: 6.245\n",
      "Iter 200/200 - Loss: 6.240\n"
     ]
    }
   ],
   "source": [
    "# initialize likelihood and model\n",
    "likelihood = BinomialLikelihood(m=m)\n",
    "inducing_index = torch.randperm(train_x.shape[0])[:500]\n",
    "model = BinomialGPModel(inducing_points=train_x[inducing_index]).double()\n",
    "\n",
    "training_iterations = 200\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, train_y.numel())\n",
    "\n",
    "for i in range(training_iterations):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize estimated expected response for the first respondent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # plot the estimated latent f for first respondent\n",
    "    test_x = train_x[0:T,:]\n",
    "    # Get classification predictions\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Initialize fig and axes for plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    ax.plot(test_x[:,6].numpy(), train_y[0:T].numpy(), 'k*')\n",
    "    # Get the predicted labels\n",
    "    pred_labels = observed_pred.mean.float()\n",
    "    ax.plot(test_x[0:T,6].numpy(), pred_labels.numpy(), 'b')\n",
    "    ax.legend(['Observed Data', 'Expected Responses'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize estimated expected response for a virtual respondent with x_1=x_2=x_3=x_4=0 with the same geo locations as the first respondent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # plot the estimated latent f for first respondent\n",
    "    test_x = train_x[0:T,:]\n",
    "    test_x[:,0:4] = 0\n",
    "    # Get classification predictions\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Initialize fig and axes for plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    true_f = t_effects * g_effects[0]\n",
    "    true_f = (true_f - f_min) / (f_max - f_min)\n",
    "    true_f = torch.clamp(torch.tensor(true_f), 0, 1)\n",
    "    ax.plot(test_x[:,6].numpy(), true_f.numpy()*m, 'k*')\n",
    "    # Get the predicted labels\n",
    "    pred_labels = observed_pred.mean.float()\n",
    "    ax.plot(test_x[0:T,6].numpy(), pred_labels.numpy(), 'b')\n",
    "    ax.legend(['True Expected Responses', 'Estimated Expected Responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
