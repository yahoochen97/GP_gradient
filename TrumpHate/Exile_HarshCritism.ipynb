{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exile on Online Opposition\n",
    "\n",
    "Examine the effect of exile on percentage of tweets' harsh criticism of Venezuela government.\n",
    "\n",
    "ESBERG, J., & SIEGEL, A. (2023). How Exile Shapes Online Opposition: Evidence from Venezuela. American Political Science Review, 117(4), 1361-1378."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb4093f7570>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load gpytoch and other packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gpytorch\n",
    "from scipy.stats import norm\n",
    "from matplotlib import pyplot as plt\n",
    "from gpytorch.means import ZeroMean, LinearMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from datetime import datetime\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we first implement GPR for right panel of figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"./data/exile.csv\")\n",
    "data = data[[\"perc_harsh_criticism\", \"lead_lags\",\"month\",\"num_tweets\", \"exile\", \"date_of_exile\", \"actor.id\"]]\n",
    "data = data[~data.lead_lags.isna()]\n",
    "\n",
    "def diff_month(d1, d2):\n",
    "    d1 = datetime.strptime(d1,\"%Y-%m-%d\")\n",
    "    d2 = datetime.strptime(d2,\"%Y-%m-%d\")\n",
    "    return (d1.year - d2.year) * 12 + d1.month - d2.month\n",
    "\n",
    "# xs: unit id, month, log_num_tweets, dummies for lead_lags\n",
    "xs = data.month.apply(lambda x: diff_month(x,\"2013-01-01\"))\n",
    "xs = torch.tensor(np.hstack((data[\"actor.id\"].astype('category').cat.codes.values.reshape((-1,1)),\\\n",
    "                    xs.values.reshape((-1,1)),\n",
    "                    np.log(data.num_tweets.values+1).reshape((-1,1)), \\\n",
    "                    pd.get_dummies(data['lead_lags']).values))).double()\n",
    "\n",
    "ys = torch.tensor(data.perc_harsh_criticism.values).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we build a Gaussian process regression model with a linear mean function and an automatic relevance determination RBF kernel:\n",
    "$$\n",
    "f(t,D) \\sim\\mathcal{GP}(\\beta x,K)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.means import Mean\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "\n",
    "class ConstantVectorMean(Mean):\n",
    "    def __init__(self, n, prior=None, batch_shape=torch.Size(), **kwargs):\n",
    "        super().__init__()\n",
    "        self.batch_shape = batch_shape\n",
    "        self.register_parameter(name=\"constantvector\",\\\n",
    "                 parameter=torch.nn.Parameter(torch.zeros(*batch_shape, n)))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.constantvector[input.long()]\n",
    "\n",
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=False)\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        # linear mean\n",
    "        self.mean_module = LinearMean(input_size=(inducing_points.size(1)-2), bias=False)\n",
    "        self.covar_module = ScaleKernel(RBFKernel(ard_num_dims=(inducing_points.size(1)-2)))\n",
    "        # self.t_covar_module = ScaleKernel(RBFKernel(active_dims=[0])*RBFKernel(active_dims=[1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x[:,2:])\n",
    "        covar_x = self.covar_module(x[:,2:]) # + self.t_covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iter 2 - Loss: 180.029\n",
      "Epoch 1 Iter 3 - Loss: 136.734\n",
      "Epoch 1 Iter 4 - Loss: 139.053\n",
      "Epoch 1 Iter 5 - Loss: 126.825\n",
      "Epoch 1 Iter 6 - Loss: 114.277\n",
      "Epoch 1 Iter 7 - Loss: 111.970\n",
      "Epoch 1 Iter 8 - Loss: 87.447\n",
      "Epoch 1 Iter 9 - Loss: 67.979\n",
      "Epoch 1 Iter 10 - Loss: 77.062\n",
      "Epoch 1 Iter 11 - Loss: 58.602\n",
      "Epoch 1 Iter 12 - Loss: 84.486\n",
      "Epoch 1 Iter 13 - Loss: 70.617\n",
      "Epoch 1 Iter 14 - Loss: 74.991\n",
      "Epoch 1 Iter 15 - Loss: 73.096\n",
      "Epoch 1 Iter 16 - Loss: 46.800\n",
      "Epoch 1 Iter 17 - Loss: 57.567\n",
      "Epoch 1 Iter 18 - Loss: 51.942\n",
      "Epoch 1 Iter 19 - Loss: 46.602\n",
      "Epoch 1 Iter 20 - Loss: 54.956\n",
      "Epoch 1 Iter 21 - Loss: 59.328\n",
      "Epoch 1 Iter 22 - Loss: 44.144\n",
      "Epoch 1 Iter 23 - Loss: 51.195\n",
      "Epoch 1 Iter 24 - Loss: 40.872\n",
      "Epoch 1 Iter 25 - Loss: 40.873\n",
      "Epoch 1 Iter 26 - Loss: 47.213\n",
      "Epoch 1 Iter 27 - Loss: 57.237\n",
      "Epoch 1 Iter 28 - Loss: 40.318\n",
      "Epoch 1 Iter 29 - Loss: 38.865\n",
      "Epoch 1 Iter 30 - Loss: 47.797\n",
      "Epoch 1 Iter 31 - Loss: 40.868\n",
      "Epoch 1 Iter 32 - Loss: 43.676\n",
      "Epoch 1 Iter 33 - Loss: 34.851\n",
      "Epoch 1 Iter 34 - Loss: 32.693\n",
      "Epoch 1 Iter 35 - Loss: 41.079\n",
      "Epoch 1 Iter 36 - Loss: 35.384\n",
      "Epoch 1 Iter 37 - Loss: 43.547\n",
      "Epoch 1 Iter 38 - Loss: 30.170\n",
      "Epoch 1 Iter 39 - Loss: 36.105\n",
      "Epoch 1 Iter 40 - Loss: 36.288\n",
      "Epoch 1 Iter 41 - Loss: 39.644\n",
      "Epoch 1 Iter 42 - Loss: 32.400\n",
      "Epoch 1 Iter 43 - Loss: 31.976\n",
      "Epoch 1 Iter 44 - Loss: 32.477\n",
      "Epoch 1 Iter 45 - Loss: 38.138\n",
      "Epoch 2 Iter 2 - Loss: 38.343\n",
      "Epoch 2 Iter 3 - Loss: 30.858\n",
      "Epoch 2 Iter 4 - Loss: 30.742\n",
      "Epoch 2 Iter 5 - Loss: 33.535\n",
      "Epoch 2 Iter 6 - Loss: 33.003\n",
      "Epoch 2 Iter 7 - Loss: 25.018\n",
      "Epoch 2 Iter 8 - Loss: 25.313\n",
      "Epoch 2 Iter 9 - Loss: 29.435\n",
      "Epoch 2 Iter 10 - Loss: 31.995\n",
      "Epoch 2 Iter 11 - Loss: 27.728\n",
      "Epoch 2 Iter 12 - Loss: 27.855\n",
      "Epoch 2 Iter 13 - Loss: 43.413\n",
      "Epoch 2 Iter 14 - Loss: 30.117\n",
      "Epoch 2 Iter 15 - Loss: 26.892\n",
      "Epoch 2 Iter 16 - Loss: 27.517\n",
      "Epoch 2 Iter 17 - Loss: 22.112\n",
      "Epoch 2 Iter 18 - Loss: 29.363\n",
      "Epoch 2 Iter 19 - Loss: 28.712\n",
      "Epoch 2 Iter 20 - Loss: 29.422\n",
      "Epoch 2 Iter 21 - Loss: 25.707\n",
      "Epoch 2 Iter 22 - Loss: 23.739\n",
      "Epoch 2 Iter 23 - Loss: 21.200\n",
      "Epoch 2 Iter 24 - Loss: 33.726\n",
      "Epoch 2 Iter 25 - Loss: 27.489\n",
      "Epoch 2 Iter 26 - Loss: 22.623\n",
      "Epoch 2 Iter 27 - Loss: 25.825\n",
      "Epoch 2 Iter 28 - Loss: 23.773\n",
      "Epoch 2 Iter 29 - Loss: 33.570\n",
      "Epoch 2 Iter 30 - Loss: 27.019\n",
      "Epoch 2 Iter 31 - Loss: 27.421\n",
      "Epoch 2 Iter 32 - Loss: 34.869\n",
      "Epoch 2 Iter 33 - Loss: 26.112\n",
      "Epoch 2 Iter 34 - Loss: 28.844\n",
      "Epoch 2 Iter 35 - Loss: 30.822\n",
      "Epoch 2 Iter 36 - Loss: 28.043\n",
      "Epoch 2 Iter 37 - Loss: 29.035\n",
      "Epoch 2 Iter 38 - Loss: 28.936\n",
      "Epoch 2 Iter 39 - Loss: 19.684\n",
      "Epoch 2 Iter 40 - Loss: 27.108\n",
      "Epoch 2 Iter 41 - Loss: 27.303\n",
      "Epoch 2 Iter 42 - Loss: 24.990\n",
      "Epoch 2 Iter 43 - Loss: 22.563\n",
      "Epoch 2 Iter 44 - Loss: 27.345\n",
      "Epoch 2 Iter 45 - Loss: 36.373\n",
      "Epoch 3 Iter 2 - Loss: 27.631\n",
      "Epoch 3 Iter 3 - Loss: 22.020\n",
      "Epoch 3 Iter 4 - Loss: 24.374\n",
      "Epoch 3 Iter 5 - Loss: 28.563\n",
      "Epoch 3 Iter 6 - Loss: 26.904\n",
      "Epoch 3 Iter 7 - Loss: 26.703\n",
      "Epoch 3 Iter 8 - Loss: 24.217\n",
      "Epoch 3 Iter 9 - Loss: 24.158\n",
      "Epoch 3 Iter 10 - Loss: 23.370\n",
      "Epoch 3 Iter 11 - Loss: 21.119\n",
      "Epoch 3 Iter 12 - Loss: 21.769\n",
      "Epoch 3 Iter 13 - Loss: 20.262\n",
      "Epoch 3 Iter 14 - Loss: 19.057\n",
      "Epoch 3 Iter 15 - Loss: 25.605\n",
      "Epoch 3 Iter 16 - Loss: 21.460\n",
      "Epoch 3 Iter 17 - Loss: 26.599\n",
      "Epoch 3 Iter 18 - Loss: 22.678\n",
      "Epoch 3 Iter 19 - Loss: 24.342\n",
      "Epoch 3 Iter 20 - Loss: 31.303\n",
      "Epoch 3 Iter 21 - Loss: 24.129\n",
      "Epoch 3 Iter 22 - Loss: 23.345\n",
      "Epoch 3 Iter 23 - Loss: 25.516\n",
      "Epoch 3 Iter 24 - Loss: 24.012\n",
      "Epoch 3 Iter 25 - Loss: 19.328\n",
      "Epoch 3 Iter 26 - Loss: 22.626\n",
      "Epoch 3 Iter 27 - Loss: 24.602\n",
      "Epoch 3 Iter 28 - Loss: 22.429\n",
      "Epoch 3 Iter 29 - Loss: 18.212\n",
      "Epoch 3 Iter 30 - Loss: 24.514\n",
      "Epoch 3 Iter 31 - Loss: 27.550\n",
      "Epoch 3 Iter 32 - Loss: 21.124\n",
      "Epoch 3 Iter 33 - Loss: 17.392\n",
      "Epoch 3 Iter 34 - Loss: 21.245\n",
      "Epoch 3 Iter 35 - Loss: 19.064\n",
      "Epoch 3 Iter 36 - Loss: 18.185\n",
      "Epoch 3 Iter 37 - Loss: 21.964\n",
      "Epoch 3 Iter 38 - Loss: 18.953\n",
      "Epoch 3 Iter 39 - Loss: 19.318\n",
      "Epoch 3 Iter 40 - Loss: 23.070\n",
      "Epoch 3 Iter 41 - Loss: 23.273\n",
      "Epoch 3 Iter 42 - Loss: 20.675\n",
      "Epoch 3 Iter 43 - Loss: 19.546\n",
      "Epoch 3 Iter 44 - Loss: 18.570\n",
      "Epoch 3 Iter 45 - Loss: 16.694\n",
      "Epoch 4 Iter 2 - Loss: 22.220\n",
      "Epoch 4 Iter 3 - Loss: 17.214\n",
      "Epoch 4 Iter 4 - Loss: 19.950\n",
      "Epoch 4 Iter 5 - Loss: 20.700\n",
      "Epoch 4 Iter 6 - Loss: 20.945\n",
      "Epoch 4 Iter 7 - Loss: 23.887\n",
      "Epoch 4 Iter 8 - Loss: 19.139\n",
      "Epoch 4 Iter 9 - Loss: 21.855\n",
      "Epoch 4 Iter 10 - Loss: 18.879\n",
      "Epoch 4 Iter 11 - Loss: 18.192\n",
      "Epoch 4 Iter 12 - Loss: 21.996\n",
      "Epoch 4 Iter 13 - Loss: 20.119\n",
      "Epoch 4 Iter 14 - Loss: 21.639\n",
      "Epoch 4 Iter 15 - Loss: 17.727\n",
      "Epoch 4 Iter 16 - Loss: 16.847\n",
      "Epoch 4 Iter 17 - Loss: 18.657\n",
      "Epoch 4 Iter 18 - Loss: 21.482\n",
      "Epoch 4 Iter 19 - Loss: 17.838\n",
      "Epoch 4 Iter 20 - Loss: 22.143\n",
      "Epoch 4 Iter 21 - Loss: 17.600\n",
      "Epoch 4 Iter 22 - Loss: 22.198\n",
      "Epoch 4 Iter 23 - Loss: 18.832\n",
      "Epoch 4 Iter 24 - Loss: 20.134\n",
      "Epoch 4 Iter 25 - Loss: 19.952\n",
      "Epoch 4 Iter 26 - Loss: 20.511\n",
      "Epoch 4 Iter 27 - Loss: 17.892\n",
      "Epoch 4 Iter 28 - Loss: 19.975\n",
      "Epoch 4 Iter 29 - Loss: 19.519\n",
      "Epoch 4 Iter 30 - Loss: 17.169\n",
      "Epoch 4 Iter 31 - Loss: 22.493\n",
      "Epoch 4 Iter 32 - Loss: 26.298\n",
      "Epoch 4 Iter 33 - Loss: 22.757\n",
      "Epoch 4 Iter 34 - Loss: 19.150\n",
      "Epoch 4 Iter 35 - Loss: 21.326\n",
      "Epoch 4 Iter 36 - Loss: 18.668\n",
      "Epoch 4 Iter 37 - Loss: 18.798\n",
      "Epoch 4 Iter 38 - Loss: 16.611\n",
      "Epoch 4 Iter 39 - Loss: 17.301\n",
      "Epoch 4 Iter 40 - Loss: 20.020\n",
      "Epoch 4 Iter 41 - Loss: 16.874\n",
      "Epoch 4 Iter 42 - Loss: 15.684\n",
      "Epoch 4 Iter 43 - Loss: 18.554\n",
      "Epoch 4 Iter 44 - Loss: 20.146\n",
      "Epoch 4 Iter 45 - Loss: 14.660\n",
      "Epoch 5 Iter 2 - Loss: 16.819\n",
      "Epoch 5 Iter 3 - Loss: 21.833\n",
      "Epoch 5 Iter 4 - Loss: 22.139\n",
      "Epoch 5 Iter 5 - Loss: 21.697\n",
      "Epoch 5 Iter 6 - Loss: 15.746\n",
      "Epoch 5 Iter 7 - Loss: 22.682\n",
      "Epoch 5 Iter 8 - Loss: 15.987\n",
      "Epoch 5 Iter 9 - Loss: 17.903\n",
      "Epoch 5 Iter 10 - Loss: 17.648\n",
      "Epoch 5 Iter 11 - Loss: 23.773\n",
      "Epoch 5 Iter 12 - Loss: 20.873\n",
      "Epoch 5 Iter 13 - Loss: 17.954\n",
      "Epoch 5 Iter 14 - Loss: 19.035\n",
      "Epoch 5 Iter 15 - Loss: 20.537\n",
      "Epoch 5 Iter 16 - Loss: 19.823\n",
      "Epoch 5 Iter 17 - Loss: 15.870\n",
      "Epoch 5 Iter 18 - Loss: 18.105\n",
      "Epoch 5 Iter 19 - Loss: 17.668\n",
      "Epoch 5 Iter 20 - Loss: 19.415\n",
      "Epoch 5 Iter 21 - Loss: 19.184\n",
      "Epoch 5 Iter 22 - Loss: 17.325\n",
      "Epoch 5 Iter 23 - Loss: 14.728\n",
      "Epoch 5 Iter 24 - Loss: 17.465\n",
      "Epoch 5 Iter 25 - Loss: 18.063\n",
      "Epoch 5 Iter 26 - Loss: 18.157\n",
      "Epoch 5 Iter 27 - Loss: 15.502\n",
      "Epoch 5 Iter 28 - Loss: 14.086\n",
      "Epoch 5 Iter 29 - Loss: 15.768\n",
      "Epoch 5 Iter 30 - Loss: 17.262\n",
      "Epoch 5 Iter 31 - Loss: 17.942\n",
      "Epoch 5 Iter 32 - Loss: 15.966\n",
      "Epoch 5 Iter 33 - Loss: 17.314\n",
      "Epoch 5 Iter 34 - Loss: 17.219\n",
      "Epoch 5 Iter 35 - Loss: 19.566\n",
      "Epoch 5 Iter 36 - Loss: 20.126\n",
      "Epoch 5 Iter 37 - Loss: 14.659\n",
      "Epoch 5 Iter 38 - Loss: 17.109\n",
      "Epoch 5 Iter 39 - Loss: 18.251\n",
      "Epoch 5 Iter 40 - Loss: 14.553\n",
      "Epoch 5 Iter 41 - Loss: 16.831\n",
      "Epoch 5 Iter 42 - Loss: 15.796\n",
      "Epoch 5 Iter 43 - Loss: 14.701\n",
      "Epoch 5 Iter 44 - Loss: 17.646\n",
      "Epoch 5 Iter 45 - Loss: 15.107\n",
      "Epoch 6 Iter 2 - Loss: 15.064\n",
      "Epoch 6 Iter 3 - Loss: 15.276\n",
      "Epoch 6 Iter 4 - Loss: 15.286\n",
      "Epoch 6 Iter 5 - Loss: 16.456\n",
      "Epoch 6 Iter 6 - Loss: 18.453\n",
      "Epoch 6 Iter 7 - Loss: 16.930\n",
      "Epoch 6 Iter 8 - Loss: 20.159\n",
      "Epoch 6 Iter 9 - Loss: 19.039\n",
      "Epoch 6 Iter 10 - Loss: 15.713\n",
      "Epoch 6 Iter 11 - Loss: 18.415\n",
      "Epoch 6 Iter 12 - Loss: 15.492\n",
      "Epoch 6 Iter 13 - Loss: 16.346\n",
      "Epoch 6 Iter 14 - Loss: 21.725\n",
      "Epoch 6 Iter 15 - Loss: 16.930\n",
      "Epoch 6 Iter 16 - Loss: 16.898\n",
      "Epoch 6 Iter 17 - Loss: 19.760\n",
      "Epoch 6 Iter 18 - Loss: 14.733\n",
      "Epoch 6 Iter 19 - Loss: 19.361\n",
      "Epoch 6 Iter 20 - Loss: 16.638\n",
      "Epoch 6 Iter 21 - Loss: 15.917\n",
      "Epoch 6 Iter 22 - Loss: 16.956\n",
      "Epoch 6 Iter 23 - Loss: 15.022\n",
      "Epoch 6 Iter 24 - Loss: 18.403\n",
      "Epoch 6 Iter 25 - Loss: 12.838\n",
      "Epoch 6 Iter 26 - Loss: 18.862\n",
      "Epoch 6 Iter 27 - Loss: 13.628\n",
      "Epoch 6 Iter 28 - Loss: 14.664\n",
      "Epoch 6 Iter 29 - Loss: 15.130\n",
      "Epoch 6 Iter 30 - Loss: 20.270\n",
      "Epoch 6 Iter 31 - Loss: 13.481\n",
      "Epoch 6 Iter 32 - Loss: 15.971\n",
      "Epoch 6 Iter 33 - Loss: 16.328\n",
      "Epoch 6 Iter 34 - Loss: 16.684\n",
      "Epoch 6 Iter 35 - Loss: 16.746\n",
      "Epoch 6 Iter 36 - Loss: 20.299\n",
      "Epoch 6 Iter 37 - Loss: 15.919\n",
      "Epoch 6 Iter 38 - Loss: 13.859\n",
      "Epoch 6 Iter 39 - Loss: 22.190\n",
      "Epoch 6 Iter 40 - Loss: 14.019\n",
      "Epoch 6 Iter 41 - Loss: 12.744\n",
      "Epoch 6 Iter 42 - Loss: 17.622\n",
      "Epoch 6 Iter 43 - Loss: 12.641\n",
      "Epoch 6 Iter 44 - Loss: 12.806\n",
      "Epoch 6 Iter 45 - Loss: 15.886\n",
      "Epoch 7 Iter 2 - Loss: 15.082\n",
      "Epoch 7 Iter 3 - Loss: 18.834\n",
      "Epoch 7 Iter 4 - Loss: 17.812\n",
      "Epoch 7 Iter 5 - Loss: 15.450\n",
      "Epoch 7 Iter 6 - Loss: 18.653\n",
      "Epoch 7 Iter 7 - Loss: 15.034\n",
      "Epoch 7 Iter 8 - Loss: 18.842\n",
      "Epoch 7 Iter 9 - Loss: 16.669\n",
      "Epoch 7 Iter 10 - Loss: 12.316\n",
      "Epoch 7 Iter 11 - Loss: 14.881\n",
      "Epoch 7 Iter 12 - Loss: 13.636\n",
      "Epoch 7 Iter 13 - Loss: 13.368\n",
      "Epoch 7 Iter 14 - Loss: 14.975\n",
      "Epoch 7 Iter 15 - Loss: 15.131\n",
      "Epoch 7 Iter 16 - Loss: 16.646\n",
      "Epoch 7 Iter 17 - Loss: 17.035\n",
      "Epoch 7 Iter 18 - Loss: 13.425\n",
      "Epoch 7 Iter 19 - Loss: 15.811\n",
      "Epoch 7 Iter 20 - Loss: 16.711\n",
      "Epoch 7 Iter 21 - Loss: 17.446\n",
      "Epoch 7 Iter 22 - Loss: 12.430\n",
      "Epoch 7 Iter 23 - Loss: 19.000\n",
      "Epoch 7 Iter 24 - Loss: 12.375\n",
      "Epoch 7 Iter 25 - Loss: 15.091\n",
      "Epoch 7 Iter 26 - Loss: 17.995\n",
      "Epoch 7 Iter 27 - Loss: 15.322\n",
      "Epoch 7 Iter 28 - Loss: 14.989\n",
      "Epoch 7 Iter 29 - Loss: 13.522\n",
      "Epoch 7 Iter 30 - Loss: 13.089\n",
      "Epoch 7 Iter 31 - Loss: 14.436\n",
      "Epoch 7 Iter 32 - Loss: 14.509\n",
      "Epoch 7 Iter 33 - Loss: 15.689\n",
      "Epoch 7 Iter 34 - Loss: 16.135\n",
      "Epoch 7 Iter 35 - Loss: 14.050\n",
      "Epoch 7 Iter 36 - Loss: 20.089\n",
      "Epoch 7 Iter 37 - Loss: 17.952\n",
      "Epoch 7 Iter 38 - Loss: 12.871\n",
      "Epoch 7 Iter 39 - Loss: 13.919\n",
      "Epoch 7 Iter 40 - Loss: 12.701\n",
      "Epoch 7 Iter 41 - Loss: 13.898\n",
      "Epoch 7 Iter 42 - Loss: 16.301\n",
      "Epoch 7 Iter 43 - Loss: 14.642\n",
      "Epoch 7 Iter 44 - Loss: 14.039\n",
      "Epoch 7 Iter 45 - Loss: 9.230\n",
      "Epoch 8 Iter 2 - Loss: 14.280\n",
      "Epoch 8 Iter 3 - Loss: 15.548\n",
      "Epoch 8 Iter 4 - Loss: 17.021\n",
      "Epoch 8 Iter 5 - Loss: 17.847\n",
      "Epoch 8 Iter 6 - Loss: 14.057\n",
      "Epoch 8 Iter 7 - Loss: 12.852\n",
      "Epoch 8 Iter 8 - Loss: 14.467\n",
      "Epoch 8 Iter 9 - Loss: 18.329\n",
      "Epoch 8 Iter 10 - Loss: 12.699\n",
      "Epoch 8 Iter 11 - Loss: 12.809\n",
      "Epoch 8 Iter 12 - Loss: 15.085\n",
      "Epoch 8 Iter 13 - Loss: 11.694\n",
      "Epoch 8 Iter 14 - Loss: 16.898\n",
      "Epoch 8 Iter 15 - Loss: 15.281\n",
      "Epoch 8 Iter 16 - Loss: 15.475\n",
      "Epoch 8 Iter 17 - Loss: 14.964\n",
      "Epoch 8 Iter 18 - Loss: 12.663\n",
      "Epoch 8 Iter 19 - Loss: 14.680\n",
      "Epoch 8 Iter 20 - Loss: 12.881\n",
      "Epoch 8 Iter 21 - Loss: 14.212\n",
      "Epoch 8 Iter 22 - Loss: 12.843\n",
      "Epoch 8 Iter 23 - Loss: 14.388\n",
      "Epoch 8 Iter 24 - Loss: 14.707\n",
      "Epoch 8 Iter 25 - Loss: 13.491\n",
      "Epoch 8 Iter 26 - Loss: 13.527\n",
      "Epoch 8 Iter 27 - Loss: 13.090\n",
      "Epoch 8 Iter 28 - Loss: 15.646\n",
      "Epoch 8 Iter 29 - Loss: 11.441\n",
      "Epoch 8 Iter 30 - Loss: 16.653\n",
      "Epoch 8 Iter 31 - Loss: 14.659\n",
      "Epoch 8 Iter 32 - Loss: 12.126\n",
      "Epoch 8 Iter 33 - Loss: 16.355\n",
      "Epoch 8 Iter 34 - Loss: 14.163\n",
      "Epoch 8 Iter 35 - Loss: 16.711\n",
      "Epoch 8 Iter 36 - Loss: 13.870\n",
      "Epoch 8 Iter 37 - Loss: 12.033\n",
      "Epoch 8 Iter 38 - Loss: 15.690\n",
      "Epoch 8 Iter 39 - Loss: 13.684\n",
      "Epoch 8 Iter 40 - Loss: 12.796\n",
      "Epoch 8 Iter 41 - Loss: 15.189\n",
      "Epoch 8 Iter 42 - Loss: 15.931\n",
      "Epoch 8 Iter 43 - Loss: 14.231\n",
      "Epoch 8 Iter 44 - Loss: 15.816\n",
      "Epoch 8 Iter 45 - Loss: 20.796\n",
      "Epoch 9 Iter 2 - Loss: 14.934\n",
      "Epoch 9 Iter 3 - Loss: 12.808\n",
      "Epoch 9 Iter 4 - Loss: 16.598\n",
      "Epoch 9 Iter 5 - Loss: 14.114\n",
      "Epoch 9 Iter 6 - Loss: 14.202\n",
      "Epoch 9 Iter 7 - Loss: 13.961\n",
      "Epoch 9 Iter 8 - Loss: 13.606\n",
      "Epoch 9 Iter 9 - Loss: 18.627\n",
      "Epoch 9 Iter 10 - Loss: 16.929\n",
      "Epoch 9 Iter 11 - Loss: 14.292\n",
      "Epoch 9 Iter 12 - Loss: 11.362\n",
      "Epoch 9 Iter 13 - Loss: 12.890\n",
      "Epoch 9 Iter 14 - Loss: 14.829\n",
      "Epoch 9 Iter 15 - Loss: 14.702\n",
      "Epoch 9 Iter 16 - Loss: 12.369\n",
      "Epoch 9 Iter 17 - Loss: 13.738\n",
      "Epoch 9 Iter 18 - Loss: 10.943\n",
      "Epoch 9 Iter 19 - Loss: 13.793\n",
      "Epoch 9 Iter 20 - Loss: 12.406\n",
      "Epoch 9 Iter 21 - Loss: 16.767\n",
      "Epoch 9 Iter 22 - Loss: 13.377\n",
      "Epoch 9 Iter 23 - Loss: 12.750\n",
      "Epoch 9 Iter 24 - Loss: 15.298\n",
      "Epoch 9 Iter 25 - Loss: 14.148\n",
      "Epoch 9 Iter 26 - Loss: 14.775\n",
      "Epoch 9 Iter 27 - Loss: 13.898\n",
      "Epoch 9 Iter 28 - Loss: 13.984\n",
      "Epoch 9 Iter 29 - Loss: 13.661\n",
      "Epoch 9 Iter 30 - Loss: 12.535\n",
      "Epoch 9 Iter 31 - Loss: 12.379\n",
      "Epoch 9 Iter 32 - Loss: 13.591\n",
      "Epoch 9 Iter 33 - Loss: 11.680\n",
      "Epoch 9 Iter 34 - Loss: 14.271\n",
      "Epoch 9 Iter 35 - Loss: 15.139\n",
      "Epoch 9 Iter 36 - Loss: 13.221\n",
      "Epoch 9 Iter 37 - Loss: 14.346\n",
      "Epoch 9 Iter 38 - Loss: 13.633\n",
      "Epoch 9 Iter 39 - Loss: 12.909\n",
      "Epoch 9 Iter 40 - Loss: 14.633\n",
      "Epoch 9 Iter 41 - Loss: 12.683\n",
      "Epoch 9 Iter 42 - Loss: 11.440\n",
      "Epoch 9 Iter 43 - Loss: 12.978\n",
      "Epoch 9 Iter 44 - Loss: 14.346\n",
      "Epoch 9 Iter 45 - Loss: 11.243\n",
      "Epoch 10 Iter 2 - Loss: 17.515\n",
      "Epoch 10 Iter 3 - Loss: 11.472\n",
      "Epoch 10 Iter 4 - Loss: 13.863\n",
      "Epoch 10 Iter 5 - Loss: 10.759\n",
      "Epoch 10 Iter 6 - Loss: 13.299\n",
      "Epoch 10 Iter 7 - Loss: 14.908\n",
      "Epoch 10 Iter 8 - Loss: 11.088\n",
      "Epoch 10 Iter 9 - Loss: 12.733\n",
      "Epoch 10 Iter 10 - Loss: 13.209\n",
      "Epoch 10 Iter 11 - Loss: 13.976\n",
      "Epoch 10 Iter 12 - Loss: 12.820\n",
      "Epoch 10 Iter 13 - Loss: 15.601\n",
      "Epoch 10 Iter 14 - Loss: 13.513\n",
      "Epoch 10 Iter 15 - Loss: 12.533\n",
      "Epoch 10 Iter 16 - Loss: 12.677\n",
      "Epoch 10 Iter 17 - Loss: 12.929\n",
      "Epoch 10 Iter 18 - Loss: 12.202\n",
      "Epoch 10 Iter 19 - Loss: 15.358\n",
      "Epoch 10 Iter 20 - Loss: 14.052\n",
      "Epoch 10 Iter 21 - Loss: 13.807\n",
      "Epoch 10 Iter 22 - Loss: 12.084\n",
      "Epoch 10 Iter 23 - Loss: 11.987\n",
      "Epoch 10 Iter 24 - Loss: 14.578\n",
      "Epoch 10 Iter 25 - Loss: 15.074\n",
      "Epoch 10 Iter 26 - Loss: 16.298\n",
      "Epoch 10 Iter 27 - Loss: 12.003\n",
      "Epoch 10 Iter 28 - Loss: 12.772\n",
      "Epoch 10 Iter 29 - Loss: 14.052\n",
      "Epoch 10 Iter 30 - Loss: 11.219\n",
      "Epoch 10 Iter 31 - Loss: 11.752\n",
      "Epoch 10 Iter 32 - Loss: 13.346\n",
      "Epoch 10 Iter 33 - Loss: 11.401\n",
      "Epoch 10 Iter 34 - Loss: 13.263\n",
      "Epoch 10 Iter 35 - Loss: 17.081\n",
      "Epoch 10 Iter 36 - Loss: 13.815\n",
      "Epoch 10 Iter 37 - Loss: 13.654\n",
      "Epoch 10 Iter 38 - Loss: 13.159\n",
      "Epoch 10 Iter 39 - Loss: 10.908\n",
      "Epoch 10 Iter 40 - Loss: 10.090\n",
      "Epoch 10 Iter 41 - Loss: 10.473\n",
      "Epoch 10 Iter 42 - Loss: 13.157\n",
      "Epoch 10 Iter 43 - Loss: 13.957\n",
      "Epoch 10 Iter 44 - Loss: 12.169\n",
      "Epoch 10 Iter 45 - Loss: 14.460\n",
      "Epoch 11 Iter 2 - Loss: 12.342\n",
      "Epoch 11 Iter 3 - Loss: 12.596\n",
      "Epoch 11 Iter 4 - Loss: 13.211\n",
      "Epoch 11 Iter 5 - Loss: 12.306\n",
      "Epoch 11 Iter 6 - Loss: 15.108\n",
      "Epoch 11 Iter 7 - Loss: 13.048\n",
      "Epoch 11 Iter 8 - Loss: 10.966\n",
      "Epoch 11 Iter 9 - Loss: 12.511\n",
      "Epoch 11 Iter 10 - Loss: 13.931\n",
      "Epoch 11 Iter 11 - Loss: 12.172\n",
      "Epoch 11 Iter 12 - Loss: 11.134\n",
      "Epoch 11 Iter 13 - Loss: 14.084\n",
      "Epoch 11 Iter 14 - Loss: 13.579\n",
      "Epoch 11 Iter 15 - Loss: 10.984\n",
      "Epoch 11 Iter 16 - Loss: 11.260\n",
      "Epoch 11 Iter 17 - Loss: 12.188\n",
      "Epoch 11 Iter 18 - Loss: 12.500\n",
      "Epoch 11 Iter 19 - Loss: 14.964\n",
      "Epoch 11 Iter 20 - Loss: 13.340\n",
      "Epoch 11 Iter 21 - Loss: 14.806\n",
      "Epoch 11 Iter 22 - Loss: 11.473\n",
      "Epoch 11 Iter 23 - Loss: 13.866\n",
      "Epoch 11 Iter 24 - Loss: 12.227\n",
      "Epoch 11 Iter 25 - Loss: 14.303\n",
      "Epoch 11 Iter 26 - Loss: 12.965\n",
      "Epoch 11 Iter 27 - Loss: 11.792\n",
      "Epoch 11 Iter 28 - Loss: 14.021\n",
      "Epoch 11 Iter 29 - Loss: 11.009\n",
      "Epoch 11 Iter 30 - Loss: 14.643\n",
      "Epoch 11 Iter 31 - Loss: 12.686\n",
      "Epoch 11 Iter 32 - Loss: 11.701\n",
      "Epoch 11 Iter 33 - Loss: 10.975\n",
      "Epoch 11 Iter 34 - Loss: 11.942\n",
      "Epoch 11 Iter 35 - Loss: 13.283\n",
      "Epoch 11 Iter 36 - Loss: 11.518\n",
      "Epoch 11 Iter 37 - Loss: 14.134\n",
      "Epoch 11 Iter 38 - Loss: 14.083\n",
      "Epoch 11 Iter 39 - Loss: 13.273\n",
      "Epoch 11 Iter 40 - Loss: 13.242\n",
      "Epoch 11 Iter 41 - Loss: 10.364\n",
      "Epoch 11 Iter 42 - Loss: 9.898\n",
      "Epoch 11 Iter 43 - Loss: 12.852\n",
      "Epoch 11 Iter 44 - Loss: 11.953\n",
      "Epoch 11 Iter 45 - Loss: 18.102\n",
      "Epoch 12 Iter 2 - Loss: 14.621\n",
      "Epoch 12 Iter 3 - Loss: 9.803\n",
      "Epoch 12 Iter 4 - Loss: 13.341\n",
      "Epoch 12 Iter 5 - Loss: 11.645\n",
      "Epoch 12 Iter 6 - Loss: 10.680\n",
      "Epoch 12 Iter 7 - Loss: 11.379\n",
      "Epoch 12 Iter 8 - Loss: 13.049\n",
      "Epoch 12 Iter 9 - Loss: 12.648\n",
      "Epoch 12 Iter 10 - Loss: 13.386\n",
      "Epoch 12 Iter 11 - Loss: 10.074\n",
      "Epoch 12 Iter 12 - Loss: 12.164\n",
      "Epoch 12 Iter 13 - Loss: 13.628\n",
      "Epoch 12 Iter 14 - Loss: 14.086\n",
      "Epoch 12 Iter 15 - Loss: 9.945\n",
      "Epoch 12 Iter 16 - Loss: 11.857\n",
      "Epoch 12 Iter 17 - Loss: 14.534\n",
      "Epoch 12 Iter 18 - Loss: 11.502\n",
      "Epoch 12 Iter 19 - Loss: 12.854\n",
      "Epoch 12 Iter 20 - Loss: 13.420\n",
      "Epoch 12 Iter 21 - Loss: 12.114\n",
      "Epoch 12 Iter 22 - Loss: 12.100\n",
      "Epoch 12 Iter 23 - Loss: 13.006\n",
      "Epoch 12 Iter 24 - Loss: 11.050\n",
      "Epoch 12 Iter 25 - Loss: 10.922\n",
      "Epoch 12 Iter 26 - Loss: 15.870\n",
      "Epoch 12 Iter 27 - Loss: 12.463\n",
      "Epoch 12 Iter 28 - Loss: 12.285\n",
      "Epoch 12 Iter 29 - Loss: 12.943\n",
      "Epoch 12 Iter 30 - Loss: 11.338\n",
      "Epoch 12 Iter 31 - Loss: 11.019\n",
      "Epoch 12 Iter 32 - Loss: 16.644\n",
      "Epoch 12 Iter 33 - Loss: 12.786\n",
      "Epoch 12 Iter 34 - Loss: 12.031\n",
      "Epoch 12 Iter 35 - Loss: 12.767\n",
      "Epoch 12 Iter 36 - Loss: 9.355\n",
      "Epoch 12 Iter 37 - Loss: 12.469\n",
      "Epoch 12 Iter 38 - Loss: 10.026\n",
      "Epoch 12 Iter 39 - Loss: 13.018\n",
      "Epoch 12 Iter 40 - Loss: 9.622\n",
      "Epoch 12 Iter 41 - Loss: 12.811\n",
      "Epoch 12 Iter 42 - Loss: 11.168\n",
      "Epoch 12 Iter 43 - Loss: 13.388\n",
      "Epoch 12 Iter 44 - Loss: 12.295\n",
      "Epoch 12 Iter 45 - Loss: 12.016\n",
      "Epoch 13 Iter 2 - Loss: 10.954\n",
      "Epoch 13 Iter 3 - Loss: 11.871\n",
      "Epoch 13 Iter 4 - Loss: 12.724\n",
      "Epoch 13 Iter 5 - Loss: 10.852\n",
      "Epoch 13 Iter 6 - Loss: 13.694\n",
      "Epoch 13 Iter 7 - Loss: 12.645\n",
      "Epoch 13 Iter 8 - Loss: 12.470\n",
      "Epoch 13 Iter 9 - Loss: 11.135\n",
      "Epoch 13 Iter 10 - Loss: 13.772\n",
      "Epoch 13 Iter 11 - Loss: 11.658\n",
      "Epoch 13 Iter 12 - Loss: 13.136\n",
      "Epoch 13 Iter 13 - Loss: 12.516\n",
      "Epoch 13 Iter 14 - Loss: 10.596\n",
      "Epoch 13 Iter 15 - Loss: 12.271\n",
      "Epoch 13 Iter 16 - Loss: 12.255\n",
      "Epoch 13 Iter 17 - Loss: 12.542\n",
      "Epoch 13 Iter 18 - Loss: 12.034\n",
      "Epoch 13 Iter 19 - Loss: 12.410\n",
      "Epoch 13 Iter 20 - Loss: 11.812\n",
      "Epoch 13 Iter 21 - Loss: 12.832\n",
      "Epoch 13 Iter 22 - Loss: 12.778\n",
      "Epoch 13 Iter 23 - Loss: 11.702\n",
      "Epoch 13 Iter 24 - Loss: 13.220\n",
      "Epoch 13 Iter 25 - Loss: 11.130\n",
      "Epoch 13 Iter 26 - Loss: 9.625\n",
      "Epoch 13 Iter 27 - Loss: 11.580\n",
      "Epoch 13 Iter 28 - Loss: 8.919\n",
      "Epoch 13 Iter 29 - Loss: 12.625\n",
      "Epoch 13 Iter 30 - Loss: 10.472\n",
      "Epoch 13 Iter 31 - Loss: 10.451\n",
      "Epoch 13 Iter 32 - Loss: 12.232\n",
      "Epoch 13 Iter 33 - Loss: 12.221\n",
      "Epoch 13 Iter 34 - Loss: 8.886\n",
      "Epoch 13 Iter 35 - Loss: 11.734\n",
      "Epoch 13 Iter 36 - Loss: 11.153\n",
      "Epoch 13 Iter 37 - Loss: 11.029\n",
      "Epoch 13 Iter 38 - Loss: 11.179\n",
      "Epoch 13 Iter 39 - Loss: 12.871\n",
      "Epoch 13 Iter 40 - Loss: 13.047\n",
      "Epoch 13 Iter 41 - Loss: 8.256\n",
      "Epoch 13 Iter 42 - Loss: 10.654\n",
      "Epoch 13 Iter 43 - Loss: 14.474\n",
      "Epoch 13 Iter 44 - Loss: 12.121\n",
      "Epoch 13 Iter 45 - Loss: 16.593\n",
      "Epoch 14 Iter 2 - Loss: 11.238\n",
      "Epoch 14 Iter 3 - Loss: 12.111\n",
      "Epoch 14 Iter 4 - Loss: 11.590\n",
      "Epoch 14 Iter 5 - Loss: 13.348\n",
      "Epoch 14 Iter 6 - Loss: 12.426\n",
      "Epoch 14 Iter 7 - Loss: 10.828\n",
      "Epoch 14 Iter 8 - Loss: 10.248\n",
      "Epoch 14 Iter 9 - Loss: 13.036\n",
      "Epoch 14 Iter 10 - Loss: 11.711\n",
      "Epoch 14 Iter 11 - Loss: 13.706\n",
      "Epoch 14 Iter 12 - Loss: 11.281\n",
      "Epoch 14 Iter 13 - Loss: 9.336\n",
      "Epoch 14 Iter 14 - Loss: 9.907\n",
      "Epoch 14 Iter 15 - Loss: 10.600\n",
      "Epoch 14 Iter 16 - Loss: 9.791\n",
      "Epoch 14 Iter 17 - Loss: 10.072\n",
      "Epoch 14 Iter 18 - Loss: 12.533\n",
      "Epoch 14 Iter 19 - Loss: 9.282\n",
      "Epoch 14 Iter 20 - Loss: 12.042\n",
      "Epoch 14 Iter 21 - Loss: 13.987\n",
      "Epoch 14 Iter 22 - Loss: 13.068\n",
      "Epoch 14 Iter 23 - Loss: 12.703\n",
      "Epoch 14 Iter 24 - Loss: 11.538\n",
      "Epoch 14 Iter 25 - Loss: 12.525\n",
      "Epoch 14 Iter 26 - Loss: 11.300\n",
      "Epoch 14 Iter 27 - Loss: 10.745\n",
      "Epoch 14 Iter 28 - Loss: 10.957\n",
      "Epoch 14 Iter 29 - Loss: 11.502\n",
      "Epoch 14 Iter 30 - Loss: 11.814\n",
      "Epoch 14 Iter 31 - Loss: 9.985\n",
      "Epoch 14 Iter 32 - Loss: 10.305\n",
      "Epoch 14 Iter 33 - Loss: 10.515\n",
      "Epoch 14 Iter 34 - Loss: 11.222\n",
      "Epoch 14 Iter 35 - Loss: 9.397\n",
      "Epoch 14 Iter 36 - Loss: 8.212\n",
      "Epoch 14 Iter 37 - Loss: 10.379\n",
      "Epoch 14 Iter 38 - Loss: 10.909\n",
      "Epoch 14 Iter 39 - Loss: 12.378\n",
      "Epoch 14 Iter 40 - Loss: 11.868\n",
      "Epoch 14 Iter 41 - Loss: 14.916\n",
      "Epoch 14 Iter 42 - Loss: 11.985\n",
      "Epoch 14 Iter 43 - Loss: 12.702\n",
      "Epoch 14 Iter 44 - Loss: 12.999\n",
      "Epoch 14 Iter 45 - Loss: 10.480\n",
      "Epoch 15 Iter 2 - Loss: 12.036\n",
      "Epoch 15 Iter 3 - Loss: 12.267\n",
      "Epoch 15 Iter 4 - Loss: 13.469\n",
      "Epoch 15 Iter 5 - Loss: 12.105\n",
      "Epoch 15 Iter 6 - Loss: 12.635\n",
      "Epoch 15 Iter 7 - Loss: 11.931\n",
      "Epoch 15 Iter 8 - Loss: 11.144\n",
      "Epoch 15 Iter 9 - Loss: 12.397\n",
      "Epoch 15 Iter 10 - Loss: 10.797\n",
      "Epoch 15 Iter 11 - Loss: 9.945\n",
      "Epoch 15 Iter 12 - Loss: 11.453\n",
      "Epoch 15 Iter 13 - Loss: 11.408\n",
      "Epoch 15 Iter 14 - Loss: 11.106\n",
      "Epoch 15 Iter 15 - Loss: 9.089\n",
      "Epoch 15 Iter 16 - Loss: 12.110\n",
      "Epoch 15 Iter 17 - Loss: 10.390\n",
      "Epoch 15 Iter 18 - Loss: 11.019\n",
      "Epoch 15 Iter 19 - Loss: 11.696\n",
      "Epoch 15 Iter 20 - Loss: 9.511\n",
      "Epoch 15 Iter 21 - Loss: 9.466\n",
      "Epoch 15 Iter 22 - Loss: 12.122\n",
      "Epoch 15 Iter 23 - Loss: 11.646\n",
      "Epoch 15 Iter 24 - Loss: 10.204\n",
      "Epoch 15 Iter 25 - Loss: 13.306\n",
      "Epoch 15 Iter 26 - Loss: 9.054\n",
      "Epoch 15 Iter 27 - Loss: 11.137\n",
      "Epoch 15 Iter 28 - Loss: 10.773\n",
      "Epoch 15 Iter 29 - Loss: 11.420\n",
      "Epoch 15 Iter 30 - Loss: 12.024\n",
      "Epoch 15 Iter 31 - Loss: 10.767\n",
      "Epoch 15 Iter 32 - Loss: 9.878\n",
      "Epoch 15 Iter 33 - Loss: 11.950\n",
      "Epoch 15 Iter 34 - Loss: 10.100\n",
      "Epoch 15 Iter 35 - Loss: 10.301\n",
      "Epoch 15 Iter 36 - Loss: 10.761\n",
      "Epoch 15 Iter 37 - Loss: 11.912\n",
      "Epoch 15 Iter 38 - Loss: 12.321\n",
      "Epoch 15 Iter 39 - Loss: 9.311\n",
      "Epoch 15 Iter 40 - Loss: 11.475\n",
      "Epoch 15 Iter 41 - Loss: 13.357\n",
      "Epoch 15 Iter 42 - Loss: 10.409\n",
      "Epoch 15 Iter 43 - Loss: 11.263\n",
      "Epoch 15 Iter 44 - Loss: 9.009\n",
      "Epoch 15 Iter 45 - Loss: 13.706\n",
      "Epoch 16 Iter 2 - Loss: 10.985\n",
      "Epoch 16 Iter 3 - Loss: 11.131\n",
      "Epoch 16 Iter 4 - Loss: 12.011\n",
      "Epoch 16 Iter 5 - Loss: 9.149\n",
      "Epoch 16 Iter 6 - Loss: 12.766\n",
      "Epoch 16 Iter 7 - Loss: 9.154\n",
      "Epoch 16 Iter 8 - Loss: 9.835\n",
      "Epoch 16 Iter 9 - Loss: 11.782\n",
      "Epoch 16 Iter 10 - Loss: 11.036\n",
      "Epoch 16 Iter 11 - Loss: 11.213\n",
      "Epoch 16 Iter 12 - Loss: 10.775\n",
      "Epoch 16 Iter 13 - Loss: 9.621\n",
      "Epoch 16 Iter 14 - Loss: 13.071\n",
      "Epoch 16 Iter 15 - Loss: 9.531\n",
      "Epoch 16 Iter 16 - Loss: 8.208\n",
      "Epoch 16 Iter 17 - Loss: 12.815\n",
      "Epoch 16 Iter 18 - Loss: 10.805\n",
      "Epoch 16 Iter 19 - Loss: 9.975\n",
      "Epoch 16 Iter 20 - Loss: 11.672\n",
      "Epoch 16 Iter 21 - Loss: 8.982\n",
      "Epoch 16 Iter 22 - Loss: 9.685\n",
      "Epoch 16 Iter 23 - Loss: 11.608\n",
      "Epoch 16 Iter 24 - Loss: 10.958\n",
      "Epoch 16 Iter 25 - Loss: 9.579\n",
      "Epoch 16 Iter 26 - Loss: 12.614\n",
      "Epoch 16 Iter 27 - Loss: 11.078\n",
      "Epoch 16 Iter 28 - Loss: 12.561\n",
      "Epoch 16 Iter 29 - Loss: 9.963\n",
      "Epoch 16 Iter 30 - Loss: 10.204\n",
      "Epoch 16 Iter 31 - Loss: 10.712\n",
      "Epoch 16 Iter 32 - Loss: 10.387\n",
      "Epoch 16 Iter 33 - Loss: 11.650\n",
      "Epoch 16 Iter 34 - Loss: 11.570\n",
      "Epoch 16 Iter 35 - Loss: 9.947\n",
      "Epoch 16 Iter 36 - Loss: 9.863\n",
      "Epoch 16 Iter 37 - Loss: 12.718\n",
      "Epoch 16 Iter 38 - Loss: 9.696\n",
      "Epoch 16 Iter 39 - Loss: 9.413\n",
      "Epoch 16 Iter 40 - Loss: 12.324\n",
      "Epoch 16 Iter 41 - Loss: 11.701\n",
      "Epoch 16 Iter 42 - Loss: 10.216\n",
      "Epoch 16 Iter 43 - Loss: 10.486\n",
      "Epoch 16 Iter 44 - Loss: 11.812\n",
      "Epoch 16 Iter 45 - Loss: 16.800\n",
      "Epoch 17 Iter 2 - Loss: 9.628\n",
      "Epoch 17 Iter 3 - Loss: 8.394\n",
      "Epoch 17 Iter 4 - Loss: 11.750\n",
      "Epoch 17 Iter 5 - Loss: 13.279\n",
      "Epoch 17 Iter 6 - Loss: 12.752\n",
      "Epoch 17 Iter 7 - Loss: 13.571\n",
      "Epoch 17 Iter 8 - Loss: 9.846\n",
      "Epoch 17 Iter 9 - Loss: 10.052\n",
      "Epoch 17 Iter 10 - Loss: 10.781\n",
      "Epoch 17 Iter 11 - Loss: 11.145\n",
      "Epoch 17 Iter 12 - Loss: 10.893\n",
      "Epoch 17 Iter 13 - Loss: 9.788\n",
      "Epoch 17 Iter 14 - Loss: 12.866\n",
      "Epoch 17 Iter 15 - Loss: 11.798\n",
      "Epoch 17 Iter 16 - Loss: 11.951\n",
      "Epoch 17 Iter 17 - Loss: 11.762\n",
      "Epoch 17 Iter 18 - Loss: 11.322\n",
      "Epoch 17 Iter 19 - Loss: 9.409\n",
      "Epoch 17 Iter 20 - Loss: 11.092\n",
      "Epoch 17 Iter 21 - Loss: 9.723\n",
      "Epoch 17 Iter 22 - Loss: 11.031\n",
      "Epoch 17 Iter 23 - Loss: 9.273\n",
      "Epoch 17 Iter 24 - Loss: 12.995\n",
      "Epoch 17 Iter 25 - Loss: 8.725\n",
      "Epoch 17 Iter 26 - Loss: 11.263\n",
      "Epoch 17 Iter 27 - Loss: 10.927\n",
      "Epoch 17 Iter 28 - Loss: 9.354\n",
      "Epoch 17 Iter 29 - Loss: 9.299\n",
      "Epoch 17 Iter 30 - Loss: 11.322\n",
      "Epoch 17 Iter 31 - Loss: 10.273\n",
      "Epoch 17 Iter 32 - Loss: 9.591\n",
      "Epoch 17 Iter 33 - Loss: 9.383\n",
      "Epoch 17 Iter 34 - Loss: 10.106\n",
      "Epoch 17 Iter 35 - Loss: 9.376\n",
      "Epoch 17 Iter 36 - Loss: 9.558\n",
      "Epoch 17 Iter 37 - Loss: 10.466\n",
      "Epoch 17 Iter 38 - Loss: 11.935\n",
      "Epoch 17 Iter 39 - Loss: 10.812\n",
      "Epoch 17 Iter 40 - Loss: 9.240\n",
      "Epoch 17 Iter 41 - Loss: 9.390\n",
      "Epoch 17 Iter 42 - Loss: 9.921\n",
      "Epoch 17 Iter 43 - Loss: 9.775\n",
      "Epoch 17 Iter 44 - Loss: 9.218\n",
      "Epoch 17 Iter 45 - Loss: 9.242\n",
      "Epoch 18 Iter 2 - Loss: 11.306\n",
      "Epoch 18 Iter 3 - Loss: 11.180\n",
      "Epoch 18 Iter 4 - Loss: 10.162\n",
      "Epoch 18 Iter 5 - Loss: 10.670\n",
      "Epoch 18 Iter 6 - Loss: 9.375\n",
      "Epoch 18 Iter 7 - Loss: 11.842\n",
      "Epoch 18 Iter 8 - Loss: 9.727\n",
      "Epoch 18 Iter 9 - Loss: 9.678\n",
      "Epoch 18 Iter 10 - Loss: 9.056\n",
      "Epoch 18 Iter 11 - Loss: 11.241\n",
      "Epoch 18 Iter 12 - Loss: 9.295\n",
      "Epoch 18 Iter 13 - Loss: 10.661\n",
      "Epoch 18 Iter 14 - Loss: 9.965\n",
      "Epoch 18 Iter 15 - Loss: 12.664\n",
      "Epoch 18 Iter 16 - Loss: 10.906\n",
      "Epoch 18 Iter 17 - Loss: 12.170\n",
      "Epoch 18 Iter 18 - Loss: 9.379\n",
      "Epoch 18 Iter 19 - Loss: 11.429\n",
      "Epoch 18 Iter 20 - Loss: 9.387\n",
      "Epoch 18 Iter 21 - Loss: 9.308\n",
      "Epoch 18 Iter 22 - Loss: 9.121\n",
      "Epoch 18 Iter 23 - Loss: 10.248\n",
      "Epoch 18 Iter 24 - Loss: 10.138\n",
      "Epoch 18 Iter 25 - Loss: 11.454\n",
      "Epoch 18 Iter 26 - Loss: 9.125\n",
      "Epoch 18 Iter 27 - Loss: 10.076\n",
      "Epoch 18 Iter 28 - Loss: 10.687\n",
      "Epoch 18 Iter 29 - Loss: 11.314\n",
      "Epoch 18 Iter 30 - Loss: 11.008\n",
      "Epoch 18 Iter 31 - Loss: 9.336\n",
      "Epoch 18 Iter 32 - Loss: 10.287\n",
      "Epoch 18 Iter 33 - Loss: 8.881\n",
      "Epoch 18 Iter 34 - Loss: 10.330\n",
      "Epoch 18 Iter 35 - Loss: 9.738\n",
      "Epoch 18 Iter 36 - Loss: 11.898\n",
      "Epoch 18 Iter 37 - Loss: 9.054\n",
      "Epoch 18 Iter 38 - Loss: 8.450\n",
      "Epoch 18 Iter 39 - Loss: 12.011\n",
      "Epoch 18 Iter 40 - Loss: 9.928\n",
      "Epoch 18 Iter 41 - Loss: 11.936\n",
      "Epoch 18 Iter 42 - Loss: 11.752\n",
      "Epoch 18 Iter 43 - Loss: 11.734\n",
      "Epoch 18 Iter 44 - Loss: 10.751\n",
      "Epoch 18 Iter 45 - Loss: 8.690\n",
      "Epoch 19 Iter 2 - Loss: 9.567\n",
      "Epoch 19 Iter 3 - Loss: 12.405\n",
      "Epoch 19 Iter 4 - Loss: 8.625\n",
      "Epoch 19 Iter 5 - Loss: 9.264\n",
      "Epoch 19 Iter 6 - Loss: 12.224\n",
      "Epoch 19 Iter 7 - Loss: 9.346\n",
      "Epoch 19 Iter 8 - Loss: 9.978\n",
      "Epoch 19 Iter 9 - Loss: 12.603\n",
      "Epoch 19 Iter 10 - Loss: 10.889\n",
      "Epoch 19 Iter 11 - Loss: 9.994\n",
      "Epoch 19 Iter 12 - Loss: 11.511\n",
      "Epoch 19 Iter 13 - Loss: 8.518\n",
      "Epoch 19 Iter 14 - Loss: 11.990\n",
      "Epoch 19 Iter 15 - Loss: 10.595\n",
      "Epoch 19 Iter 16 - Loss: 11.007\n",
      "Epoch 19 Iter 17 - Loss: 9.783\n",
      "Epoch 19 Iter 18 - Loss: 9.122\n",
      "Epoch 19 Iter 19 - Loss: 9.691\n",
      "Epoch 19 Iter 20 - Loss: 9.048\n",
      "Epoch 19 Iter 21 - Loss: 9.659\n",
      "Epoch 19 Iter 22 - Loss: 9.838\n",
      "Epoch 19 Iter 23 - Loss: 10.388\n",
      "Epoch 19 Iter 24 - Loss: 12.365\n",
      "Epoch 19 Iter 25 - Loss: 10.617\n",
      "Epoch 19 Iter 26 - Loss: 9.040\n",
      "Epoch 19 Iter 27 - Loss: 12.054\n",
      "Epoch 19 Iter 28 - Loss: 10.753\n",
      "Epoch 19 Iter 29 - Loss: 9.643\n",
      "Epoch 19 Iter 30 - Loss: 8.382\n",
      "Epoch 19 Iter 31 - Loss: 8.771\n",
      "Epoch 19 Iter 32 - Loss: 12.837\n",
      "Epoch 19 Iter 33 - Loss: 9.316\n",
      "Epoch 19 Iter 34 - Loss: 8.872\n",
      "Epoch 19 Iter 35 - Loss: 11.309\n",
      "Epoch 19 Iter 36 - Loss: 11.392\n",
      "Epoch 19 Iter 37 - Loss: 9.454\n",
      "Epoch 19 Iter 38 - Loss: 9.468\n",
      "Epoch 19 Iter 39 - Loss: 10.579\n",
      "Epoch 19 Iter 40 - Loss: 10.048\n",
      "Epoch 19 Iter 41 - Loss: 9.995\n",
      "Epoch 19 Iter 42 - Loss: 9.758\n",
      "Epoch 19 Iter 43 - Loss: 10.282\n",
      "Epoch 19 Iter 44 - Loss: 7.770\n",
      "Epoch 19 Iter 45 - Loss: 7.172\n",
      "Epoch 20 Iter 2 - Loss: 9.810\n",
      "Epoch 20 Iter 3 - Loss: 9.631\n",
      "Epoch 20 Iter 4 - Loss: 8.475\n",
      "Epoch 20 Iter 5 - Loss: 10.540\n",
      "Epoch 20 Iter 6 - Loss: 10.302\n",
      "Epoch 20 Iter 7 - Loss: 10.152\n",
      "Epoch 20 Iter 8 - Loss: 11.170\n",
      "Epoch 20 Iter 9 - Loss: 10.291\n",
      "Epoch 20 Iter 10 - Loss: 9.750\n",
      "Epoch 20 Iter 11 - Loss: 8.462\n",
      "Epoch 20 Iter 12 - Loss: 9.406\n",
      "Epoch 20 Iter 13 - Loss: 8.512\n",
      "Epoch 20 Iter 14 - Loss: 11.165\n",
      "Epoch 20 Iter 15 - Loss: 10.608\n",
      "Epoch 20 Iter 16 - Loss: 9.123\n",
      "Epoch 20 Iter 17 - Loss: 10.454\n",
      "Epoch 20 Iter 18 - Loss: 10.611\n",
      "Epoch 20 Iter 19 - Loss: 10.203\n",
      "Epoch 20 Iter 20 - Loss: 13.325\n",
      "Epoch 20 Iter 21 - Loss: 11.311\n",
      "Epoch 20 Iter 22 - Loss: 10.614\n",
      "Epoch 20 Iter 23 - Loss: 9.968\n",
      "Epoch 20 Iter 24 - Loss: 11.770\n",
      "Epoch 20 Iter 25 - Loss: 10.643\n",
      "Epoch 20 Iter 26 - Loss: 10.222\n",
      "Epoch 20 Iter 27 - Loss: 9.447\n",
      "Epoch 20 Iter 28 - Loss: 8.179\n",
      "Epoch 20 Iter 29 - Loss: 8.448\n",
      "Epoch 20 Iter 30 - Loss: 10.709\n",
      "Epoch 20 Iter 31 - Loss: 9.010\n",
      "Epoch 20 Iter 32 - Loss: 11.026\n",
      "Epoch 20 Iter 33 - Loss: 10.338\n",
      "Epoch 20 Iter 34 - Loss: 9.508\n",
      "Epoch 20 Iter 35 - Loss: 10.849\n",
      "Epoch 20 Iter 36 - Loss: 11.028\n",
      "Epoch 20 Iter 37 - Loss: 7.873\n",
      "Epoch 20 Iter 38 - Loss: 9.451\n",
      "Epoch 20 Iter 39 - Loss: 10.481\n",
      "Epoch 20 Iter 40 - Loss: 9.914\n",
      "Epoch 20 Iter 41 - Loss: 8.472\n",
      "Epoch 20 Iter 42 - Loss: 9.309\n",
      "Epoch 20 Iter 43 - Loss: 8.307\n",
      "Epoch 20 Iter 44 - Loss: 9.516\n",
      "Epoch 20 Iter 45 - Loss: 8.550\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "inducing_points = xs[np.random.choice(xs.size(0),1000,replace=False),:]\n",
    "model = GPModel(inducing_points=inducing_points).double()\n",
    "likelihood = GaussianLikelihood().double()\n",
    "\n",
    "train_dataset = TensorDataset(xs, ys)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "# initialize model parameters\n",
    "# model.t_covar_module.base_kernel.kernels[0].raw_lengthscale.require_grad = False\n",
    "# model.t_covar_module.base_kernel.kernels[0].lengthscale = 0.01\n",
    "# model.t_covar_module.raw_outputscale.require_grad = False\n",
    "# model.t_covar_module.outputscale = 1.\n",
    "model.covar_module.raw_outputscale.requires_grad = False\n",
    "model.covar_module.outputscale = 1.\n",
    "likelihood.noise = 1.\n",
    "\n",
    "# train model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': list(set(model.parameters()) - \\\n",
    "                {\\\n",
    "                #     model.t_covar_module.base_kernel.kernels[0].raw_lengthscale,\\\n",
    "                # model.t_covar_module.raw_outputscale,\\\n",
    "                \\\n",
    "                model.covar_module.raw_outputscale})},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=ys.size(0))\n",
    "\n",
    "num_epochs = 20\n",
    "for i in range(num_epochs):\n",
    "    for j, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)\n",
    "        loss = -mll(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j % 2000:\n",
    "            print('Epoch %d Iter %d - Loss: %.3f' % (i + 1, j+1, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model and likelihood to evaluation mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    out = model(xs)\n",
    "    mu_f = out.mean.numpy()\n",
    "    lower, upper = out.confidence_region()\n",
    "\n",
    "# store results\n",
    "results = pd.DataFrame({\"gpr_mean\":mu_f})\n",
    "results['true_y'] = ys\n",
    "results['gpr_lwr'] = lower\n",
    "results['gpr_upr'] = upper\n",
    "results['month'] = xs[:,1].numpy().astype(int)\n",
    "results['unit'] = xs[:,0].numpy().astype(int)\n",
    "results.to_csv(\"./results/exile_fitted_gpr.csv\",index=False) #save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# number of empirically sample \n",
    "n_samples = 100\n",
    "x_grad = np.zeros((xs.size(0),xs.size(1)))\n",
    "sampled_dydtest_x = np.zeros((n_samples, xs.size(0),xs.size(1)))\n",
    "\n",
    "# we proceed in small batches of size 100 for speed up\n",
    "for i in range(xs.size(0)//100):\n",
    "    with gpytorch.settings.fast_pred_var():\n",
    "        test_x = xs[(i*100):(i*100+100)].clone().detach().requires_grad_(True)\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "        dydtest_x = torch.autograd.grad(observed_pred.mean.sum(), test_x, retain_graph=True)[0]\n",
    "        x_grad[(i*100):(i*100+100)] = dydtest_x\n",
    "\n",
    "        sampled_pred = observed_pred.rsample(torch.Size([n_samples]))\n",
    "        sampled_dydtest_x[:,(i*100):(i*100+100),:] = torch.stack([torch.autograd.grad(pred.sum(), \\\n",
    "                                    test_x, retain_graph=True)[0] for pred in sampled_pred])\n",
    "        \n",
    "# last 100 rows\n",
    "with gpytorch.settings.fast_pred_var():\n",
    "    test_x = xs[(100*i+100):].clone().detach().requires_grad_(True)\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "    dydtest_x = torch.autograd.grad(observed_pred.mean.sum(), test_x, retain_graph=True)[0]\n",
    "    x_grad[(100*i+100):] = dydtest_x\n",
    "\n",
    "    sampled_pred = observed_pred.rsample(torch.Size([n_samples]))\n",
    "    sampled_dydtest_x[:,(100*i+100):,:] = torch.stack([torch.autograd.grad(pred.sum(),\\\n",
    "                                     test_x, retain_graph=True)[0] for pred in sampled_pred])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-020a295a6012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m results = pd.DataFrame({\"x\": covariate_names, \\\n\u001b[1;32m      7\u001b[0m                         \u001b[0;34m'est_mean'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                         'est_std': est_std[1:]})\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'est_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'est_std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pvalue\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         ]\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "est_std = np.sqrt(sampled_dydtest_x.mean(1).std(0)**2 + \\\n",
    "                  sampled_dydtest_x.std(1).mean(0)**2).round(decimals=5)\n",
    "covariate_names = [\"time\",\"log_num_tweets\"]\n",
    "# for tmp in pd.get_dummies(data['lead_lags']).columns.tolist():\n",
    "#     covariate_names.append(\"beta \"+tmp)\n",
    "results = pd.DataFrame({\"x\": covariate_names, \\\n",
    "                        'est_mean': x_grad.mean(axis=0)[1:],\n",
    "                        'est_std': est_std[1:]})\n",
    "results[\"t\"] = results['est_mean'].values/results['est_std'].values\n",
    "results[\"pvalue\"] = 1 - norm.cdf(np.abs(results[\"t\"].values))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-4feb01bb0931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mplot_est_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta month_before\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mest_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mplot_est_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mest_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mplot_est_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mest_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_est_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplot_est_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot_est_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "plot_est_mean = []\n",
    "plot_est_std = []\n",
    "for i in range(-6,12):\n",
    "    if i==-7:\n",
    "        plot_est_mean.append(results[results.x==(\"beta pre\")].est_mean.values[0])\n",
    "        plot_est_std.append(results[results.x==(\"beta pre\")].est_std.values[0])\n",
    "    elif i==12:\n",
    "        plot_est_mean.append(results[results.x==(\"beta post\")].est_mean.values[0])\n",
    "        plot_est_std.append(results[results.x==(\"beta post\")].est_std.values[0])\n",
    "    elif i==-1:\n",
    "        plot_est_mean.append(results[results.x==(\"beta month_before\")].est_mean.values[0])\n",
    "        plot_est_std.append(results[results.x==(\"beta month_before\")].est_std.values[0])\n",
    "    else:\n",
    "        plot_est_mean.append(results[results.x==(\"beta \"+str(i))].est_mean.values[0])\n",
    "        plot_est_std.append(results[results.x==(\"beta \"+str(i))].est_std.values[0])\n",
    "ax.errorbar([i  for i in range(-6,12)], np.array(plot_est_mean)-plot_est_mean[5], yerr=plot_est_std, fmt=\"k\", ecolor=\"k\")\n",
    "ax.axvline(x=-0.5, ls=\"--\", color=\"gray\")\n",
    "ax.axhline(y=0, ls=\"--\", color=\"gray\")\n",
    "ax.set_xlabel(\"Months Since Exile\")\n",
    "ax.set_ylabel(\"Change in % Tweets on Harsh Criticism\")\n",
    "ax.set_xticks(range(-5,10,5))\n",
    "ax.spines['top'].set_color('gray')\n",
    "ax.spines['right'].set_color('gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we estimate effect of exile on percentage of harsh criticism for left panel of figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"./data/exile.csv\")\n",
    "data = data[[\"perc_harsh_criticism\", \"exile\", \"month\",\"num_tweets\", \"date_of_exile\", \"actor.id\"]]\n",
    "\n",
    "def diff_month(d1, d2):\n",
    "    d1 = datetime.strptime(d1,\"%Y-%m-%d\")\n",
    "    d2 = datetime.strptime(d2,\"%Y-%m-%d\")\n",
    "    return (d1.year - d2.year) * 12 + d1.month - d2.month\n",
    "\n",
    "# xs: unit id, month, log_num_tweets, exile\n",
    "xs = data.month.apply(lambda x: diff_month(x,\"2013-01-01\"))\n",
    "xs = torch.tensor(np.hstack((data[\"actor.id\"].astype('category').cat.codes.values.reshape((-1,1)),\\\n",
    "                    xs.values.reshape((-1,1)),\n",
    "                    np.log(data.num_tweets.values+1).reshape((-1,1)), \\\n",
    "                    data['exile'].values.reshape((-1,1))==\"yes\")))\n",
    "ys = torch.tensor(data.perc_harsh_criticism.values).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.means import Mean\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "\n",
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=False)\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        # linear mean\n",
    "        self.mean_module = LinearMean(input_size=(inducing_points.size(1)-2), bias=False)\n",
    "        self.covar_module = ScaleKernel(RBFKernel(ard_num_dims=(inducing_points.size(1)-2)))\n",
    "        self.t_covar_module = ScaleKernel(RBFKernel(active_dims=[0])*RBFKernel(active_dims=[1,2]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x[:,2:])\n",
    "        covar_x =  self.t_covar_module(x) # self.covar_module(x[:,2:]) +\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iter 2 - Loss: 178.160\n",
      "Epoch 1 Iter 3 - Loss: 171.044\n",
      "Epoch 1 Iter 4 - Loss: 174.585\n",
      "Epoch 1 Iter 5 - Loss: 155.254\n",
      "Epoch 1 Iter 6 - Loss: 109.192\n",
      "Epoch 1 Iter 7 - Loss: 121.211\n",
      "Epoch 1 Iter 8 - Loss: 106.765\n",
      "Epoch 1 Iter 9 - Loss: 101.079\n",
      "Epoch 1 Iter 10 - Loss: 97.810\n",
      "Epoch 1 Iter 11 - Loss: 96.693\n",
      "Epoch 1 Iter 12 - Loss: 100.591\n",
      "Epoch 1 Iter 13 - Loss: 91.283\n",
      "Epoch 1 Iter 14 - Loss: 87.534\n",
      "Epoch 1 Iter 15 - Loss: 76.135\n",
      "Epoch 1 Iter 16 - Loss: 69.843\n",
      "Epoch 1 Iter 17 - Loss: 68.789\n",
      "Epoch 1 Iter 18 - Loss: 68.475\n",
      "Epoch 1 Iter 19 - Loss: 55.780\n",
      "Epoch 1 Iter 20 - Loss: 57.528\n",
      "Epoch 1 Iter 21 - Loss: 55.917\n",
      "Epoch 1 Iter 22 - Loss: 46.741\n",
      "Epoch 1 Iter 23 - Loss: 53.282\n",
      "Epoch 2 Iter 2 - Loss: 49.578\n",
      "Epoch 2 Iter 3 - Loss: 52.003\n",
      "Epoch 2 Iter 4 - Loss: 43.781\n",
      "Epoch 2 Iter 5 - Loss: 42.412\n",
      "Epoch 2 Iter 6 - Loss: 47.993\n",
      "Epoch 2 Iter 7 - Loss: 40.478\n",
      "Epoch 2 Iter 8 - Loss: 46.655\n",
      "Epoch 2 Iter 9 - Loss: 41.822\n",
      "Epoch 2 Iter 10 - Loss: 42.503\n",
      "Epoch 2 Iter 11 - Loss: 42.345\n",
      "Epoch 2 Iter 12 - Loss: 44.479\n",
      "Epoch 2 Iter 13 - Loss: 42.261\n",
      "Epoch 2 Iter 14 - Loss: 44.721\n",
      "Epoch 2 Iter 15 - Loss: 35.668\n",
      "Epoch 2 Iter 16 - Loss: 38.931\n",
      "Epoch 2 Iter 17 - Loss: 33.162\n",
      "Epoch 2 Iter 18 - Loss: 37.604\n",
      "Epoch 2 Iter 19 - Loss: 35.067\n",
      "Epoch 2 Iter 20 - Loss: 41.955\n",
      "Epoch 2 Iter 21 - Loss: 31.798\n",
      "Epoch 2 Iter 22 - Loss: 35.660\n",
      "Epoch 2 Iter 23 - Loss: 24.756\n",
      "Epoch 3 Iter 2 - Loss: 34.415\n",
      "Epoch 3 Iter 3 - Loss: 37.157\n",
      "Epoch 3 Iter 4 - Loss: 28.678\n",
      "Epoch 3 Iter 5 - Loss: 40.603\n",
      "Epoch 3 Iter 6 - Loss: 33.015\n",
      "Epoch 3 Iter 7 - Loss: 35.279\n",
      "Epoch 3 Iter 8 - Loss: 29.428\n",
      "Epoch 3 Iter 9 - Loss: 33.247\n",
      "Epoch 3 Iter 10 - Loss: 29.391\n",
      "Epoch 3 Iter 11 - Loss: 34.476\n",
      "Epoch 3 Iter 12 - Loss: 33.480\n",
      "Epoch 3 Iter 13 - Loss: 30.181\n",
      "Epoch 3 Iter 14 - Loss: 26.284\n",
      "Epoch 3 Iter 15 - Loss: 29.610\n",
      "Epoch 3 Iter 16 - Loss: 24.021\n",
      "Epoch 3 Iter 17 - Loss: 27.113\n",
      "Epoch 3 Iter 18 - Loss: 33.117\n",
      "Epoch 3 Iter 19 - Loss: 29.057\n",
      "Epoch 3 Iter 20 - Loss: 29.272\n",
      "Epoch 3 Iter 21 - Loss: 27.940\n",
      "Epoch 3 Iter 22 - Loss: 31.184\n",
      "Epoch 3 Iter 23 - Loss: 31.160\n",
      "Epoch 4 Iter 2 - Loss: 30.489\n",
      "Epoch 4 Iter 3 - Loss: 30.386\n",
      "Epoch 4 Iter 4 - Loss: 29.558\n",
      "Epoch 4 Iter 5 - Loss: 27.209\n",
      "Epoch 4 Iter 6 - Loss: 31.450\n",
      "Epoch 4 Iter 7 - Loss: 33.402\n",
      "Epoch 4 Iter 8 - Loss: 23.555\n",
      "Epoch 4 Iter 9 - Loss: 26.549\n",
      "Epoch 4 Iter 10 - Loss: 22.515\n",
      "Epoch 4 Iter 11 - Loss: 24.496\n",
      "Epoch 4 Iter 12 - Loss: 26.780\n",
      "Epoch 4 Iter 13 - Loss: 23.826\n",
      "Epoch 4 Iter 14 - Loss: 23.367\n",
      "Epoch 4 Iter 15 - Loss: 22.858\n",
      "Epoch 4 Iter 16 - Loss: 25.855\n",
      "Epoch 4 Iter 17 - Loss: 23.644\n",
      "Epoch 4 Iter 18 - Loss: 22.626\n",
      "Epoch 4 Iter 19 - Loss: 26.166\n",
      "Epoch 4 Iter 20 - Loss: 22.821\n",
      "Epoch 4 Iter 21 - Loss: 25.018\n",
      "Epoch 4 Iter 22 - Loss: 24.706\n",
      "Epoch 4 Iter 23 - Loss: 32.678\n",
      "Epoch 5 Iter 2 - Loss: 24.833\n",
      "Epoch 5 Iter 3 - Loss: 22.497\n",
      "Epoch 5 Iter 4 - Loss: 22.957\n",
      "Epoch 5 Iter 5 - Loss: 22.362\n",
      "Epoch 5 Iter 6 - Loss: 21.605\n",
      "Epoch 5 Iter 7 - Loss: 20.332\n",
      "Epoch 5 Iter 8 - Loss: 25.682\n",
      "Epoch 5 Iter 9 - Loss: 22.353\n",
      "Epoch 5 Iter 10 - Loss: 24.577\n",
      "Epoch 5 Iter 11 - Loss: 20.206\n",
      "Epoch 5 Iter 12 - Loss: 26.490\n",
      "Epoch 5 Iter 13 - Loss: 22.242\n",
      "Epoch 5 Iter 14 - Loss: 22.325\n",
      "Epoch 5 Iter 15 - Loss: 21.739\n",
      "Epoch 5 Iter 16 - Loss: 21.241\n",
      "Epoch 5 Iter 17 - Loss: 25.013\n",
      "Epoch 5 Iter 18 - Loss: 21.958\n",
      "Epoch 5 Iter 19 - Loss: 22.369\n",
      "Epoch 5 Iter 20 - Loss: 23.355\n",
      "Epoch 5 Iter 21 - Loss: 21.922\n",
      "Epoch 5 Iter 22 - Loss: 19.735\n",
      "Epoch 5 Iter 23 - Loss: 29.482\n",
      "Epoch 6 Iter 2 - Loss: 18.596\n",
      "Epoch 6 Iter 3 - Loss: 18.683\n",
      "Epoch 6 Iter 4 - Loss: 20.881\n",
      "Epoch 6 Iter 5 - Loss: 18.224\n",
      "Epoch 6 Iter 6 - Loss: 19.447\n",
      "Epoch 6 Iter 7 - Loss: 20.944\n",
      "Epoch 6 Iter 8 - Loss: 19.974\n",
      "Epoch 6 Iter 9 - Loss: 20.139\n",
      "Epoch 6 Iter 10 - Loss: 18.480\n",
      "Epoch 6 Iter 11 - Loss: 22.068\n",
      "Epoch 6 Iter 12 - Loss: 19.581\n",
      "Epoch 6 Iter 13 - Loss: 18.815\n",
      "Epoch 6 Iter 14 - Loss: 23.102\n",
      "Epoch 6 Iter 15 - Loss: 21.211\n",
      "Epoch 6 Iter 16 - Loss: 19.639\n",
      "Epoch 6 Iter 17 - Loss: 19.178\n",
      "Epoch 6 Iter 18 - Loss: 18.616\n",
      "Epoch 6 Iter 19 - Loss: 20.411\n",
      "Epoch 6 Iter 20 - Loss: 21.724\n",
      "Epoch 6 Iter 21 - Loss: 19.226\n",
      "Epoch 6 Iter 22 - Loss: 17.400\n",
      "Epoch 6 Iter 23 - Loss: 35.792\n",
      "Epoch 7 Iter 2 - Loss: 20.567\n",
      "Epoch 7 Iter 3 - Loss: 18.269\n",
      "Epoch 7 Iter 4 - Loss: 20.967\n",
      "Epoch 7 Iter 5 - Loss: 16.850\n",
      "Epoch 7 Iter 6 - Loss: 21.130\n",
      "Epoch 7 Iter 7 - Loss: 18.769\n",
      "Epoch 7 Iter 8 - Loss: 14.780\n",
      "Epoch 7 Iter 9 - Loss: 15.411\n",
      "Epoch 7 Iter 10 - Loss: 19.269\n",
      "Epoch 7 Iter 11 - Loss: 17.576\n",
      "Epoch 7 Iter 12 - Loss: 19.142\n",
      "Epoch 7 Iter 13 - Loss: 19.128\n",
      "Epoch 7 Iter 14 - Loss: 21.967\n",
      "Epoch 7 Iter 15 - Loss: 18.009\n",
      "Epoch 7 Iter 16 - Loss: 21.749\n",
      "Epoch 7 Iter 17 - Loss: 17.878\n",
      "Epoch 7 Iter 18 - Loss: 13.273\n",
      "Epoch 7 Iter 19 - Loss: 18.563\n",
      "Epoch 7 Iter 20 - Loss: 18.828\n",
      "Epoch 7 Iter 21 - Loss: 16.529\n",
      "Epoch 7 Iter 22 - Loss: 15.549\n",
      "Epoch 7 Iter 23 - Loss: 13.294\n",
      "Epoch 8 Iter 2 - Loss: 19.756\n",
      "Epoch 8 Iter 3 - Loss: 18.089\n",
      "Epoch 8 Iter 4 - Loss: 17.174\n",
      "Epoch 8 Iter 5 - Loss: 15.233\n",
      "Epoch 8 Iter 6 - Loss: 16.666\n",
      "Epoch 8 Iter 7 - Loss: 14.932\n",
      "Epoch 8 Iter 8 - Loss: 15.100\n",
      "Epoch 8 Iter 9 - Loss: 18.855\n",
      "Epoch 8 Iter 10 - Loss: 16.936\n",
      "Epoch 8 Iter 11 - Loss: 14.067\n",
      "Epoch 8 Iter 12 - Loss: 18.821\n",
      "Epoch 8 Iter 13 - Loss: 14.170\n",
      "Epoch 8 Iter 14 - Loss: 16.862\n",
      "Epoch 8 Iter 15 - Loss: 18.557\n",
      "Epoch 8 Iter 16 - Loss: 22.339\n",
      "Epoch 8 Iter 17 - Loss: 19.289\n",
      "Epoch 8 Iter 18 - Loss: 16.838\n",
      "Epoch 8 Iter 19 - Loss: 18.307\n",
      "Epoch 8 Iter 20 - Loss: 12.691\n",
      "Epoch 8 Iter 21 - Loss: 16.489\n",
      "Epoch 8 Iter 22 - Loss: 12.762\n",
      "Epoch 8 Iter 23 - Loss: 15.384\n",
      "Epoch 9 Iter 2 - Loss: 13.698\n",
      "Epoch 9 Iter 3 - Loss: 16.700\n",
      "Epoch 9 Iter 4 - Loss: 12.945\n",
      "Epoch 9 Iter 5 - Loss: 16.510\n",
      "Epoch 9 Iter 6 - Loss: 16.843\n",
      "Epoch 9 Iter 7 - Loss: 14.733\n",
      "Epoch 9 Iter 8 - Loss: 14.006\n",
      "Epoch 9 Iter 9 - Loss: 19.103\n",
      "Epoch 9 Iter 10 - Loss: 14.705\n",
      "Epoch 9 Iter 11 - Loss: 13.337\n",
      "Epoch 9 Iter 12 - Loss: 18.563\n",
      "Epoch 9 Iter 13 - Loss: 13.025\n",
      "Epoch 9 Iter 14 - Loss: 19.009\n",
      "Epoch 9 Iter 15 - Loss: 15.867\n",
      "Epoch 9 Iter 16 - Loss: 16.613\n",
      "Epoch 9 Iter 17 - Loss: 21.931\n",
      "Epoch 9 Iter 18 - Loss: 13.467\n",
      "Epoch 9 Iter 19 - Loss: 15.847\n",
      "Epoch 9 Iter 20 - Loss: 16.150\n",
      "Epoch 9 Iter 21 - Loss: 13.190\n",
      "Epoch 9 Iter 22 - Loss: 15.371\n",
      "Epoch 9 Iter 23 - Loss: 28.440\n",
      "Epoch 10 Iter 2 - Loss: 16.620\n",
      "Epoch 10 Iter 3 - Loss: 13.239\n",
      "Epoch 10 Iter 4 - Loss: 15.714\n",
      "Epoch 10 Iter 5 - Loss: 18.104\n",
      "Epoch 10 Iter 6 - Loss: 16.686\n",
      "Epoch 10 Iter 7 - Loss: 13.967\n",
      "Epoch 10 Iter 8 - Loss: 14.487\n",
      "Epoch 10 Iter 9 - Loss: 14.280\n",
      "Epoch 10 Iter 10 - Loss: 17.380\n",
      "Epoch 10 Iter 11 - Loss: 13.171\n",
      "Epoch 10 Iter 12 - Loss: 16.055\n",
      "Epoch 10 Iter 13 - Loss: 14.410\n",
      "Epoch 10 Iter 14 - Loss: 13.567\n",
      "Epoch 10 Iter 15 - Loss: 16.800\n",
      "Epoch 10 Iter 16 - Loss: 15.380\n",
      "Epoch 10 Iter 17 - Loss: 14.850\n",
      "Epoch 10 Iter 18 - Loss: 16.255\n",
      "Epoch 10 Iter 19 - Loss: 13.421\n",
      "Epoch 10 Iter 20 - Loss: 15.000\n",
      "Epoch 10 Iter 21 - Loss: 12.777\n",
      "Epoch 10 Iter 22 - Loss: 15.138\n",
      "Epoch 10 Iter 23 - Loss: 10.886\n",
      "Epoch 11 Iter 2 - Loss: 15.279\n",
      "Epoch 11 Iter 3 - Loss: 14.152\n",
      "Epoch 11 Iter 4 - Loss: 17.493\n",
      "Epoch 11 Iter 5 - Loss: 13.785\n",
      "Epoch 11 Iter 6 - Loss: 14.609\n",
      "Epoch 11 Iter 7 - Loss: 11.639\n",
      "Epoch 11 Iter 8 - Loss: 16.266\n",
      "Epoch 11 Iter 9 - Loss: 15.406\n",
      "Epoch 11 Iter 10 - Loss: 17.594\n",
      "Epoch 11 Iter 11 - Loss: 13.767\n",
      "Epoch 11 Iter 12 - Loss: 14.180\n",
      "Epoch 11 Iter 13 - Loss: 13.104\n",
      "Epoch 11 Iter 14 - Loss: 15.288\n",
      "Epoch 11 Iter 15 - Loss: 13.318\n",
      "Epoch 11 Iter 16 - Loss: 14.669\n",
      "Epoch 11 Iter 17 - Loss: 15.299\n",
      "Epoch 11 Iter 18 - Loss: 14.134\n",
      "Epoch 11 Iter 19 - Loss: 14.835\n",
      "Epoch 11 Iter 20 - Loss: 11.827\n",
      "Epoch 11 Iter 21 - Loss: 14.159\n",
      "Epoch 11 Iter 22 - Loss: 11.069\n",
      "Epoch 11 Iter 23 - Loss: 20.277\n",
      "Epoch 12 Iter 2 - Loss: 12.573\n",
      "Epoch 12 Iter 3 - Loss: 13.169\n",
      "Epoch 12 Iter 4 - Loss: 13.319\n",
      "Epoch 12 Iter 5 - Loss: 14.385\n",
      "Epoch 12 Iter 6 - Loss: 13.925\n",
      "Epoch 12 Iter 7 - Loss: 15.041\n",
      "Epoch 12 Iter 8 - Loss: 15.068\n",
      "Epoch 12 Iter 9 - Loss: 12.424\n",
      "Epoch 12 Iter 10 - Loss: 12.342\n",
      "Epoch 12 Iter 11 - Loss: 11.295\n",
      "Epoch 12 Iter 12 - Loss: 15.094\n",
      "Epoch 12 Iter 13 - Loss: 13.203\n",
      "Epoch 12 Iter 14 - Loss: 12.272\n",
      "Epoch 12 Iter 15 - Loss: 13.685\n",
      "Epoch 12 Iter 16 - Loss: 12.613\n",
      "Epoch 12 Iter 17 - Loss: 16.465\n",
      "Epoch 12 Iter 18 - Loss: 13.436\n",
      "Epoch 12 Iter 19 - Loss: 15.445\n",
      "Epoch 12 Iter 20 - Loss: 14.003\n",
      "Epoch 12 Iter 21 - Loss: 14.347\n",
      "Epoch 12 Iter 22 - Loss: 16.210\n",
      "Epoch 12 Iter 23 - Loss: 12.086\n",
      "Epoch 13 Iter 2 - Loss: 14.749\n",
      "Epoch 13 Iter 3 - Loss: 13.957\n",
      "Epoch 13 Iter 4 - Loss: 11.836\n",
      "Epoch 13 Iter 5 - Loss: 12.155\n",
      "Epoch 13 Iter 6 - Loss: 13.883\n",
      "Epoch 13 Iter 7 - Loss: 15.936\n",
      "Epoch 13 Iter 8 - Loss: 9.665\n",
      "Epoch 13 Iter 9 - Loss: 11.835\n",
      "Epoch 13 Iter 10 - Loss: 12.983\n",
      "Epoch 13 Iter 11 - Loss: 12.060\n",
      "Epoch 13 Iter 12 - Loss: 12.719\n",
      "Epoch 13 Iter 13 - Loss: 14.317\n",
      "Epoch 13 Iter 14 - Loss: 15.261\n",
      "Epoch 13 Iter 15 - Loss: 12.743\n",
      "Epoch 13 Iter 16 - Loss: 13.289\n",
      "Epoch 13 Iter 17 - Loss: 12.773\n",
      "Epoch 13 Iter 18 - Loss: 13.536\n",
      "Epoch 13 Iter 19 - Loss: 13.336\n",
      "Epoch 13 Iter 20 - Loss: 12.618\n",
      "Epoch 13 Iter 21 - Loss: 12.819\n",
      "Epoch 13 Iter 22 - Loss: 14.272\n",
      "Epoch 13 Iter 23 - Loss: 16.393\n",
      "Epoch 14 Iter 2 - Loss: 12.597\n",
      "Epoch 14 Iter 3 - Loss: 15.063\n",
      "Epoch 14 Iter 4 - Loss: 14.357\n",
      "Epoch 14 Iter 5 - Loss: 14.102\n",
      "Epoch 14 Iter 6 - Loss: 13.272\n",
      "Epoch 14 Iter 7 - Loss: 13.610\n",
      "Epoch 14 Iter 8 - Loss: 10.213\n",
      "Epoch 14 Iter 9 - Loss: 11.141\n",
      "Epoch 14 Iter 10 - Loss: 15.409\n",
      "Epoch 14 Iter 11 - Loss: 12.535\n",
      "Epoch 14 Iter 12 - Loss: 10.826\n",
      "Epoch 14 Iter 13 - Loss: 15.058\n",
      "Epoch 14 Iter 14 - Loss: 11.800\n",
      "Epoch 14 Iter 15 - Loss: 12.200\n",
      "Epoch 14 Iter 16 - Loss: 15.162\n",
      "Epoch 14 Iter 17 - Loss: 12.281\n",
      "Epoch 14 Iter 18 - Loss: 12.903\n",
      "Epoch 14 Iter 19 - Loss: 12.389\n",
      "Epoch 14 Iter 20 - Loss: 11.135\n",
      "Epoch 14 Iter 21 - Loss: 13.647\n",
      "Epoch 14 Iter 22 - Loss: 10.921\n",
      "Epoch 14 Iter 23 - Loss: 11.857\n",
      "Epoch 15 Iter 2 - Loss: 12.386\n",
      "Epoch 15 Iter 3 - Loss: 13.572\n",
      "Epoch 15 Iter 4 - Loss: 13.499\n",
      "Epoch 15 Iter 5 - Loss: 10.576\n",
      "Epoch 15 Iter 6 - Loss: 12.385\n",
      "Epoch 15 Iter 7 - Loss: 11.697\n",
      "Epoch 15 Iter 8 - Loss: 15.039\n",
      "Epoch 15 Iter 9 - Loss: 11.963\n",
      "Epoch 15 Iter 10 - Loss: 12.596\n",
      "Epoch 15 Iter 11 - Loss: 13.427\n",
      "Epoch 15 Iter 12 - Loss: 12.877\n",
      "Epoch 15 Iter 13 - Loss: 12.309\n",
      "Epoch 15 Iter 14 - Loss: 11.958\n",
      "Epoch 15 Iter 15 - Loss: 13.171\n",
      "Epoch 15 Iter 16 - Loss: 13.301\n",
      "Epoch 15 Iter 17 - Loss: 11.307\n",
      "Epoch 15 Iter 18 - Loss: 13.125\n",
      "Epoch 15 Iter 19 - Loss: 12.204\n",
      "Epoch 15 Iter 20 - Loss: 11.030\n",
      "Epoch 15 Iter 21 - Loss: 12.143\n",
      "Epoch 15 Iter 22 - Loss: 12.884\n",
      "Epoch 15 Iter 23 - Loss: 10.352\n",
      "Epoch 16 Iter 2 - Loss: 12.337\n",
      "Epoch 16 Iter 3 - Loss: 12.046\n",
      "Epoch 16 Iter 4 - Loss: 12.266\n",
      "Epoch 16 Iter 5 - Loss: 10.370\n",
      "Epoch 16 Iter 6 - Loss: 12.590\n",
      "Epoch 16 Iter 7 - Loss: 13.259\n",
      "Epoch 16 Iter 8 - Loss: 15.041\n",
      "Epoch 16 Iter 9 - Loss: 12.268\n",
      "Epoch 16 Iter 10 - Loss: 13.180\n",
      "Epoch 16 Iter 11 - Loss: 11.887\n",
      "Epoch 16 Iter 12 - Loss: 12.134\n",
      "Epoch 16 Iter 13 - Loss: 10.884\n",
      "Epoch 16 Iter 14 - Loss: 12.012\n",
      "Epoch 16 Iter 15 - Loss: 10.915\n",
      "Epoch 16 Iter 16 - Loss: 10.797\n",
      "Epoch 16 Iter 17 - Loss: 12.307\n",
      "Epoch 16 Iter 18 - Loss: 12.397\n",
      "Epoch 16 Iter 19 - Loss: 11.013\n",
      "Epoch 16 Iter 20 - Loss: 12.211\n",
      "Epoch 16 Iter 21 - Loss: 13.448\n",
      "Epoch 16 Iter 22 - Loss: 12.028\n",
      "Epoch 16 Iter 23 - Loss: 11.450\n",
      "Epoch 17 Iter 2 - Loss: 11.097\n",
      "Epoch 17 Iter 3 - Loss: 14.156\n",
      "Epoch 17 Iter 4 - Loss: 12.129\n",
      "Epoch 17 Iter 5 - Loss: 12.236\n",
      "Epoch 17 Iter 6 - Loss: 13.088\n",
      "Epoch 17 Iter 7 - Loss: 10.368\n",
      "Epoch 17 Iter 8 - Loss: 10.089\n",
      "Epoch 17 Iter 9 - Loss: 12.652\n",
      "Epoch 17 Iter 10 - Loss: 10.734\n",
      "Epoch 17 Iter 11 - Loss: 14.401\n",
      "Epoch 17 Iter 12 - Loss: 12.279\n",
      "Epoch 17 Iter 13 - Loss: 10.134\n",
      "Epoch 17 Iter 14 - Loss: 14.491\n",
      "Epoch 17 Iter 15 - Loss: 12.788\n",
      "Epoch 17 Iter 16 - Loss: 12.020\n",
      "Epoch 17 Iter 17 - Loss: 9.711\n",
      "Epoch 17 Iter 18 - Loss: 12.408\n",
      "Epoch 17 Iter 19 - Loss: 10.729\n",
      "Epoch 17 Iter 20 - Loss: 12.713\n",
      "Epoch 17 Iter 21 - Loss: 10.742\n",
      "Epoch 17 Iter 22 - Loss: 11.081\n",
      "Epoch 17 Iter 23 - Loss: 7.871\n",
      "Epoch 18 Iter 2 - Loss: 11.188\n",
      "Epoch 18 Iter 3 - Loss: 11.036\n",
      "Epoch 18 Iter 4 - Loss: 12.078\n",
      "Epoch 18 Iter 5 - Loss: 10.217\n",
      "Epoch 18 Iter 6 - Loss: 13.276\n",
      "Epoch 18 Iter 7 - Loss: 12.504\n",
      "Epoch 18 Iter 8 - Loss: 12.625\n",
      "Epoch 18 Iter 9 - Loss: 12.416\n",
      "Epoch 18 Iter 10 - Loss: 12.423\n",
      "Epoch 18 Iter 11 - Loss: 11.526\n",
      "Epoch 18 Iter 12 - Loss: 11.239\n",
      "Epoch 18 Iter 13 - Loss: 10.802\n",
      "Epoch 18 Iter 14 - Loss: 11.750\n",
      "Epoch 18 Iter 15 - Loss: 10.314\n",
      "Epoch 18 Iter 16 - Loss: 10.126\n",
      "Epoch 18 Iter 17 - Loss: 14.642\n",
      "Epoch 18 Iter 18 - Loss: 9.796\n",
      "Epoch 18 Iter 19 - Loss: 11.913\n",
      "Epoch 18 Iter 20 - Loss: 10.914\n",
      "Epoch 18 Iter 21 - Loss: 11.765\n",
      "Epoch 18 Iter 22 - Loss: 12.282\n",
      "Epoch 18 Iter 23 - Loss: 9.170\n",
      "Epoch 19 Iter 2 - Loss: 10.438\n",
      "Epoch 19 Iter 3 - Loss: 12.377\n",
      "Epoch 19 Iter 4 - Loss: 11.184\n",
      "Epoch 19 Iter 5 - Loss: 10.630\n",
      "Epoch 19 Iter 6 - Loss: 11.590\n",
      "Epoch 19 Iter 7 - Loss: 11.062\n",
      "Epoch 19 Iter 8 - Loss: 12.732\n",
      "Epoch 19 Iter 9 - Loss: 8.936\n",
      "Epoch 19 Iter 10 - Loss: 12.364\n",
      "Epoch 19 Iter 11 - Loss: 11.033\n",
      "Epoch 19 Iter 12 - Loss: 10.876\n",
      "Epoch 19 Iter 13 - Loss: 10.021\n",
      "Epoch 19 Iter 14 - Loss: 9.801\n",
      "Epoch 19 Iter 15 - Loss: 14.055\n",
      "Epoch 19 Iter 16 - Loss: 11.046\n",
      "Epoch 19 Iter 17 - Loss: 12.146\n",
      "Epoch 19 Iter 18 - Loss: 11.423\n",
      "Epoch 19 Iter 19 - Loss: 11.935\n",
      "Epoch 19 Iter 20 - Loss: 10.269\n",
      "Epoch 19 Iter 21 - Loss: 13.343\n",
      "Epoch 19 Iter 22 - Loss: 12.317\n",
      "Epoch 19 Iter 23 - Loss: 11.920\n",
      "Epoch 20 Iter 2 - Loss: 10.340\n",
      "Epoch 20 Iter 3 - Loss: 12.638\n",
      "Epoch 20 Iter 4 - Loss: 12.650\n",
      "Epoch 20 Iter 5 - Loss: 10.394\n",
      "Epoch 20 Iter 6 - Loss: 10.699\n",
      "Epoch 20 Iter 7 - Loss: 11.738\n",
      "Epoch 20 Iter 8 - Loss: 13.022\n",
      "Epoch 20 Iter 9 - Loss: 10.873\n",
      "Epoch 20 Iter 10 - Loss: 10.495\n",
      "Epoch 20 Iter 11 - Loss: 10.328\n",
      "Epoch 20 Iter 12 - Loss: 12.144\n",
      "Epoch 20 Iter 13 - Loss: 12.504\n",
      "Epoch 20 Iter 14 - Loss: 12.496\n",
      "Epoch 20 Iter 15 - Loss: 8.488\n",
      "Epoch 20 Iter 16 - Loss: 10.150\n",
      "Epoch 20 Iter 17 - Loss: 11.063\n",
      "Epoch 20 Iter 18 - Loss: 12.361\n",
      "Epoch 20 Iter 19 - Loss: 10.923\n",
      "Epoch 20 Iter 20 - Loss: 10.184\n",
      "Epoch 20 Iter 21 - Loss: 11.496\n",
      "Epoch 20 Iter 22 - Loss: 11.416\n",
      "Epoch 20 Iter 23 - Loss: 6.276\n"
     ]
    }
   ],
   "source": [
    "inducing_points = xs[np.random.choice(xs.size(0),1000,replace=False),:]\n",
    "model = GPModel(inducing_points=inducing_points).double()\n",
    "likelihood = GaussianLikelihood().double()\n",
    "\n",
    "train_dataset = TensorDataset(xs, ys)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "# initialize model parameters\n",
    "model.t_covar_module.base_kernel.kernels[0].raw_lengthscale.require_grad = False\n",
    "model.t_covar_module.base_kernel.kernels[0].lengthscale = 0.1\n",
    "model.t_covar_module.outputscale = 1.\n",
    "likelihood.noise = 1.\n",
    "\n",
    "# train model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': list(set(model.parameters()) - \\\n",
    "                {model.t_covar_module.base_kernel.kernels[0].raw_lengthscale,\\\n",
    "                model.t_covar_module.raw_outputscale})},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=ys.size(0))\n",
    "\n",
    "num_epochs = 20\n",
    "for i in range(num_epochs):\n",
    "    for j, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)\n",
    "        loss = -mll(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j % 200:\n",
    "            print('Epoch %d Iter %d - Loss: %.3f' % (i + 1, j+1, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model and likelihood to evaluation mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    out = model(xs)\n",
    "    mu_f = out.mean.numpy()\n",
    "    lower, upper = out.confidence_region()\n",
    "\n",
    "# store results\n",
    "results = pd.DataFrame({\"gpr_mean\":mu_f})\n",
    "results['true_y'] = ys\n",
    "results['gpr_lwr'] = lower\n",
    "results['gpr_upr'] = upper\n",
    "results['month'] = xs[:,1].numpy().astype(int)\n",
    "results['unit'] = xs[:,0].numpy().astype(int)\n",
    "results.to_csv(\"./results/exile_fitted_gpr.csv\",index=False) #save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# number of empirically sample \n",
    "n_samples = 100\n",
    "x_grad = np.zeros((xs.size(0),xs.size(1)))\n",
    "sampled_dydtest_x = np.zeros((n_samples, xs.size(0),xs.size(1)))\n",
    "\n",
    "# we proceed in small batches of size 100 for speed up\n",
    "for i in range(xs.size(0)//100):\n",
    "    with gpytorch.settings.fast_pred_var():\n",
    "        test_x = xs[(i*100):(i*100+100)].clone().detach().requires_grad_(True)\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "        dydtest_x = torch.autograd.grad(observed_pred.mean.sum(), test_x, retain_graph=True)[0]\n",
    "        x_grad[(i*100):(i*100+100)] = dydtest_x\n",
    "\n",
    "        sampled_pred = observed_pred.rsample(torch.Size([n_samples]))\n",
    "        sampled_dydtest_x[:,(i*100):(i*100+100),:] = torch.stack([torch.autograd.grad(pred.sum(), \\\n",
    "                                    test_x, retain_graph=True)[0] for pred in sampled_pred])\n",
    "        \n",
    "# last 100 rows\n",
    "with gpytorch.settings.fast_pred_var():\n",
    "    test_x = xs[(100*i+100):].clone().detach().requires_grad_(True)\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "    dydtest_x = torch.autograd.grad(observed_pred.mean.sum(), test_x, retain_graph=True)[0]\n",
    "    x_grad[(100*i+100):] = dydtest_x\n",
    "\n",
    "    sampled_pred = observed_pred.rsample(torch.Size([n_samples]))\n",
    "    sampled_dydtest_x[:,(100*i+100):,:] = torch.stack([torch.autograd.grad(pred.sum(),\\\n",
    "                                     test_x, retain_graph=True)[0] for pred in sampled_pred])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                x  est_mean  est_std          t  pvalue\n",
      "0  log_num_tweets  2.577454  0.03093  83.331845     0.0\n"
     ]
    }
   ],
   "source": [
    "est_std = np.sqrt(sampled_dydtest_x.mean(1).std(0)**2 + \\\n",
    "                  sampled_dydtest_x.std(1).mean(0)**2).round(decimals=5)\n",
    "\n",
    "covariate_names = [\"log_num_tweets\"]\n",
    "results = pd.DataFrame({\"x\": covariate_names, \\\n",
    "                        'est_mean': x_grad.mean(axis=0)[2:3],\n",
    "                        'est_std': est_std[2:3]})\n",
    "results[\"t\"] = results['est_mean'].values/results['est_std'].values\n",
    "results[\"pvalue\"] = 1 - norm.cdf(np.abs(results[\"t\"].values))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: 6.359 +- 0.036\n",
      "\n",
      "model evidence: -138.928 \n",
      "\n",
      "BIC: 328.000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# copy training tesnor to test tensors and set exile to 1 and 0\n",
    "test_x1 = xs.clone().detach().requires_grad_(False)\n",
    "test_x1[:,3] = 1\n",
    "test_x0 = xs.clone().detach().requires_grad_(False)\n",
    "test_x0[:,3] = 0\n",
    "\n",
    "# in eval mode the forward() function returns posterioir\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    out1 = likelihood(model(test_x1))\n",
    "    out0 = likelihood(model(test_x0))\n",
    "\n",
    "# compute ATE and its uncertainty\n",
    "effect = out1.mean.numpy().mean() - out0.mean.numpy().mean()\n",
    "effect_std = np.sqrt((out1.mean.numpy().mean()+out0.mean.numpy().mean())) / np.sqrt(xs.size()[0])\n",
    "BIC = (1+1+2+1)*\\\n",
    "    torch.log(torch.tensor(xs.size()[0])) + 2*loss*xs.size(0)/1024\n",
    "print(\"ATE: {:0.3f} +- {:0.3f}\\n\".format(effect, effect_std))\n",
    "print(\"model evidence: {:0.3f} \\n\".format(-loss*xs.size(0)/1024))\n",
    "print(\"BIC: {:0.3f} \\n\".format(BIC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS Regression Results                             \n",
      "================================================================================\n",
      "Dep. Variable:     perc_harsh_criticism   R-squared:                       0.209\n",
      "Model:                              OLS   Adj. R-squared:                  0.206\n",
      "Method:                   Least Squares   F-statistic:                     66.28\n",
      "Date:                  Mon, 03 Jun 2024   Prob (F-statistic):               0.00\n",
      "Time:                          14:35:18   Log-Likelihood:                -90566.\n",
      "No. Observations:                 22609   AIC:                         1.813e+05\n",
      "Df Residuals:                     22518   BIC:                         1.820e+05\n",
      "Df Model:                            90                                         \n",
      "Covariance Type:              nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          3.4964      0.956      3.656      0.000       1.622       5.371\n",
      "exile[T.yes]       5.7368      0.195     29.443      0.000       5.355       6.119\n",
      "C(t)[T.1.0]        1.2408      1.303      0.952      0.341      -1.313       3.794\n",
      "C(t)[T.2.0]       -1.9004      1.287     -1.477      0.140      -4.423       0.622\n",
      "C(t)[T.3.0]       -0.5923      1.284     -0.461      0.645      -3.110       1.925\n",
      "C(t)[T.4.0]        0.4099      1.290      0.318      0.751      -2.118       2.938\n",
      "C(t)[T.5.0]       -0.9152      1.291     -0.709      0.478      -3.446       1.615\n",
      "C(t)[T.6.0]        0.0560      1.290      0.043      0.965      -2.472       2.584\n",
      "C(t)[T.7.0]       -1.3473      1.281     -1.051      0.293      -3.859       1.165\n",
      "C(t)[T.8.0]       -0.7573      1.280     -0.592      0.554      -3.267       1.752\n",
      "C(t)[T.9.0]       -1.9129      1.274     -1.502      0.133      -4.409       0.584\n",
      "C(t)[T.10.0]      -1.4896      1.282     -1.162      0.245      -4.001       1.022\n",
      "C(t)[T.11.0]      -1.1186      1.290     -0.867      0.386      -3.646       1.409\n",
      "C(t)[T.12.0]       0.4682      1.286      0.364      0.716      -2.052       2.988\n",
      "C(t)[T.13.0]       7.4578      1.282      5.818      0.000       4.945       9.971\n",
      "C(t)[T.14.0]       7.5914      1.269      5.982      0.000       5.104      10.079\n",
      "C(t)[T.15.0]       3.7966      1.269      2.992      0.003       1.310       6.283\n",
      "C(t)[T.16.0]       5.1134      1.279      3.998      0.000       2.607       7.620\n",
      "C(t)[T.17.0]       2.7167      1.276      2.129      0.033       0.215       5.218\n",
      "C(t)[T.18.0]       1.5982      1.280      1.248      0.212      -0.911       4.107\n",
      "C(t)[T.19.0]       1.0963      1.267      0.865      0.387      -1.388       3.581\n",
      "C(t)[T.20.0]      -0.2264      1.275     -0.178      0.859      -2.725       2.273\n",
      "C(t)[T.21.0]       0.7680      1.274      0.603      0.547      -1.729       3.265\n",
      "C(t)[T.22.0]       0.6527      1.280      0.510      0.610      -1.857       3.162\n",
      "C(t)[T.23.0]       5.1920      1.276      4.068      0.000       2.690       7.693\n",
      "C(t)[T.24.0]       1.8588      1.276      1.456      0.145      -0.643       4.360\n",
      "C(t)[T.25.0]       5.7721      1.271      4.541      0.000       3.280       8.264\n",
      "C(t)[T.26.0]       1.6590      1.260      1.316      0.188      -0.811       4.129\n",
      "C(t)[T.27.0]       0.5001      1.267      0.395      0.693      -1.984       2.984\n",
      "C(t)[T.28.0]       1.5980      1.266      1.262      0.207      -0.884       4.080\n",
      "C(t)[T.29.0]       0.9226      1.260      0.732      0.464      -1.548       3.393\n",
      "C(t)[T.30.0]      -1.3664      1.267     -1.078      0.281      -3.851       1.118\n",
      "C(t)[T.31.0]      -0.7070      1.263     -0.560      0.576      -3.182       1.768\n",
      "C(t)[T.32.0]       0.1618      1.251      0.129      0.897      -2.291       2.614\n",
      "C(t)[T.33.0]      -1.3074      1.245     -1.050      0.294      -3.747       1.132\n",
      "C(t)[T.34.0]      -1.3981      1.244     -1.124      0.261      -3.836       1.040\n",
      "C(t)[T.35.0]      -1.1446      1.245     -0.920      0.358      -3.584       1.295\n",
      "C(t)[T.36.0]      -1.4575      1.241     -1.175      0.240      -3.889       0.974\n",
      "C(t)[T.37.0]       0.7833      1.239      0.632      0.527      -1.646       3.213\n",
      "C(t)[T.38.0]       1.9209      1.246      1.542      0.123      -0.521       4.363\n",
      "C(t)[T.39.0]      -0.1892      1.242     -0.152      0.879      -2.623       2.245\n",
      "C(t)[T.40.0]       0.3869      1.240      0.312      0.755      -2.043       2.817\n",
      "C(t)[T.41.0]       1.2124      1.245      0.974      0.330      -1.228       3.653\n",
      "C(t)[T.42.0]       0.9072      1.239      0.732      0.464      -1.520       3.335\n",
      "C(t)[T.43.0]       1.2130      1.235      0.982      0.326      -1.209       3.635\n",
      "C(t)[T.44.0]       2.9910      1.235      2.423      0.015       0.571       5.411\n",
      "C(t)[T.45.0]       2.9949      1.237      2.422      0.015       0.571       5.419\n",
      "C(t)[T.46.0]       6.7326      1.234      5.454      0.000       4.313       9.152\n",
      "C(t)[T.47.0]       5.9353      1.236      4.800      0.000       3.512       8.359\n",
      "C(t)[T.48.0]       4.9831      1.239      4.020      0.000       2.554       7.413\n",
      "C(t)[T.49.0]       6.0901      1.236      4.926      0.000       3.667       8.514\n",
      "C(t)[T.50.0]       4.4887      1.235      3.636      0.000       2.069       6.908\n",
      "C(t)[T.51.0]      14.0720      1.231     11.431      0.000      11.659      16.485\n",
      "C(t)[T.52.0]      13.5293      1.227     11.025      0.000      11.124      15.935\n",
      "C(t)[T.53.0]      10.5704      1.229      8.602      0.000       8.162      12.979\n",
      "C(t)[T.54.0]       8.6578      1.231      7.032      0.000       6.244      11.071\n",
      "C(t)[T.55.0]       8.8644      1.226      7.231      0.000       6.462      11.267\n",
      "C(t)[T.56.0]       6.7506      1.229      5.495      0.000       4.342       9.159\n",
      "C(t)[T.57.0]       3.7504      1.230      3.048      0.002       1.339       6.162\n",
      "C(t)[T.58.0]       7.4895      1.231      6.082      0.000       5.076       9.903\n",
      "C(t)[T.59.0]       9.1931      1.235      7.441      0.000       6.772      11.615\n",
      "C(t)[T.60.0]       9.0179      1.232      7.317      0.000       6.602      11.434\n",
      "C(t)[T.61.0]       8.3064      1.241      6.696      0.000       5.875      10.738\n",
      "C(t)[T.62.0]       7.8036      1.238      6.301      0.000       5.376      10.231\n",
      "C(t)[T.63.0]       8.2854      1.240      6.684      0.000       5.856      10.715\n",
      "C(t)[T.64.0]      11.7295      1.234      9.502      0.000       9.310      14.149\n",
      "C(t)[T.65.0]      13.9233      1.236     11.269      0.000      11.502      16.345\n",
      "C(t)[T.66.0]       8.6172      1.254      6.874      0.000       6.160      11.074\n",
      "C(t)[T.67.0]      10.7519      1.248      8.616      0.000       8.306      13.198\n",
      "C(t)[T.68.0]      11.7276      1.250      9.380      0.000       9.277      14.178\n",
      "C(t)[T.69.0]      15.2416      1.241     12.286      0.000      12.810      17.673\n",
      "C(t)[T.70.0]      12.2349      1.250      9.787      0.000       9.785      14.685\n",
      "C(t)[T.71.0]      12.3884      1.246      9.942      0.000       9.946      14.831\n",
      "C(t)[T.72.0]      11.9070      1.235      9.638      0.000       9.485      14.329\n",
      "C(t)[T.73.0]      10.0239      1.239      8.087      0.000       7.595      12.453\n",
      "C(t)[T.74.0]      16.6177      1.234     13.462      0.000      14.198      19.037\n",
      "C(t)[T.75.0]      12.3581      1.228     10.067      0.000       9.952      14.764\n",
      "C(t)[T.76.0]      18.9627      1.221     15.529      0.000      16.569      21.356\n",
      "C(t)[T.77.0]      17.2122      1.230     13.988      0.000      14.800      19.624\n",
      "C(t)[T.78.0]      22.2024      1.232     18.015      0.000      19.787      24.618\n",
      "C(t)[T.79.0]      15.0200      1.231     12.206      0.000      12.608      17.432\n",
      "C(t)[T.80.0]      16.5221      1.231     13.427      0.000      14.110      18.934\n",
      "C(t)[T.81.0]      14.6186      1.235     11.832      0.000      12.197      17.040\n",
      "C(t)[T.82.0]      10.7669      1.231      8.749      0.000       8.355      13.179\n",
      "C(t)[T.83.0]      16.1679      1.228     13.167      0.000      13.761      18.575\n",
      "C(t)[T.84.0]      13.3345      1.232     10.820      0.000      10.919      15.750\n",
      "C(t)[T.85.0]      13.4769      1.234     10.917      0.000      11.057      15.897\n",
      "C(t)[T.86.0]      13.6900      1.228     11.152      0.000      11.284      16.096\n",
      "C(t)[T.87.0]      13.0396      1.231     10.589      0.000      10.626      15.453\n",
      "C(t)[T.88.0]      15.8175      1.235     12.804      0.000      13.396      18.239\n",
      "log_num_tweets     0.4984      0.053      9.469      0.000       0.395       0.602\n",
      "==============================================================================\n",
      "Omnibus:                    10495.743   Durbin-Watson:                   0.948\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            85454.041\n",
      "Skew:                           2.061   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.586   Cond. No.                         474.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# monthly fixed effect\n",
    "data[\"log_num_tweets\"] = np.log(data[\"num_tweets\"])\n",
    "data[\"t\"] = xs[:,1].numpy()\n",
    "lm = sm.ols('perc_harsh_criticism ~ 1 + log_num_tweets + exile + C(t)', data).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS Regression Results                             \n",
      "================================================================================\n",
      "Dep. Variable:     perc_harsh_criticism   R-squared:                       0.478\n",
      "Model:                              OLS   Adj. R-squared:                  0.467\n",
      "Method:                   Least Squares   F-statistic:                     45.59\n",
      "Date:                  Mon, 03 Jun 2024   Prob (F-statistic):               0.00\n",
      "Time:                          14:35:25   Log-Likelihood:                -85875.\n",
      "No. Observations:                 22609   AIC:                         1.726e+05\n",
      "Df Residuals:                     22163   BIC:                         1.762e+05\n",
      "Df Model:                           445                                         \n",
      "Covariance Type:              nonrobust                                         \n",
      "=====================================================================================================================\n",
      "                                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                             4.2090      0.814      5.170      0.000       2.613       5.805\n",
      "exile[T.yes]                                         11.7318      1.176      9.979      0.000       9.427      14.036\n",
      "C(t)[T.1.0]                                           1.3203      1.069      1.235      0.217      -0.775       3.416\n",
      "C(t)[T.2.0]                                          -1.6584      1.055     -1.572      0.116      -3.726       0.409\n",
      "C(t)[T.3.0]                                          -0.0413      1.054     -0.039      0.969      -2.106       2.024\n",
      "C(t)[T.4.0]                                           0.8204      1.057      0.776      0.438      -1.252       2.893\n",
      "C(t)[T.5.0]                                          -0.5403      1.059     -0.510      0.610      -2.616       1.535\n",
      "C(t)[T.6.0]                                           0.3087      1.058      0.292      0.770      -1.764       2.382\n",
      "C(t)[T.7.0]                                          -0.9419      1.051     -0.896      0.370      -3.001       1.118\n",
      "C(t)[T.8.0]                                          -0.3663      1.050     -0.349      0.727      -2.425       1.693\n",
      "C(t)[T.9.0]                                          -1.4510      1.046     -1.388      0.165      -3.501       0.599\n",
      "C(t)[T.10.0]                                         -1.1523      1.051     -1.096      0.273      -3.213       0.908\n",
      "C(t)[T.11.0]                                         -0.8478      1.058     -0.802      0.423      -2.921       1.225\n",
      "C(t)[T.12.0]                                          0.7292      1.055      0.691      0.489      -1.338       2.796\n",
      "C(t)[T.13.0]                                          8.0612      1.052      7.663      0.000       5.999      10.123\n",
      "C(t)[T.14.0]                                          8.0397      1.042      7.718      0.000       5.998      10.081\n",
      "C(t)[T.15.0]                                          4.3010      1.041      4.133      0.000       2.261       6.341\n",
      "C(t)[T.16.0]                                          5.5427      1.049      5.283      0.000       3.486       7.599\n",
      "C(t)[T.17.0]                                          3.1983      1.047      3.055      0.002       1.147       5.250\n",
      "C(t)[T.18.0]                                          1.9760      1.050      1.882      0.060      -0.082       4.034\n",
      "C(t)[T.19.0]                                          1.3477      1.040      1.296      0.195      -0.690       3.385\n",
      "C(t)[T.20.0]                                         -0.0685      1.046     -0.066      0.948      -2.119       1.981\n",
      "C(t)[T.21.0]                                          1.0912      1.045      1.044      0.296      -0.957       3.140\n",
      "C(t)[T.22.0]                                          0.9705      1.050      0.924      0.355      -1.088       3.029\n",
      "C(t)[T.23.0]                                          5.4434      1.047      5.199      0.000       3.391       7.496\n",
      "C(t)[T.24.0]                                          2.0900      1.047      1.996      0.046       0.038       4.142\n",
      "C(t)[T.25.0]                                          6.0141      1.043      5.766      0.000       3.970       8.058\n",
      "C(t)[T.26.0]                                          1.9572      1.034      1.892      0.058      -0.070       3.985\n",
      "C(t)[T.27.0]                                          0.9314      1.040      0.895      0.371      -1.108       2.971\n",
      "C(t)[T.28.0]                                          2.1900      1.040      2.107      0.035       0.152       4.227\n",
      "C(t)[T.29.0]                                          1.3732      1.036      1.326      0.185      -0.657       3.404\n",
      "C(t)[T.30.0]                                         -0.7376      1.040     -0.709      0.478      -2.776       1.301\n",
      "C(t)[T.31.0]                                         -0.3122      1.037     -0.301      0.763      -2.345       1.720\n",
      "C(t)[T.32.0]                                          0.5867      1.028      0.570      0.568      -1.429       2.603\n",
      "C(t)[T.33.0]                                         -0.9766      1.023     -0.955      0.340      -2.981       1.028\n",
      "C(t)[T.34.0]                                         -0.9342      1.022     -0.914      0.361      -2.938       1.069\n",
      "C(t)[T.35.0]                                         -0.7819      1.022     -0.765      0.444      -2.786       1.222\n",
      "C(t)[T.36.0]                                         -1.2635      1.019     -1.240      0.215      -3.261       0.734\n",
      "C(t)[T.37.0]                                          0.8751      1.019      0.859      0.390      -1.122       2.872\n",
      "C(t)[T.38.0]                                          2.2470      1.024      2.194      0.028       0.240       4.254\n",
      "C(t)[T.39.0]                                          0.0473      1.020      0.046      0.963      -1.953       2.047\n",
      "C(t)[T.40.0]                                          0.6003      1.019      0.589      0.556      -1.397       2.597\n",
      "C(t)[T.41.0]                                          1.4427      1.023      1.410      0.159      -0.563       3.449\n",
      "C(t)[T.42.0]                                          1.2960      1.020      1.271      0.204      -0.703       3.295\n",
      "C(t)[T.43.0]                                          1.6349      1.016      1.609      0.108      -0.357       3.626\n",
      "C(t)[T.44.0]                                          3.2821      1.015      3.235      0.001       1.293       5.271\n",
      "C(t)[T.45.0]                                          3.3553      1.016      3.302      0.001       1.364       5.347\n",
      "C(t)[T.46.0]                                          7.0227      1.014      6.925      0.000       5.035       9.010\n",
      "C(t)[T.47.0]                                          5.9410      1.015      5.851      0.000       3.951       7.931\n",
      "C(t)[T.48.0]                                          5.1196      1.018      5.029      0.000       3.124       7.115\n",
      "C(t)[T.49.0]                                          6.1683      1.015      6.074      0.000       4.178       8.159\n",
      "C(t)[T.50.0]                                          4.5942      1.014      4.531      0.000       2.607       6.582\n",
      "C(t)[T.51.0]                                         14.3482      1.013     14.168      0.000      12.363      16.333\n",
      "C(t)[T.52.0]                                         13.9985      1.009     13.878      0.000      12.021      15.976\n",
      "C(t)[T.53.0]                                         10.9274      1.010     10.821      0.000       8.948      12.907\n",
      "C(t)[T.54.0]                                          8.9705      1.013      8.860      0.000       6.986      10.955\n",
      "C(t)[T.55.0]                                          9.1749      1.007      9.109      0.000       7.201      11.149\n",
      "C(t)[T.56.0]                                          6.9604      1.010      6.895      0.000       4.982       8.939\n",
      "C(t)[T.57.0]                                          4.0431      1.011      3.998      0.000       2.061       6.025\n",
      "C(t)[T.58.0]                                          7.6962      1.012      7.603      0.000       5.712       9.680\n",
      "C(t)[T.59.0]                                          9.4954      1.016      9.349      0.000       7.505      11.486\n",
      "C(t)[T.60.0]                                          9.2485      1.013      9.131      0.000       7.263      11.234\n",
      "C(t)[T.61.0]                                          8.4729      1.019      8.312      0.000       6.475      10.471\n",
      "C(t)[T.62.0]                                          7.8560      1.018      7.719      0.000       5.861       9.851\n",
      "C(t)[T.63.0]                                          8.3880      1.019      8.235      0.000       6.391      10.384\n",
      "C(t)[T.64.0]                                         11.9662      1.014     11.799      0.000       9.978      13.954\n",
      "C(t)[T.65.0]                                         13.8408      1.015     13.631      0.000      11.851      15.831\n",
      "C(t)[T.66.0]                                          8.4423      1.030      8.194      0.000       6.423      10.462\n",
      "C(t)[T.67.0]                                         10.7206      1.026     10.445      0.000       8.709      12.732\n",
      "C(t)[T.68.0]                                         11.6039      1.028     11.288      0.000       9.589      13.619\n",
      "C(t)[T.69.0]                                         15.1947      1.020     14.902      0.000      13.196      17.193\n",
      "C(t)[T.70.0]                                         12.2768      1.027     11.950      0.000      10.263      14.290\n",
      "C(t)[T.71.0]                                         11.9870      1.025     11.697      0.000       9.978      13.996\n",
      "C(t)[T.72.0]                                         12.1120      1.015     11.928      0.000      10.122      14.102\n",
      "C(t)[T.73.0]                                          9.9879      1.019      9.798      0.000       7.990      11.986\n",
      "C(t)[T.74.0]                                         16.5025      1.014     16.268      0.000      14.514      18.491\n",
      "C(t)[T.75.0]                                         12.1752      1.009     12.067      0.000      10.198      14.153\n",
      "C(t)[T.76.0]                                         18.9791      1.004     18.903      0.000      17.011      20.947\n",
      "C(t)[T.77.0]                                         17.0482      1.011     16.855      0.000      15.066      19.031\n",
      "C(t)[T.78.0]                                         21.8436      1.013     21.563      0.000      19.858      23.829\n",
      "C(t)[T.79.0]                                         14.6073      1.012     14.441      0.000      12.625      16.590\n",
      "C(t)[T.80.0]                                         16.1323      1.012     15.943      0.000      14.149      18.116\n",
      "C(t)[T.81.0]                                         14.0121      1.016     13.791      0.000      12.021      16.004\n",
      "C(t)[T.82.0]                                         10.2220      1.012     10.104      0.000       8.239      12.205\n",
      "C(t)[T.83.0]                                         15.6714      1.010     15.518      0.000      13.692      17.651\n",
      "C(t)[T.84.0]                                         12.9917      1.014     12.818      0.000      11.005      14.978\n",
      "C(t)[T.85.0]                                         12.9343      1.016     12.735      0.000      10.943      14.925\n",
      "C(t)[T.86.0]                                         13.4867      1.010     13.351      0.000      11.507      15.467\n",
      "C(t)[T.87.0]                                         12.5706      1.014     12.401      0.000      10.584      14.557\n",
      "C(t)[T.88.0]                                         15.4271      1.017     15.167      0.000      13.433      17.421\n",
      "C(actor_id)[T.id:twitter.com:1019056064]              5.4524      1.581      3.448      0.001       2.353       8.552\n",
      "C(actor_id)[T.id:twitter.com:102188256]              -0.1840      1.615     -0.114      0.909      -3.349       2.981\n",
      "C(actor_id)[T.id:twitter.com:102482331]              11.7118      1.174      9.975      0.000       9.411      14.013\n",
      "C(actor_id)[T.id:twitter.com:1025567515]            -11.9283      1.711     -6.971      0.000     -15.282      -8.574\n",
      "C(actor_id)[T.id:twitter.com:1040696701]              0.0232      7.703      0.003      0.998     -15.074      15.121\n",
      "C(actor_id)[T.id:twitter.com:105172211]              -8.9867      1.846     -4.869      0.000     -12.604      -5.369\n",
      "C(actor_id)[T.id:twitter.com:106435977]              -8.9772      1.648     -5.448      0.000     -12.207      -5.748\n",
      "C(actor_id)[T.id:twitter.com:107519253]              -2.0166      1.673     -1.205      0.228      -5.296       1.263\n",
      "C(actor_id)[T.id:twitter.com:107694628]              -3.1751      2.558     -1.241      0.215      -8.189       1.839\n",
      "C(actor_id)[T.id:twitter.com:108117226]               3.0618      1.200      2.551      0.011       0.709       5.414\n",
      "C(actor_id)[T.id:twitter.com:108177410]               6.6156      1.169      5.657      0.000       4.323       8.908\n",
      "C(actor_id)[T.id:twitter.com:108290069]               7.5016      1.664      4.508      0.000       4.240      10.763\n",
      "C(actor_id)[T.id:twitter.com:109057415]              -5.1578      1.170     -4.409      0.000      -7.451      -2.865\n",
      "C(actor_id)[T.id:twitter.com:109485280]              -0.9573      2.282     -0.419      0.675      -5.430       3.516\n",
      "C(actor_id)[T.id:twitter.com:109591461]              15.5140      1.172     13.236      0.000      13.217      17.811\n",
      "C(actor_id)[T.id:twitter.com:109667868]              -1.9668      1.254     -1.568      0.117      -4.425       0.491\n",
      "C(actor_id)[T.id:twitter.com:1101752148]             -5.6773      1.849     -3.070      0.002      -9.302      -2.053\n",
      "C(actor_id)[T.id:twitter.com:110483566]              -4.7568      1.169     -4.069      0.000      -7.048      -2.465\n",
      "C(actor_id)[T.id:twitter.com:111042340]               1.6926      1.180      1.434      0.151      -0.620       4.005\n",
      "C(actor_id)[T.id:twitter.com:111782846]               0.7324      1.171      0.625      0.532      -1.564       3.028\n",
      "C(actor_id)[T.id:twitter.com:1128151652]              3.5258      1.173      3.007      0.003       1.227       5.824\n",
      "C(actor_id)[T.id:twitter.com:112828160]               0.0518      1.672      0.031      0.975      -3.226       3.329\n",
      "C(actor_id)[T.id:twitter.com:1129178128822226949]   -10.4173      4.041     -2.578      0.010     -18.337      -2.497\n",
      "C(actor_id)[T.id:twitter.com:113733516]              -4.2682      1.599     -2.670      0.008      -7.402      -1.134\n",
      "C(actor_id)[T.id:twitter.com:114074686]              -7.0000      1.186     -5.900      0.000      -9.326      -4.674\n",
      "C(actor_id)[T.id:twitter.com:114112198]              -0.3901      1.177     -0.332      0.740      -2.696       1.916\n",
      "C(actor_id)[T.id:twitter.com:114185889]              -0.9199      2.921     -0.315      0.753      -6.645       4.806\n",
      "C(actor_id)[T.id:twitter.com:114339619]               1.0114      1.167      0.867      0.386      -1.276       3.298\n",
      "C(actor_id)[T.id:twitter.com:114472937]               1.2810      1.327      0.965      0.334      -1.320       3.882\n",
      "C(actor_id)[T.id:twitter.com:115717343]              -0.8828      1.167     -0.757      0.449      -3.170       1.404\n",
      "C(actor_id)[T.id:twitter.com:116227294]               8.9165      1.178      7.571      0.000       6.608      11.225\n",
      "C(actor_id)[T.id:twitter.com:1163186330966396928]    12.9113      3.449      3.744      0.000       6.151      19.671\n",
      "C(actor_id)[T.id:twitter.com:1163416884]             -9.9466      1.649     -6.032      0.000     -13.179      -6.715\n",
      "C(actor_id)[T.id:twitter.com:117439710]               3.1608      2.730      1.158      0.247      -2.191       8.512\n",
      "C(actor_id)[T.id:twitter.com:117961446]              -4.0570      1.169     -3.469      0.001      -6.349      -1.765\n",
      "C(actor_id)[T.id:twitter.com:1183833234842537986]     2.5504      3.854      0.662      0.508      -5.003      10.104\n",
      "C(actor_id)[T.id:twitter.com:1201197247062519808]   -12.1121      4.871     -2.487      0.013     -21.660      -2.565\n",
      "C(actor_id)[T.id:twitter.com:120843199]              -6.4893      1.662     -3.905      0.000      -9.747      -3.232\n",
      "C(actor_id)[T.id:twitter.com:120928088]               1.7567      1.169      1.503      0.133      -0.534       4.047\n",
      "C(actor_id)[T.id:twitter.com:122221420]              -4.6189      1.169     -3.952      0.000      -6.910      -2.328\n",
      "C(actor_id)[T.id:twitter.com:1222506341421518849]    -5.1284      4.871     -1.053      0.292     -14.676       4.419\n",
      "C(actor_id)[T.id:twitter.com:124762525]              -0.7287      1.193     -0.611      0.541      -3.068       1.610\n",
      "C(actor_id)[T.id:twitter.com:126431606]               1.5987      1.231      1.298      0.194      -0.815       4.012\n",
      "C(actor_id)[T.id:twitter.com:1268659980]              1.6280      1.342      1.213      0.225      -1.003       4.259\n",
      "C(actor_id)[T.id:twitter.com:127637567]              -8.3935      1.249     -6.722      0.000     -10.841      -5.946\n",
      "C(actor_id)[T.id:twitter.com:1278533784]            -13.7094      1.963     -6.984      0.000     -17.557      -9.862\n",
      "C(actor_id)[T.id:twitter.com:130224262]               2.1460      1.167      1.839      0.066      -0.141       4.433\n",
      "C(actor_id)[T.id:twitter.com:130624925]              -3.2800      1.200     -2.733      0.006      -5.632      -0.928\n",
      "C(actor_id)[T.id:twitter.com:131519051]               0.9589      1.640      0.585      0.559      -2.255       4.173\n",
      "C(actor_id)[T.id:twitter.com:131523433]               3.3161      1.168      2.840      0.005       1.027       5.605\n",
      "C(actor_id)[T.id:twitter.com:131707109]              -0.0547      1.549     -0.035      0.972      -3.091       2.982\n",
      "C(actor_id)[T.id:twitter.com:132278538]              -1.3359      1.167     -1.144      0.252      -3.624       0.952\n",
      "C(actor_id)[T.id:twitter.com:132279449]               2.4552      1.753      1.401      0.161      -0.980       5.890\n",
      "C(actor_id)[T.id:twitter.com:132342295]              -6.6781      1.238     -5.394      0.000      -9.105      -4.252\n",
      "C(actor_id)[T.id:twitter.com:133138148]              -6.3762      1.648     -3.870      0.000      -9.606      -3.146\n",
      "C(actor_id)[T.id:twitter.com:133407970]              -1.9589      1.193     -1.642      0.101      -4.298       0.380\n",
      "C(actor_id)[T.id:twitter.com:133707256]              -2.7553      3.030     -0.909      0.363      -8.695       3.184\n",
      "C(actor_id)[T.id:twitter.com:133728812]               3.6245      1.183      3.063      0.002       1.305       5.944\n",
      "C(actor_id)[T.id:twitter.com:134208093]               5.6832      1.176      4.833      0.000       3.378       7.988\n",
      "C(actor_id)[T.id:twitter.com:134557956]              -4.4361      1.442     -3.076      0.002      -7.263      -1.610\n",
      "C(actor_id)[T.id:twitter.com:135033641]              -8.8170      2.003     -4.402      0.000     -12.743      -4.891\n",
      "C(actor_id)[T.id:twitter.com:135177315]               5.4385      5.448      0.998      0.318      -5.240      16.116\n",
      "C(actor_id)[T.id:twitter.com:135607670]              -5.6725      1.877     -3.022      0.003      -9.351      -1.994\n",
      "C(actor_id)[T.id:twitter.com:137128647]               0.6511      1.419      0.459      0.646      -2.130       3.432\n",
      "C(actor_id)[T.id:twitter.com:137430904]              -0.2631      2.388     -0.110      0.912      -4.943       4.417\n",
      "C(actor_id)[T.id:twitter.com:137727433]              -7.8394      1.644     -4.768      0.000     -11.062      -4.616\n",
      "C(actor_id)[T.id:twitter.com:137808883]              -0.3308      1.297     -0.255      0.799      -2.872       2.211\n",
      "C(actor_id)[T.id:twitter.com:138515802]               9.4915      1.556      6.101      0.000       6.442      12.541\n",
      "C(actor_id)[T.id:twitter.com:138534812]               3.3559      1.242      2.703      0.007       0.922       5.790\n",
      "C(actor_id)[T.id:twitter.com:138549102]              -3.8836      1.648     -2.356      0.018      -7.115      -0.653\n",
      "C(actor_id)[T.id:twitter.com:138558552]              -0.6038      1.646     -0.367      0.714      -3.829       2.622\n",
      "C(actor_id)[T.id:twitter.com:138911971]               6.3557      2.731      2.327      0.020       1.002      11.709\n",
      "C(actor_id)[T.id:twitter.com:139841711]              12.8225      1.286      9.967      0.000      10.301      15.344\n",
      "C(actor_id)[T.id:twitter.com:140122683]              -1.0211      1.643     -0.622      0.534      -4.241       2.198\n",
      "C(actor_id)[T.id:twitter.com:1406598860]            -14.1968     10.890     -1.304      0.192     -35.541       7.147\n",
      "C(actor_id)[T.id:twitter.com:140829257]              -9.0767      1.229     -7.383      0.000     -11.486      -6.667\n",
      "C(actor_id)[T.id:twitter.com:140901683]              -4.5120      1.187     -3.802      0.000      -6.838      -2.186\n",
      "C(actor_id)[T.id:twitter.com:14119371]               -5.8234      1.645     -3.539      0.000      -9.049      -2.598\n",
      "C(actor_id)[T.id:twitter.com:142312323]              -3.7546      1.750     -2.146      0.032      -7.184      -0.325\n",
      "C(actor_id)[T.id:twitter.com:142751926]              11.0343      1.180      9.353      0.000       8.722      13.347\n",
      "C(actor_id)[T.id:twitter.com:142922225]             -13.7221      6.288     -2.182      0.029     -26.046      -1.398\n",
      "C(actor_id)[T.id:twitter.com:1431759750]             -0.2324      1.667     -0.139      0.889      -3.499       3.034\n",
      "C(actor_id)[T.id:twitter.com:143237375]               0.2710      1.393      0.194      0.846      -2.460       3.002\n",
      "C(actor_id)[T.id:twitter.com:143254724]              -5.2266      2.031     -2.574      0.010      -9.207      -1.247\n",
      "C(actor_id)[T.id:twitter.com:143582572]               6.1520      1.736      3.545      0.000       2.750       9.554\n",
      "C(actor_id)[T.id:twitter.com:145649305]              -4.0392      1.713     -2.358      0.018      -7.396      -0.682\n",
      "C(actor_id)[T.id:twitter.com:145810767]              12.6459      1.181     10.711      0.000      10.332      14.960\n",
      "C(actor_id)[T.id:twitter.com:146067210]             -16.6008      1.993     -8.331      0.000     -20.507     -12.695\n",
      "C(actor_id)[T.id:twitter.com:146121511]              -7.6273      1.218     -6.264      0.000     -10.014      -5.241\n",
      "C(actor_id)[T.id:twitter.com:146295125]               1.1153      1.416      0.788      0.431      -1.661       3.891\n",
      "C(actor_id)[T.id:twitter.com:1465099951]              1.1224      2.184      0.514      0.607      -3.159       5.404\n",
      "C(actor_id)[T.id:twitter.com:146523859]              -4.3354      1.695     -2.557      0.011      -7.658      -1.012\n",
      "C(actor_id)[T.id:twitter.com:147337850]              -5.4281      1.295     -4.192      0.000      -7.966      -2.890\n",
      "C(actor_id)[T.id:twitter.com:149737458]               0.8548      1.207      0.708      0.479      -1.511       3.221\n",
      "C(actor_id)[T.id:twitter.com:15012693]              -11.5755      1.654     -6.999      0.000     -14.817      -8.334\n",
      "C(actor_id)[T.id:twitter.com:150296174]              -4.0250      1.214     -3.314      0.001      -6.405      -1.645\n",
      "C(actor_id)[T.id:twitter.com:153170209]               5.6603      1.405      4.028      0.000       2.906       8.415\n",
      "C(actor_id)[T.id:twitter.com:1559000173]             -5.8468      1.755     -3.332      0.001      -9.287      -2.407\n",
      "C(actor_id)[T.id:twitter.com:156352850]               6.0636      1.486      4.080      0.000       3.151       8.976\n",
      "C(actor_id)[T.id:twitter.com:157880742]              -1.3705      1.168     -1.173      0.241      -3.661       0.920\n",
      "C(actor_id)[T.id:twitter.com:160353332]              -1.2832      5.448     -0.236      0.814     -11.962       9.395\n",
      "C(actor_id)[T.id:twitter.com:161095085]               2.2273      1.200      1.856      0.063      -0.125       4.580\n",
      "C(actor_id)[T.id:twitter.com:168145965]              -9.1935      1.196     -7.684      0.000     -11.539      -6.848\n",
      "C(actor_id)[T.id:twitter.com:168361033]              -0.4441      1.644     -0.270      0.787      -3.667       2.779\n",
      "C(actor_id)[T.id:twitter.com:1691316967]              0.0017      1.312      0.001      0.999      -2.571       2.574\n",
      "C(actor_id)[T.id:twitter.com:169154681]               1.2592      1.196      1.053      0.292      -1.085       3.603\n",
      "C(actor_id)[T.id:twitter.com:169201397]             -14.7356      1.934     -7.620      0.000     -18.526     -10.945\n",
      "C(actor_id)[T.id:twitter.com:169454901]              -0.9515      1.187     -0.802      0.423      -3.278       1.375\n",
      "C(actor_id)[T.id:twitter.com:169687049]               5.2257      1.351      3.867      0.000       2.577       7.874\n",
      "C(actor_id)[T.id:twitter.com:1723833512]             -5.4096      4.876     -1.109      0.267     -14.968       4.148\n",
      "C(actor_id)[T.id:twitter.com:174939254]              -1.5457      3.855     -0.401      0.688      -9.102       6.011\n",
      "C(actor_id)[T.id:twitter.com:177335715]              -0.6530      1.775     -0.368      0.713      -4.131       2.825\n",
      "C(actor_id)[T.id:twitter.com:179724986]               3.0219      1.491      2.026      0.043       0.099       5.945\n",
      "C(actor_id)[T.id:twitter.com:18672473]               -1.6742      1.181     -1.418      0.156      -3.988       0.640\n",
      "C(actor_id)[T.id:twitter.com:186837436]               2.7884      2.230      1.250      0.211      -1.583       7.159\n",
      "C(actor_id)[T.id:twitter.com:188165366]              -7.1595      1.282     -5.585      0.000      -9.672      -4.647\n",
      "C(actor_id)[T.id:twitter.com:189505030]              -3.8940      1.175     -3.313      0.001      -6.198      -1.590\n",
      "C(actor_id)[T.id:twitter.com:189521140]              -2.2439      1.168     -1.922      0.055      -4.533       0.045\n",
      "C(actor_id)[T.id:twitter.com:1918380450]              3.8484      1.405      2.740      0.006       1.095       6.602\n",
      "C(actor_id)[T.id:twitter.com:192288282]              -4.5812      1.168     -3.922      0.000      -6.871      -2.292\n",
      "C(actor_id)[T.id:twitter.com:1935412261]             -3.0843      1.382     -2.231      0.026      -5.794      -0.375\n",
      "C(actor_id)[T.id:twitter.com:1941430368]             -2.9158     10.890     -0.268      0.789     -24.260      18.428\n",
      "C(actor_id)[T.id:twitter.com:196271703]              -1.1311      1.172     -0.965      0.334      -3.428       1.165\n",
      "C(actor_id)[T.id:twitter.com:197605220]              -3.4759      1.640     -2.120      0.034      -6.690      -0.262\n",
      "C(actor_id)[T.id:twitter.com:198613032]              11.6279      1.260      9.226      0.000       9.157      14.098\n",
      "C(actor_id)[T.id:twitter.com:201538731]             -14.9296     10.890     -1.371      0.170     -36.274       6.415\n",
      "C(actor_id)[T.id:twitter.com:204033649]               3.5117      1.171      2.999      0.003       1.217       5.806\n",
      "C(actor_id)[T.id:twitter.com:207865365]               2.1826      1.256      1.738      0.082      -0.279       4.644\n",
      "C(actor_id)[T.id:twitter.com:20849512]               10.4819      1.351      7.757      0.000       7.833      13.130\n",
      "C(actor_id)[T.id:twitter.com:211943582]              -7.0613      1.675     -4.214      0.000     -10.345      -3.777\n",
      "C(actor_id)[T.id:twitter.com:214114587]              11.4264      1.644      6.949      0.000       8.203      14.649\n",
      "C(actor_id)[T.id:twitter.com:216646024]               7.1925      1.184      6.074      0.000       4.872       9.513\n",
      "C(actor_id)[T.id:twitter.com:218180701]              -3.6637      1.329     -2.757      0.006      -6.268      -1.059\n",
      "C(actor_id)[T.id:twitter.com:22537447]               -5.4496      1.171     -4.654      0.000      -7.745      -3.154\n",
      "C(actor_id)[T.id:twitter.com:2255297474]             -7.0889      2.822     -2.512      0.012     -12.621      -1.557\n",
      "C(actor_id)[T.id:twitter.com:226366184]              -6.7312      1.246     -5.404      0.000      -9.173      -4.290\n",
      "C(actor_id)[T.id:twitter.com:2265669221]             -6.1359      1.824     -3.364      0.001      -9.711      -2.561\n",
      "C(actor_id)[T.id:twitter.com:2273310218]             -7.7956      3.024     -2.578      0.010     -13.724      -1.867\n",
      "C(actor_id)[T.id:twitter.com:229090782]             -10.1040      1.647     -6.134      0.000     -13.333      -6.875\n",
      "C(actor_id)[T.id:twitter.com:229647379]              -0.7870      1.173     -0.671      0.502      -3.086       1.512\n",
      "C(actor_id)[T.id:twitter.com:231902294]               9.3921      2.916      3.220      0.001       3.676      15.109\n",
      "C(actor_id)[T.id:twitter.com:2354503127]              2.5024      1.278      1.958      0.050      -0.002       5.007\n",
      "C(actor_id)[T.id:twitter.com:23719107]                1.9235      1.213      1.586      0.113      -0.454       4.301\n",
      "C(actor_id)[T.id:twitter.com:2400785744]              5.6227      1.405      4.002      0.000       2.869       8.376\n",
      "C(actor_id)[T.id:twitter.com:248010159]             -13.0261      1.640     -7.944      0.000     -16.240      -9.812\n",
      "C(actor_id)[T.id:twitter.com:2505772886]            -10.4312      4.872     -2.141      0.032     -19.981      -0.882\n",
      "C(actor_id)[T.id:twitter.com:2510653449]              0.2395      1.670      0.143      0.886      -3.035       3.514\n",
      "C(actor_id)[T.id:twitter.com:253581736]              -3.5454      2.444     -1.451      0.147      -8.336       1.245\n",
      "C(actor_id)[T.id:twitter.com:254333960]              -3.8550      2.820     -1.367      0.172      -9.382       1.672\n",
      "C(actor_id)[T.id:twitter.com:256024862]              -1.6704      1.418     -1.178      0.239      -4.451       1.110\n",
      "C(actor_id)[T.id:twitter.com:256100154]               9.0405      1.752      5.161      0.000       5.607      12.474\n",
      "C(actor_id)[T.id:twitter.com:2565811548]             -7.5556      1.692     -4.466      0.000     -10.872      -4.240\n",
      "C(actor_id)[T.id:twitter.com:256695465]              -4.7074      1.172     -4.016      0.000      -7.005      -2.410\n",
      "C(actor_id)[T.id:twitter.com:262454885]               8.7035      1.632      5.333      0.000       5.505      11.902\n",
      "C(actor_id)[T.id:twitter.com:263998351]               3.7448      1.646      2.275      0.023       0.518       6.971\n",
      "C(actor_id)[T.id:twitter.com:264866743]              -0.1666      1.169     -0.143      0.887      -2.457       2.124\n",
      "C(actor_id)[T.id:twitter.com:266868053]             -20.8809      1.649    -12.659      0.000     -24.114     -17.648\n",
      "C(actor_id)[T.id:twitter.com:2734570963]            -15.2696      4.449     -3.432      0.001     -23.990      -6.549\n",
      "C(actor_id)[T.id:twitter.com:278227183]               2.7474      1.644      1.671      0.095      -0.476       5.971\n",
      "C(actor_id)[T.id:twitter.com:281683108]              -5.2079      1.492     -3.491      0.000      -8.132      -2.284\n",
      "C(actor_id)[T.id:twitter.com:283999406]              -8.6799      1.963     -4.421      0.000     -12.528      -4.832\n",
      "C(actor_id)[T.id:twitter.com:29110681]               11.2923      1.173      9.624      0.000       8.992      13.592\n",
      "C(actor_id)[T.id:twitter.com:292065898]               2.8038      1.331      2.107      0.035       0.195       5.412\n",
      "C(actor_id)[T.id:twitter.com:2946315838]              6.6252      1.814      3.653      0.000       3.070      10.180\n",
      "C(actor_id)[T.id:twitter.com:2947638843]             -4.1884      2.187     -1.915      0.055      -8.474       0.097\n",
      "C(actor_id)[T.id:twitter.com:296943655]              -3.0460      1.253     -2.431      0.015      -5.502      -0.590\n",
      "C(actor_id)[T.id:twitter.com:3014616760]             -7.0633      1.875     -3.767      0.000     -10.738      -3.388\n",
      "C(actor_id)[T.id:twitter.com:3045502209]              0.6890      6.290      0.110      0.913     -11.640      13.018\n",
      "C(actor_id)[T.id:twitter.com:3046605658]             31.5162      2.437     12.931      0.000      26.739      36.293\n",
      "C(actor_id)[T.id:twitter.com:306358232]              -4.1710      1.534     -2.719      0.007      -7.178      -1.164\n",
      "C(actor_id)[T.id:twitter.com:307648868]             -13.6053      1.641     -8.293      0.000     -16.821     -10.390\n",
      "C(actor_id)[T.id:twitter.com:3130447076]             -6.6413      1.550     -4.284      0.000      -9.680      -3.603\n",
      "C(actor_id)[T.id:twitter.com:313481830]              -5.2592      1.377     -3.818      0.000      -7.959      -2.559\n",
      "C(actor_id)[T.id:twitter.com:3289959195]             -5.6187     10.890     -0.516      0.606     -26.965      15.727\n",
      "C(actor_id)[T.id:twitter.com:332642789]              -4.0104      1.216     -3.299      0.001      -6.393      -1.628\n",
      "C(actor_id)[T.id:twitter.com:3344950060]              5.3732      3.147      1.707      0.088      -0.795      11.542\n",
      "C(actor_id)[T.id:twitter.com:334825997]              -5.1205     10.889     -0.470      0.638     -26.463      16.222\n",
      "C(actor_id)[T.id:twitter.com:334950418]               0.6261      1.212      0.516      0.606      -1.750       3.003\n",
      "C(actor_id)[T.id:twitter.com:3350745243]             -5.5822     10.891     -0.513      0.608     -26.930      15.766\n",
      "C(actor_id)[T.id:twitter.com:3356538195]              1.7434      1.520      1.147      0.252      -1.237       4.723\n",
      "C(actor_id)[T.id:twitter.com:33718836]               -2.4133      1.645     -1.467      0.142      -5.637       0.810\n",
      "C(actor_id)[T.id:twitter.com:3395765697]             -5.4682      7.700     -0.710      0.478     -20.560       9.624\n",
      "C(actor_id)[T.id:twitter.com:3401731887]              7.6644      1.454      5.271      0.000       4.814      10.514\n",
      "C(actor_id)[T.id:twitter.com:3423025671]             -1.8879      5.446     -0.347      0.729     -12.563       8.787\n",
      "C(actor_id)[T.id:twitter.com:342330922]              10.5766      1.167      9.063      0.000       8.289      12.864\n",
      "C(actor_id)[T.id:twitter.com:342363193]              -3.3857      1.463     -2.315      0.021      -6.252      -0.519\n",
      "C(actor_id)[T.id:twitter.com:3430614579]             -8.6139      3.827     -2.251      0.024     -16.115      -1.113\n",
      "C(actor_id)[T.id:twitter.com:344351891]               4.3578      1.453      2.999      0.003       1.509       7.206\n",
      "C(actor_id)[T.id:twitter.com:3502107555]              0.6188      1.614      0.383      0.701      -2.545       3.783\n",
      "C(actor_id)[T.id:twitter.com:3571499722]             -2.8146      5.448     -0.517      0.605     -13.493       7.863\n",
      "C(actor_id)[T.id:twitter.com:364959367]              -6.3189      1.186     -5.326      0.000      -8.644      -3.993\n",
      "C(actor_id)[T.id:twitter.com:376467959]             -12.1891      1.690     -7.212      0.000     -15.502      -8.876\n",
      "C(actor_id)[T.id:twitter.com:376522933]              -2.1534      1.367     -1.575      0.115      -4.834       0.527\n",
      "C(actor_id)[T.id:twitter.com:37669604]               -3.8420      1.736     -2.213      0.027      -7.245      -0.439\n",
      "C(actor_id)[T.id:twitter.com:379197417]              -5.9252      1.167     -5.078      0.000      -8.212      -3.638\n",
      "C(actor_id)[T.id:twitter.com:39176902]                8.1885      1.174      6.974      0.000       5.887      10.490\n",
      "C(actor_id)[T.id:twitter.com:39621575]               -5.6634      1.600     -3.539      0.000      -8.800      -2.527\n",
      "C(actor_id)[T.id:twitter.com:40246785]               10.2650      1.671      6.144      0.000       6.990      13.540\n",
      "C(actor_id)[T.id:twitter.com:4119165615]             -2.1064      3.450     -0.611      0.542      -8.869       4.656\n",
      "C(actor_id)[T.id:twitter.com:41462167]               24.6870      7.813      3.160      0.002       9.373      40.001\n",
      "C(actor_id)[T.id:twitter.com:41575911]                9.7596      1.170      8.341      0.000       7.466      12.053\n",
      "C(actor_id)[T.id:twitter.com:41626835]               -7.2429      1.169     -6.195      0.000      -9.535      -4.951\n",
      "C(actor_id)[T.id:twitter.com:42176636]               -6.2146      1.173     -5.297      0.000      -8.514      -3.915\n",
      "C(actor_id)[T.id:twitter.com:42274372]              -16.3791      1.756     -9.329      0.000     -19.820     -12.938\n",
      "C(actor_id)[T.id:twitter.com:42302742]                4.1503      1.308      3.173      0.002       1.586       6.714\n",
      "C(actor_id)[T.id:twitter.com:42434332]               21.2848      1.331     15.987      0.000      18.675      23.894\n",
      "C(actor_id)[T.id:twitter.com:42473217]              -21.2138      1.644    -12.901      0.000     -24.437     -17.991\n",
      "C(actor_id)[T.id:twitter.com:4250629253]            -13.2896      1.846     -7.200      0.000     -16.907      -9.672\n",
      "C(actor_id)[T.id:twitter.com:428532039]              -4.9644      1.715     -2.894      0.004      -8.327      -1.602\n",
      "C(actor_id)[T.id:twitter.com:42903275]              -15.1185      1.644     -9.194      0.000     -18.342     -11.895\n",
      "C(actor_id)[T.id:twitter.com:43253205]              -17.4254      1.640    -10.627      0.000     -20.639     -14.211\n",
      "C(actor_id)[T.id:twitter.com:43351724]               -4.8746      1.168     -4.172      0.000      -7.165      -2.584\n",
      "C(actor_id)[T.id:twitter.com:43944739]                1.7465      1.168      1.495      0.135      -0.543       4.036\n",
      "C(actor_id)[T.id:twitter.com:44390131]               -9.4060      1.647     -5.713      0.000     -12.633      -6.179\n",
      "C(actor_id)[T.id:twitter.com:447456690]              -6.2163      1.670     -3.723      0.000      -9.489      -2.944\n",
      "C(actor_id)[T.id:twitter.com:45508459]              -13.6837      1.644     -8.321      0.000     -16.907     -10.461\n",
      "C(actor_id)[T.id:twitter.com:4635820420]              7.3711      1.731      4.259      0.000       3.979      10.763\n",
      "C(actor_id)[T.id:twitter.com:467717729]              -5.5049     10.890     -0.506      0.613     -26.850      15.840\n",
      "C(actor_id)[T.id:twitter.com:48826114]                9.6363      1.173      8.215      0.000       7.337      11.935\n",
      "C(actor_id)[T.id:twitter.com:493410134]              39.8639      1.441     27.657      0.000      37.039      42.689\n",
      "C(actor_id)[T.id:twitter.com:494522369]              -3.4808      1.167     -2.984      0.003      -5.768      -1.194\n",
      "C(actor_id)[T.id:twitter.com:49658852]                1.7518      2.142      0.818      0.413      -2.446       5.950\n",
      "C(actor_id)[T.id:twitter.com:50130973]                0.2605      1.186      0.220      0.826      -2.064       2.585\n",
      "C(actor_id)[T.id:twitter.com:50498677]               -5.5443      1.167     -4.752      0.000      -7.831      -3.258\n",
      "C(actor_id)[T.id:twitter.com:512447708]              -4.0753      4.126     -0.988      0.323     -12.163       4.012\n",
      "C(actor_id)[T.id:twitter.com:51279708]               -8.2718      1.224     -6.758      0.000     -10.671      -5.873\n",
      "C(actor_id)[T.id:twitter.com:518921347]               3.5801      1.174      3.050      0.002       1.280       5.880\n",
      "C(actor_id)[T.id:twitter.com:52253454]                3.1965      1.640      1.949      0.051      -0.018       6.411\n",
      "C(actor_id)[T.id:twitter.com:52286206]                2.9634      1.269      2.335      0.020       0.476       5.451\n",
      "C(actor_id)[T.id:twitter.com:52379357]               -6.7972      1.646     -4.129      0.000     -10.024      -3.571\n",
      "C(actor_id)[T.id:twitter.com:527447086]              -5.5292     10.894     -0.508      0.612     -26.882      15.824\n",
      "C(actor_id)[T.id:twitter.com:53142143]                3.0298      1.660      1.825      0.068      -0.225       6.284\n",
      "C(actor_id)[T.id:twitter.com:53678101]                1.5893      1.792      0.887      0.375      -1.924       5.103\n",
      "C(actor_id)[T.id:twitter.com:53778621]                1.5158      1.645      0.922      0.357      -1.708       4.740\n",
      "C(actor_id)[T.id:twitter.com:53995286]                0.8616      1.201      0.717      0.473      -1.493       3.216\n",
      "C(actor_id)[T.id:twitter.com:54054242]               -0.2025      1.645     -0.123      0.902      -3.426       3.022\n",
      "C(actor_id)[T.id:twitter.com:54305566]                9.2259      1.287      7.167      0.000       6.703      11.749\n",
      "C(actor_id)[T.id:twitter.com:545576287]               9.6000      1.174      8.181      0.000       7.300      11.900\n",
      "C(actor_id)[T.id:twitter.com:54599618]              -24.9075      2.100    -11.862      0.000     -29.023     -20.792\n",
      "C(actor_id)[T.id:twitter.com:54713891]              -12.9465      1.645     -7.872      0.000     -16.170      -9.723\n",
      "C(actor_id)[T.id:twitter.com:54973156]               -5.6527      1.168     -4.839      0.000      -7.943      -3.363\n",
      "C(actor_id)[T.id:twitter.com:55420433]               -7.9846      1.640     -4.869      0.000     -11.199      -4.770\n",
      "C(actor_id)[T.id:twitter.com:55478032]               11.3541      1.180      9.624      0.000       9.042      13.667\n",
      "C(actor_id)[T.id:twitter.com:55558616]               18.2176      2.182      8.350      0.000      13.941      22.494\n",
      "C(actor_id)[T.id:twitter.com:561437755]               5.3698      1.408      3.814      0.000       2.610       8.129\n",
      "C(actor_id)[T.id:twitter.com:56790332]               32.2057      1.169     27.558      0.000      29.915      34.496\n",
      "C(actor_id)[T.id:twitter.com:569286330]              -5.6287      1.712     -3.288      0.001      -8.984      -2.273\n",
      "C(actor_id)[T.id:twitter.com:57520674]                2.1707      1.169      1.857      0.063      -0.120       4.462\n",
      "C(actor_id)[T.id:twitter.com:58324984]               -7.0089      1.644     -4.263      0.000     -10.232      -3.786\n",
      "C(actor_id)[T.id:twitter.com:58388736]               -5.0414      1.175     -4.290      0.000      -7.345      -2.738\n",
      "C(actor_id)[T.id:twitter.com:58572021]               -0.1026      1.680     -0.061      0.951      -3.396       3.190\n",
      "C(actor_id)[T.id:twitter.com:590202306]              -1.1722      1.363     -0.860      0.390      -3.843       1.499\n",
      "C(actor_id)[T.id:twitter.com:594777427]               3.2921      1.676      1.964      0.050       0.006       6.578\n",
      "C(actor_id)[T.id:twitter.com:614782590]              -8.1073      1.972     -4.111      0.000     -11.973      -4.241\n",
      "C(actor_id)[T.id:twitter.com:62188046]                4.1752      1.167      3.578      0.000       1.888       6.463\n",
      "C(actor_id)[T.id:twitter.com:62343852]               -4.7454      1.747     -2.716      0.007      -8.170      -1.321\n",
      "C(actor_id)[T.id:twitter.com:62512359]               -3.6169      1.168     -3.097      0.002      -5.906      -1.328\n",
      "C(actor_id)[T.id:twitter.com:62917505]               11.4399      1.640      6.975      0.000       8.225      14.655\n",
      "C(actor_id)[T.id:twitter.com:63012115]               -8.3853      1.664     -5.040      0.000     -11.647      -5.124\n",
      "C(actor_id)[T.id:twitter.com:63547446]                3.7788      1.167      3.238      0.001       1.492       6.066\n",
      "C(actor_id)[T.id:twitter.com:64967178]                0.9352      1.167      0.802      0.423      -1.352       3.222\n",
      "C(actor_id)[T.id:twitter.com:65240091]               -9.8954      1.644     -6.018      0.000     -13.119      -6.672\n",
      "C(actor_id)[T.id:twitter.com:65728343]                7.8186      1.747      4.474      0.000       4.393      11.244\n",
      "C(actor_id)[T.id:twitter.com:66198530]                3.7154      1.174      3.166      0.002       1.415       6.016\n",
      "C(actor_id)[T.id:twitter.com:66453332]               -2.0615      1.640     -1.257      0.209      -5.275       1.152\n",
      "C(actor_id)[T.id:twitter.com:66612865]               -0.6992      1.215     -0.575      0.565      -3.082       1.683\n",
      "C(actor_id)[T.id:twitter.com:67005756]                2.5632      1.185      2.163      0.031       0.241       4.886\n",
      "C(actor_id)[T.id:twitter.com:67069555]               -3.5997      1.169     -3.081      0.002      -5.890      -1.309\n",
      "C(actor_id)[T.id:twitter.com:67096152]               -2.0763      2.228     -0.932      0.351      -6.444       2.292\n",
      "C(actor_id)[T.id:twitter.com:67237988]                3.7732      1.911      1.975      0.048       0.028       7.518\n",
      "C(actor_id)[T.id:twitter.com:67643026]                1.9237      3.024      0.636      0.525      -4.004       7.851\n",
      "C(actor_id)[T.id:twitter.com:68469470]               39.2607      1.169     33.586      0.000      36.969      41.552\n",
      "C(actor_id)[T.id:twitter.com:69979143]               -4.0612      2.081     -1.951      0.051      -8.141       0.019\n",
      "C(actor_id)[T.id:twitter.com:70457749]                5.5464      2.101      2.640      0.008       1.429       9.664\n",
      "C(actor_id)[T.id:twitter.com:704778641352368128]     -2.6457      3.447     -0.768      0.443      -9.402       4.110\n",
      "C(actor_id)[T.id:twitter.com:70597759]               -3.8133      1.644     -2.319      0.020      -7.036      -0.590\n",
      "C(actor_id)[T.id:twitter.com:70686932]               -0.5727      1.167     -0.491      0.624      -2.861       1.715\n",
      "C(actor_id)[T.id:twitter.com:70769118]                1.0187      1.171      0.870      0.384      -1.276       3.314\n",
      "C(actor_id)[T.id:twitter.com:709812425864957952]    -12.5537      7.702     -1.630      0.103     -27.650       2.543\n",
      "C(actor_id)[T.id:twitter.com:71076388]              -12.0930      1.640     -7.372      0.000     -15.308      -8.878\n",
      "C(actor_id)[T.id:twitter.com:72074168]              -11.2376      1.807     -6.217      0.000     -14.780      -7.695\n",
      "C(actor_id)[T.id:twitter.com:72193432]               -2.0836      1.171     -1.780      0.075      -4.378       0.211\n",
      "C(actor_id)[T.id:twitter.com:72901931]                4.2167      1.170      3.604      0.000       1.923       6.510\n",
      "C(actor_id)[T.id:twitter.com:73184984]                0.4000      1.169      0.342      0.732      -1.891       2.691\n",
      "C(actor_id)[T.id:twitter.com:73672296]               -7.1148      1.175     -6.056      0.000      -9.417      -4.812\n",
      "C(actor_id)[T.id:twitter.com:738209701658234881]     -5.3737      6.290     -0.854      0.393     -17.703       6.956\n",
      "C(actor_id)[T.id:twitter.com:74145755]               -4.5150      1.361     -3.316      0.001      -7.183      -1.846\n",
      "C(actor_id)[T.id:twitter.com:74612885]                7.6654      1.644      4.662      0.000       4.443      10.888\n",
      "C(actor_id)[T.id:twitter.com:74924009]                5.0488      1.189      4.248      0.000       2.719       7.378\n",
      "C(actor_id)[T.id:twitter.com:753205348970930176]     -5.5628     10.888     -0.511      0.609     -26.905      15.779\n",
      "C(actor_id)[T.id:twitter.com:758360992388681728]     -5.0159      2.067     -2.426      0.015      -9.068      -0.964\n",
      "C(actor_id)[T.id:twitter.com:75839700]                0.3587      1.168      0.307      0.759      -1.931       2.648\n",
      "C(actor_id)[T.id:twitter.com:75883996]              -12.3380      1.650     -7.477      0.000     -15.572      -9.104\n",
      "C(actor_id)[T.id:twitter.com:75891845]               -3.3442      1.215     -2.752      0.006      -5.726      -0.963\n",
      "C(actor_id)[T.id:twitter.com:759211292578250752]     -6.7512      7.700     -0.877      0.381     -21.845       8.342\n",
      "C(actor_id)[T.id:twitter.com:76035930]               13.5160      1.175     11.505      0.000      11.213      15.819\n",
      "C(actor_id)[T.id:twitter.com:76146411]               -7.2328      1.208     -5.986      0.000      -9.601      -4.864\n",
      "C(actor_id)[T.id:twitter.com:76555642]                3.0440      1.692      1.799      0.072      -0.273       6.361\n",
      "C(actor_id)[T.id:twitter.com:76863747]               -9.2444      1.645     -5.621      0.000     -12.468      -6.021\n",
      "C(actor_id)[T.id:twitter.com:76947892]              -15.5206      1.651     -9.403      0.000     -18.756     -12.285\n",
      "C(actor_id)[T.id:twitter.com:772150676919054340]     -4.0079      1.650     -2.429      0.015      -7.242      -0.774\n",
      "C(actor_id)[T.id:twitter.com:77613385]               -9.6227      1.640     -5.869      0.000     -12.836      -6.409\n",
      "C(actor_id)[T.id:twitter.com:776287807]              -1.2947      1.169     -1.107      0.268      -3.587       0.998\n",
      "C(actor_id)[T.id:twitter.com:78232820]                6.2812      1.167      5.380      0.000       3.993       8.569\n",
      "C(actor_id)[T.id:twitter.com:78944377]               -2.0974      1.645     -1.275      0.202      -5.321       1.126\n",
      "C(actor_id)[T.id:twitter.com:79327466]               19.5825      1.209     16.192      0.000      17.212      21.953\n",
      "C(actor_id)[T.id:twitter.com:79802712]               -4.3119      1.335     -3.229      0.001      -6.929      -1.695\n",
      "C(actor_id)[T.id:twitter.com:80047141]               13.9033      1.646      8.448      0.000      10.678      17.129\n",
      "C(actor_id)[T.id:twitter.com:80454912]               -9.3828      1.644     -5.706      0.000     -12.606      -6.160\n",
      "C(actor_id)[T.id:twitter.com:806043]                 -1.7799      1.183     -1.505      0.132      -4.098       0.539\n",
      "C(actor_id)[T.id:twitter.com:809351634]              -8.8810      5.446     -1.631      0.103     -19.555       1.793\n",
      "C(actor_id)[T.id:twitter.com:80972439]               -1.7350      1.375     -1.262      0.207      -4.431       0.961\n",
      "C(actor_id)[T.id:twitter.com:817770653432553472]    -15.8251      2.578     -6.138      0.000     -20.879     -10.772\n",
      "C(actor_id)[T.id:twitter.com:81862900]               -3.4808      1.173     -2.967      0.003      -5.780      -1.181\n",
      "C(actor_id)[T.id:twitter.com:819212221515448320]     13.0897      3.053      4.287      0.000       7.105      19.074\n",
      "C(actor_id)[T.id:twitter.com:82790893]               -4.2333      1.210     -3.500      0.000      -6.604      -1.863\n",
      "C(actor_id)[T.id:twitter.com:83407967]                3.2274      1.173      2.751      0.006       0.928       5.527\n",
      "C(actor_id)[T.id:twitter.com:83441356]               -0.0751      1.416     -0.053      0.958      -2.851       2.701\n",
      "C(actor_id)[T.id:twitter.com:84195118]               -5.9211      1.647     -3.595      0.000      -9.150      -2.693\n",
      "C(actor_id)[T.id:twitter.com:84200591]                2.1649      1.334      1.623      0.105      -0.450       4.780\n",
      "C(actor_id)[T.id:twitter.com:845814672]              -6.4376      3.639     -1.769      0.077     -13.569       0.694\n",
      "C(actor_id)[T.id:twitter.com:84914746]              -13.3535      1.649     -8.100      0.000     -16.585     -10.122\n",
      "C(actor_id)[T.id:twitter.com:85198311]                2.1493      1.180      1.822      0.068      -0.163       4.462\n",
      "C(actor_id)[T.id:twitter.com:85201025]                3.7550      1.170      3.208      0.001       1.461       6.049\n",
      "C(actor_id)[T.id:twitter.com:852166370942963713]     -7.4443      1.440     -5.170      0.000     -10.267      -4.622\n",
      "C(actor_id)[T.id:twitter.com:85386874]               15.4089      1.169     13.184      0.000      13.118      17.700\n",
      "C(actor_id)[T.id:twitter.com:85393941]               -2.6434      1.170     -2.260      0.024      -4.936      -0.351\n",
      "C(actor_id)[T.id:twitter.com:85427368]               -2.8224      1.192     -2.367      0.018      -5.159      -0.486\n",
      "C(actor_id)[T.id:twitter.com:85547988]                5.7800      1.167      4.954      0.000       3.493       8.067\n",
      "C(actor_id)[T.id:twitter.com:85723280]              -15.9991      1.647     -9.717      0.000     -19.227     -12.772\n",
      "C(actor_id)[T.id:twitter.com:857350208652529665]     32.6052      7.702      4.233      0.000      17.509      47.702\n",
      "C(actor_id)[T.id:twitter.com:86162427]               -0.1078      1.296     -0.083      0.934      -2.649       2.433\n",
      "C(actor_id)[T.id:twitter.com:86736827]               -5.2131      1.168     -4.464      0.000      -7.502      -2.924\n",
      "C(actor_id)[T.id:twitter.com:87311238]                7.0673      2.825      2.501      0.012       1.530      12.605\n",
      "C(actor_id)[T.id:twitter.com:876601172492259328]     17.1983      2.160      7.963      0.000      12.965      21.432\n",
      "C(actor_id)[T.id:twitter.com:87968677]                3.0154      1.170      2.578      0.010       0.722       5.308\n",
      "C(actor_id)[T.id:twitter.com:883455335360548866]     -8.9856      1.848     -4.861      0.000     -12.609      -5.363\n",
      "C(actor_id)[T.id:twitter.com:89799361]               10.6044      1.197      8.856      0.000       8.257      12.951\n",
      "C(actor_id)[T.id:twitter.com:92443521]                0.7119      1.261      0.564      0.573      -1.761       3.184\n",
      "C(actor_id)[T.id:twitter.com:92537787]                6.1499      1.818      3.383      0.001       2.587       9.713\n",
      "C(actor_id)[T.id:twitter.com:926289838088818688]      5.2342      2.331      2.246      0.025       0.666       9.803\n",
      "C(actor_id)[T.id:twitter.com:92819626]               -0.0030      1.454     -0.002      0.998      -2.853       2.847\n",
      "C(actor_id)[T.id:twitter.com:93242237]               -3.0103      1.167     -2.579      0.010      -5.298      -0.723\n",
      "C(actor_id)[T.id:twitter.com:933909710356480000]    -10.1610      7.699     -1.320      0.187     -25.252       4.930\n",
      "C(actor_id)[T.id:twitter.com:938531456]              -8.8718      1.642     -5.402      0.000     -12.091      -5.653\n",
      "C(actor_id)[T.id:twitter.com:94370717]              -16.3961      2.329     -7.039      0.000     -20.962     -11.831\n",
      "C(actor_id)[T.id:twitter.com:958356811253473280]      2.6079      2.277      1.146      0.252      -1.854       7.070\n",
      "C(actor_id)[T.id:twitter.com:96033227]               -5.4444      1.223     -4.452      0.000      -7.841      -3.047\n",
      "C(actor_id)[T.id:twitter.com:963418881015631873]    -29.2303      5.030     -5.811      0.000     -39.090     -19.370\n",
      "C(actor_id)[T.id:twitter.com:96669079]              -12.3093      1.644     -7.487      0.000     -15.532      -9.087\n",
      "C(actor_id)[T.id:twitter.com:96766250]               -1.0538      1.207     -0.873      0.383      -3.420       1.313\n",
      "C(actor_id)[T.id:twitter.com:96789516]               -7.0143      1.169     -6.002      0.000      -9.305      -4.724\n",
      "C(actor_id)[T.id:twitter.com:973049869]               2.8813      3.292      0.875      0.381      -3.570       9.333\n",
      "C(actor_id)[T.id:twitter.com:98632081]                6.7311      1.654      4.070      0.000       3.489       9.973\n",
      "C(actor_id)[T.id:twitter.com:99045609]                5.5193      1.167      4.730      0.000       3.232       7.806\n",
      "C(actor_id)[T.id:twitter.com:99285051]                2.6516      1.175      2.256      0.024       0.348       4.956\n",
      "log_num_tweets                                        0.0527      0.066      0.799      0.424      -0.076       0.182\n",
      "==============================================================================\n",
      "Omnibus:                    12308.239   Durbin-Watson:                   1.419\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           198327.907\n",
      "Skew:                           2.265   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.785   Cond. No.                     5.60e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.64e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# two-way fixed effect\n",
    "data[\"actor_id\"] = data[\"actor.id\"]\n",
    "lm = sm.ols('perc_harsh_criticism ~ 1 + log_num_tweets + exile + C(t) + C(actor_id)', data).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS Regression Results                             \n",
      "================================================================================\n",
      "Dep. Variable:     perc_harsh_criticism   R-squared:                       0.502\n",
      "Model:                              OLS   Adj. R-squared:                  0.492\n",
      "Method:                   Least Squares   F-statistic:                     50.19\n",
      "Date:                  Mon, 03 Jun 2024   Prob (F-statistic):               0.00\n",
      "Time:                          14:36:33   Log-Likelihood:                -85330.\n",
      "No. Observations:                 22609   AIC:                         1.716e+05\n",
      "Df Residuals:                     22162   BIC:                         1.751e+05\n",
      "Df Model:                           446                                         \n",
      "Covariance Type:              nonrobust                                         \n",
      "=====================================================================================================================\n",
      "                                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                             6.6360      0.788      8.426      0.000       5.092       8.180\n",
      "exile[T.yes]                                          0.6108      0.326      1.876      0.061      -0.027       1.249\n",
      "C(t)[T.1.0]                                           1.0888      1.034      1.053      0.292      -0.938       3.115\n",
      "C(t)[T.2.0]                                          -2.2260      1.011     -2.202      0.028      -4.208      -0.244\n",
      "C(t)[T.3.0]                                          -0.9163      1.000     -0.916      0.360      -2.877       1.044\n",
      "C(t)[T.4.0]                                          -0.1267      0.996     -0.127      0.899      -2.078       1.825\n",
      "C(t)[T.5.0]                                          -1.6984      0.988     -1.719      0.086      -3.635       0.238\n",
      "C(t)[T.6.0]                                          -0.9022      0.978     -0.922      0.356      -2.820       1.015\n",
      "C(t)[T.7.0]                                          -2.4394      0.963     -2.533      0.011      -4.327      -0.552\n",
      "C(t)[T.8.0]                                          -1.9454      0.954     -2.040      0.041      -3.814      -0.076\n",
      "C(t)[T.9.0]                                          -3.2119      0.941     -3.413      0.001      -5.056      -1.367\n",
      "C(t)[T.10.0]                                         -2.9056      0.939     -3.095      0.002      -4.745      -1.066\n",
      "C(t)[T.11.0]                                         -2.7206      0.937     -2.903      0.004      -4.558      -0.884\n",
      "C(t)[T.12.0]                                         -1.2990      0.925     -1.404      0.160      -3.113       0.515\n",
      "C(t)[T.13.0]                                          5.9109      0.914      6.465      0.000       4.119       7.703\n",
      "C(t)[T.14.0]                                          5.8099      0.896      6.484      0.000       4.053       7.566\n",
      "C(t)[T.15.0]                                          1.8245      0.886      2.059      0.039       0.088       3.561\n",
      "C(t)[T.16.0]                                          2.9463      0.887      3.321      0.001       1.207       4.685\n",
      "C(t)[T.17.0]                                          0.4049      0.877      0.461      0.644      -1.315       2.124\n",
      "C(t)[T.18.0]                                         -0.9037      0.874     -1.035      0.301      -2.616       0.808\n",
      "C(t)[T.19.0]                                         -1.6779      0.854     -1.964      0.050      -3.352      -0.004\n",
      "C(t)[T.20.0]                                         -3.0787      0.854     -3.607      0.000      -4.752      -1.406\n",
      "C(t)[T.21.0]                                         -2.2159      0.845     -2.622      0.009      -3.872      -0.559\n",
      "C(t)[T.22.0]                                         -2.5453      0.844     -3.016      0.003      -4.200      -0.891\n",
      "C(t)[T.23.0]                                          1.8814      0.833      2.257      0.024       0.248       3.515\n",
      "C(t)[T.24.0]                                         -1.5518      0.827     -1.877      0.061      -3.172       0.069\n",
      "C(t)[T.25.0]                                          2.1456      0.815      2.632      0.009       0.547       3.744\n",
      "C(t)[T.26.0]                                         -2.0557      0.798     -2.577      0.010      -3.619      -0.492\n",
      "C(t)[T.27.0]                                         -3.3113      0.799     -4.146      0.000      -4.877      -1.746\n",
      "C(t)[T.28.0]                                         -2.2538      0.791     -2.850      0.004      -3.804      -0.704\n",
      "C(t)[T.29.0]                                         -3.2170      0.781     -4.119      0.000      -4.748      -1.686\n",
      "C(t)[T.30.0]                                         -5.4994      0.779     -7.057      0.000      -7.027      -3.972\n",
      "C(t)[T.31.0]                                         -5.1254      0.769     -6.666      0.000      -6.632      -3.618\n",
      "C(t)[T.32.0]                                         -4.4000      0.752     -5.853      0.000      -5.873      -2.926\n",
      "C(t)[T.33.0]                                         -6.0408      0.739     -8.175      0.000      -7.489      -4.592\n",
      "C(t)[T.34.0]                                         -6.2092      0.732     -8.479      0.000      -7.645      -4.774\n",
      "C(t)[T.35.0]                                         -6.1569      0.727     -8.464      0.000      -7.583      -4.731\n",
      "C(t)[T.36.0]                                         -6.7603      0.717     -9.422      0.000      -8.167      -5.354\n",
      "C(t)[T.37.0]                                         -4.7512      0.712     -6.671      0.000      -6.147      -3.355\n",
      "C(t)[T.38.0]                                         -3.6106      0.714     -5.059      0.000      -5.010      -2.212\n",
      "C(t)[T.39.0]                                         -5.9493      0.704     -8.447      0.000      -7.330      -4.569\n",
      "C(t)[T.40.0]                                         -5.5035      0.698     -7.887      0.000      -6.871      -4.136\n",
      "C(t)[T.41.0]                                         -4.8737      0.699     -6.969      0.000      -6.245      -3.503\n",
      "C(t)[T.42.0]                                         -5.1984      0.690     -7.529      0.000      -6.552      -3.845\n",
      "C(t)[T.43.0]                                         -4.9801      0.682     -7.306      0.000      -6.316      -3.644\n",
      "C(t)[T.44.0]                                         -3.4302      0.676     -5.076      0.000      -4.755      -2.106\n",
      "C(t)[T.45.0]                                         -3.5455      0.674     -5.259      0.000      -4.867      -2.224\n",
      "C(t)[T.46.0]                                         -0.0406      0.668     -0.061      0.952      -1.351       1.269\n",
      "C(t)[T.47.0]                                         -1.1713      0.667     -1.756      0.079      -2.479       0.136\n",
      "C(t)[T.48.0]                                         -2.2591      0.668     -3.383      0.001      -3.568      -0.950\n",
      "C(t)[T.49.0]                                         -1.3639      0.661     -2.062      0.039      -2.660      -0.068\n",
      "C(t)[T.50.0]                                         -3.0671      0.657     -4.670      0.000      -4.354      -1.780\n",
      "C(t)[T.51.0]                                          6.5483      0.652     10.037      0.000       5.269       7.827\n",
      "C(t)[T.52.0]                                          6.0136      0.645      9.317      0.000       4.748       7.279\n",
      "C(t)[T.53.0]                                          2.7731      0.645      4.302      0.000       1.510       4.037\n",
      "C(t)[T.54.0]                                          0.6904      0.646      1.069      0.285      -0.576       1.957\n",
      "C(t)[T.55.0]                                          0.7814      0.638      1.225      0.221      -0.469       2.032\n",
      "C(t)[T.56.0]                                         -1.5997      0.640     -2.499      0.012      -2.854      -0.345\n",
      "C(t)[T.57.0]                                         -4.6565      0.642     -7.257      0.000      -5.914      -3.399\n",
      "C(t)[T.58.0]                                         -1.1919      0.642     -1.855      0.064      -2.451       0.067\n",
      "C(t)[T.59.0]                                          0.5256      0.647      0.812      0.417      -0.743       1.794\n",
      "C(t)[T.60.0]                                          0.0878      0.643      0.137      0.891      -1.173       1.348\n",
      "C(t)[T.61.0]                                         -0.9657      0.653     -1.479      0.139      -2.245       0.314\n",
      "C(t)[T.62.0]                                         -1.7482      0.651     -2.687      0.007      -3.024      -0.473\n",
      "C(t)[T.63.0]                                         -1.3353      0.653     -2.045      0.041      -2.615      -0.056\n",
      "C(t)[T.64.0]                                          2.1487      0.647      3.320      0.001       0.880       3.417\n",
      "C(t)[T.65.0]                                          3.8965      0.650      5.994      0.000       2.622       5.171\n",
      "C(t)[T.66.0]                                         -1.5658      0.673     -2.328      0.020      -2.884      -0.247\n",
      "C(t)[T.67.0]                                          0.4547      0.668      0.680      0.496      -0.855       1.765\n",
      "C(t)[T.68.0]                                          1.1023      0.672      1.639      0.101      -0.216       2.420\n",
      "C(t)[T.69.0]                                          4.6166      0.663      6.963      0.000       3.317       5.916\n",
      "C(t)[T.70.0]                                          1.6078      0.676      2.378      0.017       0.283       2.933\n",
      "C(t)[T.71.0]                                          1.1207      0.675      1.659      0.097      -0.203       2.445\n",
      "C(t)[T.72.0]                                          1.0209      0.664      1.537      0.124      -0.281       2.323\n",
      "C(t)[T.73.0]                                         -1.3138      0.673     -1.952      0.051      -2.633       0.006\n",
      "C(t)[T.74.0]                                          5.0467      0.669      7.541      0.000       3.735       6.358\n",
      "C(t)[T.75.0]                                          0.5102      0.665      0.767      0.443      -0.793       1.814\n",
      "C(t)[T.76.0]                                          7.1833      0.662     10.854      0.000       5.886       8.480\n",
      "C(t)[T.77.0]                                          5.0881      0.676      7.526      0.000       3.763       6.413\n",
      "C(t)[T.78.0]                                          9.6603      0.682     14.155      0.000       8.323      10.998\n",
      "C(t)[T.79.0]                                          2.3310      0.685      3.404      0.001       0.989       3.673\n",
      "C(t)[T.80.0]                                          3.6871      0.689      5.348      0.000       2.336       5.038\n",
      "C(t)[T.81.0]                                          1.3081      0.700      1.869      0.062      -0.063       2.680\n",
      "C(t)[T.82.0]                                         -2.5104      0.699     -3.591      0.000      -3.881      -1.140\n",
      "C(t)[T.83.0]                                          2.7813      0.702      3.962      0.000       1.405       4.157\n",
      "C(t)[T.84.0]                                         -0.0384      0.712     -0.054      0.957      -1.433       1.356\n",
      "C(t)[T.85.0]                                         -0.4901      0.720     -0.681      0.496      -1.901       0.921\n",
      "C(t)[T.86.0]                                         -0.0638      0.718     -0.089      0.929      -1.471       1.344\n",
      "C(t)[T.87.0]                                         -1.0479      0.729     -1.438      0.150      -2.476       0.380\n",
      "C(t)[T.88.0]                                          1.6640      0.739      2.252      0.024       0.215       3.112\n",
      "log_num_tweets                                        0.1238      0.059      2.106      0.035       0.009       0.239\n",
      "t:C(actor_id)[id:twitter.com:101624479]               0.3601      0.026     13.862      0.000       0.309       0.411\n",
      "t:C(actor_id)[id:twitter.com:1019056064]              0.1905      0.027      7.168      0.000       0.138       0.243\n",
      "t:C(actor_id)[id:twitter.com:102188256]               0.0482      0.057      0.841      0.401      -0.064       0.161\n",
      "t:C(actor_id)[id:twitter.com:102482331]               0.2970      0.026     11.613      0.000       0.247       0.347\n",
      "t:C(actor_id)[id:twitter.com:1025567515]              0.0876      0.031      2.854      0.004       0.027       0.148\n",
      "t:C(actor_id)[id:twitter.com:1040696701]              0.1856      0.745      0.249      0.803      -1.275       1.647\n",
      "t:C(actor_id)[id:twitter.com:105172211]               0.1629      0.026      6.236      0.000       0.112       0.214\n",
      "t:C(actor_id)[id:twitter.com:106435977]               0.2180      0.026      8.388      0.000       0.167       0.269\n",
      "t:C(actor_id)[id:twitter.com:107519253]              -0.0412      0.061     -0.677      0.498      -0.161       0.078\n",
      "t:C(actor_id)[id:twitter.com:107694628]               0.2272      0.032      7.035      0.000       0.164       0.290\n",
      "t:C(actor_id)[id:twitter.com:108117226]               0.1537      0.027      5.673      0.000       0.101       0.207\n",
      "t:C(actor_id)[id:twitter.com:108177410]               0.2449      0.026      9.584      0.000       0.195       0.295\n",
      "t:C(actor_id)[id:twitter.com:108290069]               0.4144      0.026     15.922      0.000       0.363       0.465\n",
      "t:C(actor_id)[id:twitter.com:109057415]               0.0059      0.026      0.230      0.818      -0.044       0.056\n",
      "t:C(actor_id)[id:twitter.com:109485280]              -0.1434      0.169     -0.851      0.395      -0.474       0.187\n",
      "t:C(actor_id)[id:twitter.com:109591461]               0.3915      0.026     15.319      0.000       0.341       0.442\n",
      "t:C(actor_id)[id:twitter.com:109667868]               0.0700      0.029      2.374      0.018       0.012       0.128\n",
      "t:C(actor_id)[id:twitter.com:1101752148]             -0.1952      0.082     -2.374      0.018      -0.356      -0.034\n",
      "t:C(actor_id)[id:twitter.com:110483566]              -0.0319      0.026     -1.249      0.212      -0.082       0.018\n",
      "t:C(actor_id)[id:twitter.com:111042340]               0.1173      0.026      4.588      0.000       0.067       0.167\n",
      "t:C(actor_id)[id:twitter.com:111782846]               0.0976      0.026      3.818      0.000       0.047       0.148\n",
      "t:C(actor_id)[id:twitter.com:1128151652]              0.1972      0.026      7.709      0.000       0.147       0.247\n",
      "t:C(actor_id)[id:twitter.com:112828160]               0.1123      0.032      3.474      0.001       0.049       0.176\n",
      "t:C(actor_id)[id:twitter.com:1129178128822226949]     0.1426      0.048      2.995      0.003       0.049       0.236\n",
      "t:C(actor_id)[id:twitter.com:113733516]               0.0307      0.030      1.012      0.312      -0.029       0.090\n",
      "t:C(actor_id)[id:twitter.com:114074686]              -0.0693      0.026     -2.644      0.008      -0.121      -0.018\n",
      "t:C(actor_id)[id:twitter.com:114112198]               0.0977      0.026      3.817      0.000       0.048       0.148\n",
      "t:C(actor_id)[id:twitter.com:114185889]              -0.0529      0.064     -0.821      0.412      -0.179       0.073\n",
      "t:C(actor_id)[id:twitter.com:114339619]               0.1317      0.026      5.157      0.000       0.082       0.182\n",
      "t:C(actor_id)[id:twitter.com:114472937]               0.0805      0.030      2.650      0.008       0.021       0.140\n",
      "t:C(actor_id)[id:twitter.com:115717343]               0.1112      0.026      4.355      0.000       0.061       0.161\n",
      "t:C(actor_id)[id:twitter.com:116227294]               0.3864      0.026     15.028      0.000       0.336       0.437\n",
      "t:C(actor_id)[id:twitter.com:1163186330966396928]     0.2761      0.042      6.529      0.000       0.193       0.359\n",
      "t:C(actor_id)[id:twitter.com:1163416884]              0.1239      0.026      4.754      0.000       0.073       0.175\n",
      "t:C(actor_id)[id:twitter.com:117439710]               0.6947      0.213      3.263      0.001       0.277       1.112\n",
      "t:C(actor_id)[id:twitter.com:117961446]               0.0191      0.026      0.750      0.453      -0.031       0.069\n",
      "t:C(actor_id)[id:twitter.com:1183833234842537986]     0.1603      0.046      3.457      0.001       0.069       0.251\n",
      "t:C(actor_id)[id:twitter.com:1201197247062519808]    -0.0160      0.057     -0.281      0.778      -0.127       0.095\n",
      "t:C(actor_id)[id:twitter.com:120843199]               0.2355      0.026      9.056      0.000       0.185       0.286\n",
      "t:C(actor_id)[id:twitter.com:120928088]               0.1494      0.026      5.850      0.000       0.099       0.199\n",
      "t:C(actor_id)[id:twitter.com:122221420]               0.0008      0.026      0.032      0.974      -0.049       0.051\n",
      "t:C(actor_id)[id:twitter.com:1222506341421518849]     0.0644      0.057      1.132      0.258      -0.047       0.176\n",
      "t:C(actor_id)[id:twitter.com:124762525]               0.0986      0.026      3.862      0.000       0.049       0.149\n",
      "t:C(actor_id)[id:twitter.com:126431606]               0.1366      0.027      5.121      0.000       0.084       0.189\n",
      "t:C(actor_id)[id:twitter.com:1268659980]              0.1401      0.026      5.460      0.000       0.090       0.190\n",
      "t:C(actor_id)[id:twitter.com:127637567]              -0.0727      0.026     -2.791      0.005      -0.124      -0.022\n",
      "t:C(actor_id)[id:twitter.com:1278533784]             -0.0672      0.029     -2.324      0.020      -0.124      -0.011\n",
      "t:C(actor_id)[id:twitter.com:130224262]               0.1832      0.026      7.173      0.000       0.133       0.233\n",
      "t:C(actor_id)[id:twitter.com:130624925]               0.0381      0.027      1.415      0.157      -0.015       0.091\n",
      "t:C(actor_id)[id:twitter.com:131519051]               0.3566      0.026     13.839      0.000       0.306       0.407\n",
      "t:C(actor_id)[id:twitter.com:131523433]               0.1440      0.026      5.641      0.000       0.094       0.194\n",
      "t:C(actor_id)[id:twitter.com:131707109]               0.1155      0.026      4.380      0.000       0.064       0.167\n",
      "t:C(actor_id)[id:twitter.com:132278538]               0.0402      0.026      1.571      0.116      -0.010       0.090\n",
      "t:C(actor_id)[id:twitter.com:132279449]               0.1599      0.028      5.754      0.000       0.105       0.214\n",
      "t:C(actor_id)[id:twitter.com:132342295]              -0.0875      0.029     -3.025      0.002      -0.144      -0.031\n",
      "t:C(actor_id)[id:twitter.com:133138148]               0.2605      0.026     10.022      0.000       0.210       0.311\n",
      "t:C(actor_id)[id:twitter.com:133407970]               0.0793      0.026      3.004      0.003       0.028       0.131\n",
      "t:C(actor_id)[id:twitter.com:133707256]              -0.1743      0.164     -1.065      0.287      -0.495       0.147\n",
      "t:C(actor_id)[id:twitter.com:133728812]               0.1335      0.026      5.197      0.000       0.083       0.184\n",
      "t:C(actor_id)[id:twitter.com:134208093]               0.1650      0.026      6.447      0.000       0.115       0.215\n",
      "t:C(actor_id)[id:twitter.com:134557956]              -0.0541      0.044     -1.222      0.222      -0.141       0.033\n",
      "t:C(actor_id)[id:twitter.com:135033641]              -0.1129      0.043     -2.608      0.009      -0.198      -0.028\n",
      "t:C(actor_id)[id:twitter.com:135177315]               0.1843      0.065      2.816      0.005       0.056       0.313\n",
      "t:C(actor_id)[id:twitter.com:135607670]              -0.1602      0.082     -1.954      0.051      -0.321       0.001\n",
      "t:C(actor_id)[id:twitter.com:137128647]               0.0917      0.037      2.488      0.013       0.019       0.164\n",
      "t:C(actor_id)[id:twitter.com:137430904]               0.0770      0.145      0.531      0.596      -0.207       0.361\n",
      "t:C(actor_id)[id:twitter.com:137727433]               0.1972      0.026      7.607      0.000       0.146       0.248\n",
      "t:C(actor_id)[id:twitter.com:137808883]               0.0930      0.026      3.634      0.000       0.043       0.143\n",
      "t:C(actor_id)[id:twitter.com:138515802]               0.2677      0.026     10.119      0.000       0.216       0.320\n",
      "t:C(actor_id)[id:twitter.com:138534812]               0.1691      0.026      6.609      0.000       0.119       0.219\n",
      "t:C(actor_id)[id:twitter.com:138549102]               0.2616      0.026     10.062      0.000       0.211       0.313\n",
      "t:C(actor_id)[id:twitter.com:138558552]               0.3640      0.026     13.936      0.000       0.313       0.415\n",
      "t:C(actor_id)[id:twitter.com:138911971]               0.3490      0.304      1.150      0.250      -0.246       0.944\n",
      "t:C(actor_id)[id:twitter.com:139841711]               0.3468      0.026     13.483      0.000       0.296       0.397\n",
      "t:C(actor_id)[id:twitter.com:140122683]               0.2894      0.026     11.205      0.000       0.239       0.340\n",
      "t:C(actor_id)[id:twitter.com:1406598860]             -0.0729      0.147     -0.497      0.619      -0.360       0.215\n",
      "t:C(actor_id)[id:twitter.com:140829257]              -0.1064      0.028     -3.758      0.000      -0.162      -0.051\n",
      "t:C(actor_id)[id:twitter.com:140901683]               0.0329      0.026      1.287      0.198      -0.017       0.083\n",
      "t:C(actor_id)[id:twitter.com:14119371]                0.2545      0.026      9.771      0.000       0.203       0.306\n",
      "t:C(actor_id)[id:twitter.com:142312323]               0.2753      0.029      9.561      0.000       0.219       0.332\n",
      "t:C(actor_id)[id:twitter.com:142751926]               0.3108      0.026     11.990      0.000       0.260       0.362\n",
      "t:C(actor_id)[id:twitter.com:142922225]              -0.0332      0.072     -0.462      0.644      -0.174       0.108\n",
      "t:C(actor_id)[id:twitter.com:1431759750]              0.3539      0.026     13.603      0.000       0.303       0.405\n",
      "t:C(actor_id)[id:twitter.com:143237375]               0.1242      0.026      4.817      0.000       0.074       0.175\n",
      "t:C(actor_id)[id:twitter.com:143254724]               0.0527      0.031      1.722      0.085      -0.007       0.113\n",
      "t:C(actor_id)[id:twitter.com:143582572]               0.2159      0.048      4.481      0.000       0.121       0.310\n",
      "t:C(actor_id)[id:twitter.com:145649305]              -0.0603      0.070     -0.858      0.391      -0.198       0.078\n",
      "t:C(actor_id)[id:twitter.com:145810767]               0.3238      0.026     12.642      0.000       0.274       0.374\n",
      "t:C(actor_id)[id:twitter.com:146067210]               0.0147      0.029      0.513      0.608      -0.041       0.071\n",
      "t:C(actor_id)[id:twitter.com:146121511]              -0.0594      0.026     -2.307      0.021      -0.110      -0.009\n",
      "t:C(actor_id)[id:twitter.com:146295125]               0.1421      0.042      3.391      0.001       0.060       0.224\n",
      "t:C(actor_id)[id:twitter.com:1465099951]              0.0539      0.048      1.129      0.259      -0.040       0.147\n",
      "t:C(actor_id)[id:twitter.com:146523859]              -0.0570      0.062     -0.916      0.359      -0.179       0.065\n",
      "t:C(actor_id)[id:twitter.com:147337850]              -0.0153      0.026     -0.583      0.560      -0.067       0.036\n",
      "t:C(actor_id)[id:twitter.com:149737458]               0.1303      0.027      4.841      0.000       0.078       0.183\n",
      "t:C(actor_id)[id:twitter.com:15012693]                0.1256      0.027      4.735      0.000       0.074       0.178\n",
      "t:C(actor_id)[id:twitter.com:150296174]               0.0146      0.028      0.530      0.596      -0.040       0.069\n",
      "t:C(actor_id)[id:twitter.com:153170209]               0.1851      0.026      7.076      0.000       0.134       0.236\n",
      "t:C(actor_id)[id:twitter.com:1559000173]              0.2130      0.026      8.227      0.000       0.162       0.264\n",
      "t:C(actor_id)[id:twitter.com:156352850]               0.2049      0.026      7.831      0.000       0.154       0.256\n",
      "t:C(actor_id)[id:twitter.com:157880742]               0.0627      0.026      2.452      0.014       0.013       0.113\n",
      "t:C(actor_id)[id:twitter.com:160353332]              -0.2061      0.558     -0.369      0.712      -1.300       0.888\n",
      "t:C(actor_id)[id:twitter.com:161095085]               0.0948      0.027      3.529      0.000       0.042       0.147\n",
      "t:C(actor_id)[id:twitter.com:168145965]              -0.1087      0.027     -4.054      0.000      -0.161      -0.056\n",
      "t:C(actor_id)[id:twitter.com:168361033]               0.3878      0.026     14.976      0.000       0.337       0.439\n",
      "t:C(actor_id)[id:twitter.com:1691316967]              0.1055      0.028      3.793      0.000       0.051       0.160\n",
      "t:C(actor_id)[id:twitter.com:169154681]               0.0714      0.026      2.732      0.006       0.020       0.123\n",
      "t:C(actor_id)[id:twitter.com:169201397]              -0.0866      0.029     -3.017      0.003      -0.143      -0.030\n",
      "t:C(actor_id)[id:twitter.com:169454901]               0.0833      0.026      3.237      0.001       0.033       0.134\n",
      "t:C(actor_id)[id:twitter.com:169687049]               0.2142      0.029      7.417      0.000       0.158       0.271\n",
      "t:C(actor_id)[id:twitter.com:1723833512]             -0.5970      0.442     -1.351      0.177      -1.463       0.269\n",
      "t:C(actor_id)[id:twitter.com:174939254]              -0.1240      0.662     -0.187      0.852      -1.422       1.174\n",
      "t:C(actor_id)[id:twitter.com:177335715]               0.1021      0.028      3.696      0.000       0.048       0.156\n",
      "t:C(actor_id)[id:twitter.com:179724986]               0.1690      0.026      6.420      0.000       0.117       0.221\n",
      "t:C(actor_id)[id:twitter.com:18672473]                0.0694      0.026      2.718      0.007       0.019       0.119\n",
      "t:C(actor_id)[id:twitter.com:186837436]               0.1792      0.073      2.441      0.015       0.035       0.323\n",
      "t:C(actor_id)[id:twitter.com:188165366]              -0.0455      0.028     -1.609      0.108      -0.101       0.010\n",
      "t:C(actor_id)[id:twitter.com:189505030]               0.0031      0.026      0.122      0.903      -0.047       0.053\n",
      "t:C(actor_id)[id:twitter.com:189521140]               0.0108      0.026      0.424      0.672      -0.039       0.061\n",
      "t:C(actor_id)[id:twitter.com:1918380450]              0.1703      0.026      6.572      0.000       0.119       0.221\n",
      "t:C(actor_id)[id:twitter.com:192288282]              -0.0175      0.026     -0.686      0.493      -0.068       0.033\n",
      "t:C(actor_id)[id:twitter.com:1935412261]              0.0618      0.026      2.400      0.016       0.011       0.112\n",
      "t:C(actor_id)[id:twitter.com:1941430368]             -0.4217      1.186     -0.356      0.722      -2.746       1.902\n",
      "t:C(actor_id)[id:twitter.com:196271703]               0.0860      0.026      3.361      0.001       0.036       0.136\n",
      "t:C(actor_id)[id:twitter.com:197605220]               0.2592      0.026     10.059      0.000       0.209       0.310\n",
      "t:C(actor_id)[id:twitter.com:198613032]               0.3715      0.026     14.134      0.000       0.320       0.423\n",
      "t:C(actor_id)[id:twitter.com:201538731]              -0.1058      0.160     -0.663      0.508      -0.419       0.207\n",
      "t:C(actor_id)[id:twitter.com:204033649]               0.1566      0.026      6.130      0.000       0.107       0.207\n",
      "t:C(actor_id)[id:twitter.com:207865365]               0.1161      0.028      4.193      0.000       0.062       0.170\n",
      "t:C(actor_id)[id:twitter.com:20849512]                0.3131      0.037      8.492      0.000       0.241       0.385\n",
      "t:C(actor_id)[id:twitter.com:211943582]               0.2151      0.026      8.240      0.000       0.164       0.266\n",
      "t:C(actor_id)[id:twitter.com:214114587]               0.5316      0.026     20.410      0.000       0.481       0.583\n",
      "t:C(actor_id)[id:twitter.com:216646024]               0.2149      0.026      8.356      0.000       0.164       0.265\n",
      "t:C(actor_id)[id:twitter.com:218180701]               0.0495      0.027      1.868      0.062      -0.002       0.102\n",
      "t:C(actor_id)[id:twitter.com:22537447]               -0.0415      0.026     -1.625      0.104      -0.092       0.009\n",
      "t:C(actor_id)[id:twitter.com:2255297474]             -0.2867      0.137     -2.095      0.036      -0.555      -0.019\n",
      "t:C(actor_id)[id:twitter.com:226366184]              -0.0642      0.027     -2.420      0.016      -0.116      -0.012\n",
      "t:C(actor_id)[id:twitter.com:2265669221]              0.2322      0.028      8.271      0.000       0.177       0.287\n",
      "t:C(actor_id)[id:twitter.com:2273310218]             -0.0859      0.067     -1.290      0.197      -0.217       0.045\n",
      "t:C(actor_id)[id:twitter.com:229090782]               0.0962      0.026      3.711      0.000       0.045       0.147\n",
      "t:C(actor_id)[id:twitter.com:229647379]               0.0395      0.026      1.549      0.121      -0.010       0.090\n",
      "t:C(actor_id)[id:twitter.com:231902294]               0.2355      0.037      6.342      0.000       0.163       0.308\n",
      "t:C(actor_id)[id:twitter.com:2354503127]              0.1814      0.026      7.097      0.000       0.131       0.232\n",
      "t:C(actor_id)[id:twitter.com:23719107]                0.1235      0.026      4.784      0.000       0.073       0.174\n",
      "t:C(actor_id)[id:twitter.com:2400785744]              0.2256      0.026      8.712      0.000       0.175       0.276\n",
      "t:C(actor_id)[id:twitter.com:248010159]               0.0242      0.026      0.938      0.348      -0.026       0.075\n",
      "t:C(actor_id)[id:twitter.com:2505772886]             -0.0741      0.084     -0.882      0.378      -0.239       0.091\n",
      "t:C(actor_id)[id:twitter.com:2510653449]              0.1358      0.027      4.982      0.000       0.082       0.189\n",
      "t:C(actor_id)[id:twitter.com:253581736]              -0.0058      0.046     -0.125      0.901      -0.097       0.085\n",
      "t:C(actor_id)[id:twitter.com:254333960]               0.0701      0.052      1.357      0.175      -0.031       0.171\n",
      "t:C(actor_id)[id:twitter.com:256024862]               0.0882      0.027      3.297      0.001       0.036       0.141\n",
      "t:C(actor_id)[id:twitter.com:256100154]               0.2464      0.028      8.880      0.000       0.192       0.301\n",
      "t:C(actor_id)[id:twitter.com:2565811548]             -0.0206      0.030     -0.678      0.498      -0.080       0.039\n",
      "t:C(actor_id)[id:twitter.com:256695465]              -0.0089      0.026     -0.347      0.729      -0.059       0.041\n",
      "t:C(actor_id)[id:twitter.com:262454885]               0.2653      0.027      9.729      0.000       0.212       0.319\n",
      "t:C(actor_id)[id:twitter.com:263998351]               0.3543      0.026     13.732      0.000       0.304       0.405\n",
      "t:C(actor_id)[id:twitter.com:264866743]               0.0367      0.026      1.437      0.151      -0.013       0.087\n",
      "t:C(actor_id)[id:twitter.com:266868053]              -0.1011      0.026     -3.922      0.000      -0.152      -0.051\n",
      "t:C(actor_id)[id:twitter.com:2734570963]             -0.1316      0.071     -1.846      0.065      -0.271       0.008\n",
      "t:C(actor_id)[id:twitter.com:278227183]               0.4044      0.026     15.585      0.000       0.354       0.455\n",
      "t:C(actor_id)[id:twitter.com:281683108]               0.0080      0.027      0.295      0.768      -0.045       0.061\n",
      "t:C(actor_id)[id:twitter.com:283999406]               0.0024      0.029      0.084      0.933      -0.054       0.059\n",
      "t:C(actor_id)[id:twitter.com:29110681]                0.3303      0.026     12.920      0.000       0.280       0.380\n",
      "t:C(actor_id)[id:twitter.com:292065898]               0.1840      0.026      6.966      0.000       0.132       0.236\n",
      "t:C(actor_id)[id:twitter.com:2946315838]              0.4500      0.027     16.762      0.000       0.397       0.503\n",
      "t:C(actor_id)[id:twitter.com:2947638843]              0.2701      0.034      7.908      0.000       0.203       0.337\n",
      "t:C(actor_id)[id:twitter.com:296943655]               0.0894      0.030      3.029      0.002       0.032       0.147\n",
      "t:C(actor_id)[id:twitter.com:3014616760]             -0.0857      0.045     -1.915      0.056      -0.173       0.002\n",
      "t:C(actor_id)[id:twitter.com:3045502209]              0.0886      0.228      0.388      0.698      -0.359       0.536\n",
      "t:C(actor_id)[id:twitter.com:3046605658]              0.6510      0.031     20.945      0.000       0.590       0.712\n",
      "t:C(actor_id)[id:twitter.com:306358232]               0.0420      0.027      1.548      0.122      -0.011       0.095\n",
      "t:C(actor_id)[id:twitter.com:307648868]               0.0291      0.026      1.128      0.259      -0.021       0.080\n",
      "t:C(actor_id)[id:twitter.com:3130447076]             -0.0503      0.031     -1.601      0.109      -0.112       0.011\n",
      "t:C(actor_id)[id:twitter.com:313481830]              -0.0818      0.037     -2.182      0.029      -0.155      -0.008\n",
      "t:C(actor_id)[id:twitter.com:3289959195]             -0.1209      0.368     -0.328      0.743      -0.843       0.601\n",
      "t:C(actor_id)[id:twitter.com:332642789]               0.0225      0.026      0.880      0.379      -0.028       0.073\n",
      "t:C(actor_id)[id:twitter.com:3344950060]              0.1957      0.068      2.869      0.004       0.062       0.329\n",
      "t:C(actor_id)[id:twitter.com:334825997]              -0.0533      0.289     -0.185      0.854      -0.619       0.512\n",
      "t:C(actor_id)[id:twitter.com:334950418]               0.1018      0.026      3.976      0.000       0.052       0.152\n",
      "t:C(actor_id)[id:twitter.com:3350745243]             -0.1179      0.368     -0.320      0.749      -0.840       0.604\n",
      "t:C(actor_id)[id:twitter.com:3356538195]              0.1663      0.028      5.999      0.000       0.112       0.221\n",
      "t:C(actor_id)[id:twitter.com:33718836]                0.2640      0.026     10.113      0.000       0.213       0.315\n",
      "t:C(actor_id)[id:twitter.com:3395765697]             -0.0590      0.199     -0.296      0.767      -0.450       0.332\n",
      "t:C(actor_id)[id:twitter.com:3401731887]              0.2428      0.026      9.347      0.000       0.192       0.294\n",
      "t:C(actor_id)[id:twitter.com:3423025671]              0.0132      0.165      0.080      0.936      -0.309       0.336\n",
      "t:C(actor_id)[id:twitter.com:342330922]               0.2974      0.026     11.648      0.000       0.247       0.347\n",
      "t:C(actor_id)[id:twitter.com:342363193]               0.0522      0.026      1.998      0.046       0.001       0.103\n",
      "t:C(actor_id)[id:twitter.com:3430614579]              0.1556      0.102      1.530      0.126      -0.044       0.355\n",
      "t:C(actor_id)[id:twitter.com:344351891]               0.1923      0.026      7.401      0.000       0.141       0.243\n",
      "t:C(actor_id)[id:twitter.com:3502107555]              0.1449      0.029      5.077      0.000       0.089       0.201\n",
      "t:C(actor_id)[id:twitter.com:3571499722]             -0.0002      0.150     -0.001      0.999      -0.294       0.293\n",
      "t:C(actor_id)[id:twitter.com:364959367]              -0.0173      0.027     -0.653      0.514      -0.069       0.035\n",
      "t:C(actor_id)[id:twitter.com:376467959]              -0.0800      0.028     -2.847      0.004      -0.135      -0.025\n",
      "t:C(actor_id)[id:twitter.com:376522933]               0.0166      0.034      0.486      0.627      -0.050       0.083\n",
      "t:C(actor_id)[id:twitter.com:37669604]                0.2015      0.027      7.445      0.000       0.148       0.255\n",
      "t:C(actor_id)[id:twitter.com:379197417]              -0.0235      0.026     -0.919      0.358      -0.073       0.027\n",
      "t:C(actor_id)[id:twitter.com:39176902]                0.2574      0.026     10.064      0.000       0.207       0.307\n",
      "t:C(actor_id)[id:twitter.com:39621575]                0.0202      0.027      0.760      0.447      -0.032       0.072\n",
      "t:C(actor_id)[id:twitter.com:40246785]                0.4502      0.026     17.306      0.000       0.399       0.501\n",
      "t:C(actor_id)[id:twitter.com:4119165615]              0.0311      0.086      0.361      0.718      -0.138       0.200\n",
      "t:C(actor_id)[id:twitter.com:41462167]                0.5344      0.087      6.133      0.000       0.364       0.705\n",
      "t:C(actor_id)[id:twitter.com:41575911]                0.2999      0.026     11.736      0.000       0.250       0.350\n",
      "t:C(actor_id)[id:twitter.com:41626835]               -0.0530      0.026     -2.075      0.038      -0.103      -0.003\n",
      "t:C(actor_id)[id:twitter.com:42176636]               -0.0544      0.026     -2.113      0.035      -0.105      -0.004\n",
      "t:C(actor_id)[id:twitter.com:42274372]             -4.69e-05      0.026     -0.002      0.999      -0.051       0.051\n",
      "t:C(actor_id)[id:twitter.com:42302742]                0.1703      0.027      6.393      0.000       0.118       0.223\n",
      "t:C(actor_id)[id:twitter.com:42434332]                0.6190      0.031     19.829      0.000       0.558       0.680\n",
      "t:C(actor_id)[id:twitter.com:42473217]               -0.1120      0.026     -4.314      0.000      -0.163      -0.061\n",
      "t:C(actor_id)[id:twitter.com:4250629253]              0.0743      0.026      2.816      0.005       0.023       0.126\n",
      "t:C(actor_id)[id:twitter.com:428532039]               0.2618      0.026     10.033      0.000       0.211       0.313\n",
      "t:C(actor_id)[id:twitter.com:42903275]               -0.0006      0.026     -0.023      0.982      -0.052       0.050\n",
      "t:C(actor_id)[id:twitter.com:43253205]               -0.0520      0.026     -2.018      0.044      -0.103      -0.001\n",
      "t:C(actor_id)[id:twitter.com:43351724]                0.0048      0.026      0.186      0.852      -0.045       0.055\n",
      "t:C(actor_id)[id:twitter.com:43944739]                0.1438      0.026      5.628      0.000       0.094       0.194\n",
      "t:C(actor_id)[id:twitter.com:44390131]                0.1532      0.026      5.868      0.000       0.102       0.204\n",
      "t:C(actor_id)[id:twitter.com:447456690]              -0.0892      0.052     -1.708      0.088      -0.192       0.013\n",
      "t:C(actor_id)[id:twitter.com:45508459]                0.0854      0.026      3.281      0.001       0.034       0.136\n",
      "t:C(actor_id)[id:twitter.com:4635820420]              0.2269      0.029      7.699      0.000       0.169       0.285\n",
      "t:C(actor_id)[id:twitter.com:467717729]              -0.0342      0.254     -0.135      0.893      -0.533       0.464\n",
      "t:C(actor_id)[id:twitter.com:48826114]                0.3032      0.026     11.856      0.000       0.253       0.353\n",
      "t:C(actor_id)[id:twitter.com:493410134]               0.7347      0.026     28.308      0.000       0.684       0.786\n",
      "t:C(actor_id)[id:twitter.com:494522369]               0.0639      0.026      2.503      0.012       0.014       0.114\n",
      "t:C(actor_id)[id:twitter.com:49658852]                0.2212      0.031      7.055      0.000       0.160       0.283\n",
      "t:C(actor_id)[id:twitter.com:50130973]                0.0651      0.026      2.537      0.011       0.015       0.115\n",
      "t:C(actor_id)[id:twitter.com:50498677]               -0.0540      0.026     -2.116      0.034      -0.104      -0.004\n",
      "t:C(actor_id)[id:twitter.com:512447708]               0.0346      0.110      0.314      0.754      -0.182       0.251\n",
      "t:C(actor_id)[id:twitter.com:51279708]               -0.0999      0.029     -3.499      0.000      -0.156      -0.044\n",
      "t:C(actor_id)[id:twitter.com:518921347]               0.1064      0.026      4.162      0.000       0.056       0.157\n",
      "t:C(actor_id)[id:twitter.com:52253454]                0.3971      0.026     15.416      0.000       0.347       0.448\n",
      "t:C(actor_id)[id:twitter.com:52286206]                0.1926      0.026      7.535      0.000       0.142       0.243\n",
      "t:C(actor_id)[id:twitter.com:52379357]                0.1716      0.026      6.605      0.000       0.121       0.223\n",
      "t:C(actor_id)[id:twitter.com:527447086]              -7.7248     10.674     -0.724      0.469     -28.647      13.198\n",
      "t:C(actor_id)[id:twitter.com:53142143]                0.4365      0.026     16.697      0.000       0.385       0.488\n",
      "t:C(actor_id)[id:twitter.com:53678101]                0.3175      0.026     12.151      0.000       0.266       0.369\n",
      "t:C(actor_id)[id:twitter.com:53778621]                0.3951      0.026     15.210      0.000       0.344       0.446\n",
      "t:C(actor_id)[id:twitter.com:53995286]                0.0807      0.026      3.156      0.002       0.031       0.131\n",
      "t:C(actor_id)[id:twitter.com:54054242]                0.3343      0.026     12.908      0.000       0.284       0.385\n",
      "t:C(actor_id)[id:twitter.com:54305566]                0.2812      0.026     10.975      0.000       0.231       0.331\n",
      "t:C(actor_id)[id:twitter.com:545576287]               0.2668      0.026     10.437      0.000       0.217       0.317\n",
      "t:C(actor_id)[id:twitter.com:54599618]               -0.0898      0.028     -3.222      0.001      -0.144      -0.035\n",
      "t:C(actor_id)[id:twitter.com:54713891]                0.0769      0.026      2.957      0.003       0.026       0.128\n",
      "t:C(actor_id)[id:twitter.com:54973156]               -0.0144      0.026     -0.565      0.572      -0.064       0.036\n",
      "t:C(actor_id)[id:twitter.com:55420433]                0.2012      0.026      7.809      0.000       0.151       0.252\n",
      "t:C(actor_id)[id:twitter.com:55478032]                0.3468      0.026     13.523      0.000       0.297       0.397\n",
      "t:C(actor_id)[id:twitter.com:55558616]                0.5285      0.037     14.176      0.000       0.455       0.602\n",
      "t:C(actor_id)[id:twitter.com:561437755]               0.2200      0.026      8.419      0.000       0.169       0.271\n",
      "t:C(actor_id)[id:twitter.com:56790332]                0.6577      0.026     25.753      0.000       0.608       0.708\n",
      "t:C(actor_id)[id:twitter.com:569286330]              -0.0556      0.035     -1.589      0.112      -0.124       0.013\n",
      "t:C(actor_id)[id:twitter.com:57520674]                0.1647      0.026      6.451      0.000       0.115       0.215\n",
      "t:C(actor_id)[id:twitter.com:58324984]                0.2734      0.026     10.535      0.000       0.223       0.324\n",
      "t:C(actor_id)[id:twitter.com:58388736]                0.0060      0.026      0.237      0.813      -0.044       0.056\n",
      "t:C(actor_id)[id:twitter.com:58572021]                0.3167      0.027     11.743      0.000       0.264       0.370\n",
      "t:C(actor_id)[id:twitter.com:590202306]               0.0774      0.035      2.183      0.029       0.008       0.147\n",
      "t:C(actor_id)[id:twitter.com:594777427]               0.4677      0.027     17.042      0.000       0.414       0.522\n",
      "t:C(actor_id)[id:twitter.com:614782590]               0.2747      0.056      4.900      0.000       0.165       0.385\n",
      "t:C(actor_id)[id:twitter.com:62188046]                0.1592      0.026      6.235      0.000       0.109       0.209\n",
      "t:C(actor_id)[id:twitter.com:62343852]                0.2202      0.027      8.016      0.000       0.166       0.274\n",
      "t:C(actor_id)[id:twitter.com:62512359]                0.0196      0.026      0.767      0.443      -0.030       0.070\n",
      "t:C(actor_id)[id:twitter.com:62917505]                0.5807      0.026     22.535      0.000       0.530       0.631\n",
      "t:C(actor_id)[id:twitter.com:63012115]                0.2320      0.028      8.431      0.000       0.178       0.286\n",
      "t:C(actor_id)[id:twitter.com:63547446]                0.2087      0.026      8.174      0.000       0.159       0.259\n",
      "t:C(actor_id)[id:twitter.com:64967178]                0.1708      0.026      6.690      0.000       0.121       0.221\n",
      "t:C(actor_id)[id:twitter.com:65240091]                0.1252      0.026      4.843      0.000       0.075       0.176\n",
      "t:C(actor_id)[id:twitter.com:65728343]                0.4387      0.026     16.947      0.000       0.388       0.489\n",
      "t:C(actor_id)[id:twitter.com:66198530]                0.2370      0.026      9.272      0.000       0.187       0.287\n",
      "t:C(actor_id)[id:twitter.com:66453332]                0.2911      0.026     11.296      0.000       0.241       0.342\n",
      "t:C(actor_id)[id:twitter.com:66612865]                0.1074      0.028      3.867      0.000       0.053       0.162\n",
      "t:C(actor_id)[id:twitter.com:67005756]                0.1844      0.026      7.124      0.000       0.134       0.235\n",
      "t:C(actor_id)[id:twitter.com:67069555]                0.0599      0.026      2.344      0.019       0.010       0.110\n",
      "t:C(actor_id)[id:twitter.com:67096152]                0.2415      0.029      8.388      0.000       0.185       0.298\n",
      "t:C(actor_id)[id:twitter.com:67237988]                0.3245      0.027     12.175      0.000       0.272       0.377\n",
      "t:C(actor_id)[id:twitter.com:67643026]                0.1536      0.038      3.995      0.000       0.078       0.229\n",
      "t:C(actor_id)[id:twitter.com:68469470]                0.8487      0.026     33.234      0.000       0.799       0.899\n",
      "t:C(actor_id)[id:twitter.com:69979143]                0.2191      0.028      7.967      0.000       0.165       0.273\n",
      "t:C(actor_id)[id:twitter.com:70457749]                0.3455      0.028     12.332      0.000       0.291       0.400\n",
      "t:C(actor_id)[id:twitter.com:704778641352368128]      0.0303      0.079      0.383      0.702      -0.125       0.186\n",
      "t:C(actor_id)[id:twitter.com:70597759]                0.2956      0.026     11.341      0.000       0.245       0.347\n",
      "t:C(actor_id)[id:twitter.com:70686932]                0.0794      0.026      3.111      0.002       0.029       0.129\n",
      "t:C(actor_id)[id:twitter.com:70769118]                0.1227      0.026      4.803      0.000       0.073       0.173\n",
      "t:C(actor_id)[id:twitter.com:709812425864957952]     -0.1972      0.168     -1.172      0.241      -0.527       0.133\n",
      "t:C(actor_id)[id:twitter.com:71076388]                0.0654      0.026      2.538      0.011       0.015       0.116\n",
      "t:C(actor_id)[id:twitter.com:72074168]                0.0879      0.027      3.272      0.001       0.035       0.140\n",
      "t:C(actor_id)[id:twitter.com:72193432]                0.0440      0.026      1.724      0.085      -0.006       0.094\n",
      "t:C(actor_id)[id:twitter.com:72901931]                0.2023      0.026      7.917      0.000       0.152       0.252\n",
      "t:C(actor_id)[id:twitter.com:73184984]                0.0998      0.026      3.909      0.000       0.050       0.150\n",
      "t:C(actor_id)[id:twitter.com:73672296]               -0.0638      0.026     -2.496      0.013      -0.114      -0.014\n",
      "t:C(actor_id)[id:twitter.com:738209701658234881]     -0.0382      0.151     -0.254      0.800      -0.334       0.257\n",
      "t:C(actor_id)[id:twitter.com:74145755]                0.0360      0.026      1.400      0.162      -0.014       0.086\n",
      "t:C(actor_id)[id:twitter.com:74612885]                0.4535      0.026     17.465      0.000       0.403       0.504\n",
      "t:C(actor_id)[id:twitter.com:74924009]                0.2007      0.026      7.797      0.000       0.150       0.251\n",
      "t:C(actor_id)[id:twitter.com:753205348970930176]     -0.0375      0.254     -0.147      0.883      -0.536       0.461\n",
      "t:C(actor_id)[id:twitter.com:758360992388681728]      0.0001      0.036      0.004      0.997      -0.071       0.071\n",
      "t:C(actor_id)[id:twitter.com:75839700]                0.1156      0.026      4.525      0.000       0.066       0.166\n",
      "t:C(actor_id)[id:twitter.com:75883996]                0.0472      0.026      1.819      0.069      -0.004       0.098\n",
      "t:C(actor_id)[id:twitter.com:75891845]                0.0311      0.027      1.143      0.253      -0.022       0.084\n",
      "t:C(actor_id)[id:twitter.com:759211292578250752]     -0.0606      0.174     -0.348      0.727      -0.401       0.280\n",
      "t:C(actor_id)[id:twitter.com:76035930]                0.3840      0.026     15.019      0.000       0.334       0.434\n",
      "t:C(actor_id)[id:twitter.com:76146411]               -0.0604      0.026     -2.364      0.018      -0.110      -0.010\n",
      "t:C(actor_id)[id:twitter.com:76555642]                0.0507      0.058      0.871      0.384      -0.063       0.165\n",
      "t:C(actor_id)[id:twitter.com:76863747]                0.1080      0.026      4.161      0.000       0.057       0.159\n",
      "t:C(actor_id)[id:twitter.com:76947892]                0.0053      0.026      0.202      0.840      -0.046       0.056\n",
      "t:C(actor_id)[id:twitter.com:772150676919054340]      0.0447      0.027      1.653      0.098      -0.008       0.098\n",
      "t:C(actor_id)[id:twitter.com:77613385]                0.1302      0.026      5.055      0.000       0.080       0.181\n",
      "t:C(actor_id)[id:twitter.com:776287807]               0.0326      0.026      1.275      0.202      -0.017       0.083\n",
      "t:C(actor_id)[id:twitter.com:78232820]                0.2734      0.026     10.708      0.000       0.223       0.323\n",
      "t:C(actor_id)[id:twitter.com:78944377]                0.3304      0.026     12.728      0.000       0.280       0.381\n",
      "t:C(actor_id)[id:twitter.com:79327466]                0.4415      0.026     17.115      0.000       0.391       0.492\n",
      "t:C(actor_id)[id:twitter.com:79802712]               -0.0598      0.033     -1.834      0.067      -0.124       0.004\n",
      "t:C(actor_id)[id:twitter.com:80047141]                0.5881      0.026     22.765      0.000       0.537       0.639\n",
      "t:C(actor_id)[id:twitter.com:80454912]                0.1737      0.026      6.658      0.000       0.123       0.225\n",
      "t:C(actor_id)[id:twitter.com:806043]                  0.0550      0.026      2.146      0.032       0.005       0.105\n",
      "t:C(actor_id)[id:twitter.com:809351634]               0.0225      0.063      0.358      0.720      -0.101       0.146\n",
      "t:C(actor_id)[id:twitter.com:80972439]                0.0353      0.028      1.248      0.212      -0.020       0.091\n",
      "t:C(actor_id)[id:twitter.com:817770653432553472]     -0.1140      0.039     -2.946      0.003      -0.190      -0.038\n",
      "t:C(actor_id)[id:twitter.com:81862900]                0.0328      0.026      1.283      0.199      -0.017       0.083\n",
      "t:C(actor_id)[id:twitter.com:819212221515448320]      0.4189      0.036     11.538      0.000       0.348       0.490\n",
      "t:C(actor_id)[id:twitter.com:82790893]               -0.0038      0.026     -0.148      0.883      -0.055       0.047\n",
      "t:C(actor_id)[id:twitter.com:83407967]                0.1539      0.026      5.953      0.000       0.103       0.205\n",
      "t:C(actor_id)[id:twitter.com:83441356]                0.0927      0.026      3.584      0.000       0.042       0.143\n",
      "t:C(actor_id)[id:twitter.com:84195118]                0.2088      0.026      8.070      0.000       0.158       0.260\n",
      "t:C(actor_id)[id:twitter.com:84200591]                0.1183      0.027      4.317      0.000       0.065       0.172\n",
      "t:C(actor_id)[id:twitter.com:845814672]              -0.6310      0.323     -1.951      0.051      -1.265       0.003\n",
      "t:C(actor_id)[id:twitter.com:84914746]                0.0880      0.026      3.384      0.001       0.037       0.139\n",
      "t:C(actor_id)[id:twitter.com:85198311]                0.1154      0.026      4.515      0.000       0.065       0.165\n",
      "t:C(actor_id)[id:twitter.com:85201025]                0.1937      0.026      7.581      0.000       0.144       0.244\n",
      "t:C(actor_id)[id:twitter.com:852166370942963713]     -0.0123      0.027     -0.464      0.643      -0.064       0.040\n",
      "t:C(actor_id)[id:twitter.com:85386874]                0.5367      0.026     21.021      0.000       0.487       0.587\n",
      "t:C(actor_id)[id:twitter.com:85393941]                0.0323      0.026      1.266      0.206      -0.018       0.082\n",
      "t:C(actor_id)[id:twitter.com:85427368]                0.0259      0.026      1.005      0.315      -0.025       0.076\n",
      "t:C(actor_id)[id:twitter.com:85547988]                0.2240      0.026      8.774      0.000       0.174       0.274\n",
      "t:C(actor_id)[id:twitter.com:85723280]                0.0040      0.026      0.152      0.879      -0.047       0.055\n",
      "t:C(actor_id)[id:twitter.com:857350208652529665]      0.7685      0.123      6.262      0.000       0.528       1.009\n",
      "t:C(actor_id)[id:twitter.com:86162427]                0.0409      0.033      1.238      0.216      -0.024       0.106\n",
      "t:C(actor_id)[id:twitter.com:86736827]               -0.0394      0.026     -1.543      0.123      -0.089       0.011\n",
      "t:C(actor_id)[id:twitter.com:87311238]                0.3495      0.034     10.260      0.000       0.283       0.416\n",
      "t:C(actor_id)[id:twitter.com:876601172492259328]      0.5096      0.028     18.145      0.000       0.455       0.565\n",
      "t:C(actor_id)[id:twitter.com:87968677]                0.1183      0.026      4.632      0.000       0.068       0.168\n",
      "t:C(actor_id)[id:twitter.com:883455335360548866]     -0.0102      0.028     -0.362      0.717      -0.065       0.045\n",
      "t:C(actor_id)[id:twitter.com:89799361]                0.3244      0.026     12.652      0.000       0.274       0.375\n",
      "t:C(actor_id)[id:twitter.com:92443521]                0.1535      0.026      5.980      0.000       0.103       0.204\n",
      "t:C(actor_id)[id:twitter.com:92537787]                0.3494      0.026     13.267      0.000       0.298       0.401\n",
      "t:C(actor_id)[id:twitter.com:926289838088818688]      0.2131      0.033      6.448      0.000       0.148       0.278\n",
      "t:C(actor_id)[id:twitter.com:92819626]                0.0235      0.040      0.591      0.555      -0.054       0.101\n",
      "t:C(actor_id)[id:twitter.com:93242237]                0.0467      0.026      1.830      0.067      -0.003       0.097\n",
      "t:C(actor_id)[id:twitter.com:933909710356480000]     -0.0654      0.130     -0.505      0.614      -0.319       0.189\n",
      "t:C(actor_id)[id:twitter.com:938531456]               0.0884      0.026      3.424      0.001       0.038       0.139\n",
      "t:C(actor_id)[id:twitter.com:94370717]               -0.0907      0.032     -2.847      0.004      -0.153      -0.028\n",
      "t:C(actor_id)[id:twitter.com:958356811253473280]      0.1557      0.032      4.865      0.000       0.093       0.218\n",
      "t:C(actor_id)[id:twitter.com:96033227]               -0.0198      0.028     -0.720      0.472      -0.074       0.034\n",
      "t:C(actor_id)[id:twitter.com:963418881015631873]     -0.1444      0.070     -2.062      0.039      -0.282      -0.007\n",
      "t:C(actor_id)[id:twitter.com:96669079]                0.0723      0.026      2.791      0.005       0.022       0.123\n",
      "t:C(actor_id)[id:twitter.com:96766250]                0.0577      0.027      2.120      0.034       0.004       0.111\n",
      "t:C(actor_id)[id:twitter.com:96789516]               -0.0481      0.026     -1.882      0.060      -0.098       0.002\n",
      "t:C(actor_id)[id:twitter.com:973049869]              -0.0273      0.294     -0.093      0.926      -0.604       0.550\n",
      "t:C(actor_id)[id:twitter.com:98632081]                0.2179      0.027      8.069      0.000       0.165       0.271\n",
      "t:C(actor_id)[id:twitter.com:99045609]                0.1904      0.026      7.460      0.000       0.140       0.240\n",
      "t:C(actor_id)[id:twitter.com:99285051]                0.1888      0.026      7.388      0.000       0.139       0.239\n",
      "==============================================================================\n",
      "Omnibus:                    13254.375   Durbin-Watson:                   1.480\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           258074.576\n",
      "Skew:                           2.441   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.815   Cond. No.                     2.25e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.35e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# time trend\n",
    "lm = sm.ols('perc_harsh_criticism ~  log_num_tweets + exile + C(t)  + t:C(actor_id)', data).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
